{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!wandb login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:vw970or3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e259c5475ee34e1fa7a9bdecc7283256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.227164…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▄▅▁▂▅▄▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.99713</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-wind-1</strong> at: <a href='https://wandb.ai/kaifan-li/my_project/runs/vw970or3' target=\"_blank\">https://wandb.ai/kaifan-li/my_project/runs/vw970or3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230804_225122-vw970or3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:vw970or3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07bc6da2c3d4e70a35c6eab7030ed93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668189813693366, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/is/kaifan-l/private_room/proj-repos/prompt-for-long-text-summarization/wandb/run-20230804_225935-7shln82z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kaifan-li/my_project/runs/7shln82z' target=\"_blank\">swept-dawn-2</a></strong> to <a href='https://wandb.ai/kaifan-li/my_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kaifan-li/my_project' target=\"_blank\">https://wandb.ai/kaifan-li/my_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kaifan-li/my_project/runs/7shln82z' target=\"_blank\">https://wandb.ai/kaifan-li/my_project/runs/7shln82z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "os.environ['WANDB_DIR'] = os.getcwd() + '/wandb/'\n",
    "os.environ['WANDB_CACHE_DIR'] = os.getcwd() + '/wandb/.cache/'\n",
    "os.environ['WANDB_CONFIG_DIR'] = os.getcwd() + '/wandb/.config/'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 初始化wandb\n",
    "wandb.init(\n",
    "    entity='kaifan-li',\n",
    "    project=\"my_project\"\n",
    ")\n",
    "\n",
    "# 构建模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i in range(100):\n",
    "        inputs = torch.randn(32, 10)  # 随机生成输入数据\n",
    "        labels = torch.randn(32, 1)   # 随机生成标签\n",
    "        \n",
    "        # 正向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # 记录训练过程和指标\n",
    "    avg_loss = running_loss / 100\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": avg_loss})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = \"Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13014"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/is/kaifan-l/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import psutil\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, get_linear_schedule_with_warmup, set_seed\n",
    "\n",
    "from peft import PrefixTuningConfig, TaskType, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator() # device_placement=\"cuda:0\"\n",
    "model_name_or_path = \"facebook/bart-base\"\n",
    "dataset_name = \"cnn_dailymail\"\n",
    "peft_config = PrefixTuningConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    inference_mode=False,\n",
    "    num_virtual_tokens=20,\n",
    ")\n",
    "text_column = 'article'\n",
    "label_column = 'highlights'\n",
    "lr = 3e-3\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "do_test = True\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dataset = load_dataset(dataset_name, \"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "target_max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples[text_column]\n",
    "    targets = examples[label_column]\n",
    "    model_inputs = tokenizer(inputs, truncation=True) # 这里暂时不padding\n",
    "    targets = tokenizer(\n",
    "        targets,\n",
    "        max_length=target_max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    targets = targets['input_ids']\n",
    "    targets[targets == tokenizer.pad_token_id] = -100\n",
    "    model_inputs['labels'] = targets\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 13368/13368 [00:12<00:00, 1042.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "with accelerator.main_process_first():\n",
    "    cnn_dataset = cnn_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        num_proc=1,\n",
    "        remove_columns=cnn_dataset[\"train\"].column_names,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(cnn_dataset[\"train\"]) * 0.1)\n",
    "eval_size = int(len(cnn_dataset[\"validation\"]) * 0.01)\n",
    "test_size = int(len(cnn_dataset[\"test\"]) * 0.01)\n",
    "\n",
    "# 从打乱后的数据集中随机抽取指定数量的数据\n",
    "train_dataset = cnn_dataset[\"train\"].shuffle(seed=42).select(range(train_size))\n",
    "eval_dataset = cnn_dataset[\"validation\"].shuffle(seed=42).select(range(eval_size))\n",
    "test_dataset = cnn_dataset[\"test\"].shuffle(seed=42).select(range(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    return tokenizer.pad(examples, padding='longest', return_tensors='pt')\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True, # 将数据加载到固定的内存中，可以加速数据加载\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024])\n"
     ]
    }
   ],
   "source": [
    "for num, batch in enumerate(train_dataloader):\n",
    "    print(batch[\"input_ids\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:549: FutureWarning: The class `PretrainedBartModel` has been depreciated, please use `BartPreTrainedModel` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import logging\n",
    "import copy\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "from transformers import (\n",
    "    BartForConditionalGeneration, \n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "from transformers import BartConfig\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "from model.prefix_encoder import PrefixEncoder\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "class CustomBartConfig(BartConfig):\n",
    "    def __init__(self,\n",
    "                 pre_seq_len=20,\n",
    "                 input_size=512,\n",
    "                 max_n_segments=3,\n",
    "                 bptt_depth=-1,\n",
    "                 prefix_projection=False, \n",
    "                 hidden_dropout_prob=0.1,\n",
    "                 segment_alignment='left',\n",
    "                 sum_token_size=0,\n",
    "                 label_max_size=142,\n",
    "                 sum_loss=True,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pre_seq_len = pre_seq_len\n",
    "        self.input_size = input_size\n",
    "        self.max_n_segments = max_n_segments\n",
    "        self.bptt_depth = bptt_depth\n",
    "        self.prefix_projection = prefix_projection # whether to use reparametrization trick\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob # dropout for prefix encoder\n",
    "        self.segment_alignment = segment_alignment\n",
    "        self.sum_token_size = sum_token_size\n",
    "        self.label_max_size = label_max_size # the max size of labels\n",
    "        self.sum_loss = sum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_config = BartConfig.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBartConfig {\n",
       "  \"_name_or_path\": \"bart-base\",\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"BartModel\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"bptt_depth\": -1,\n",
       "  \"classif_dropout\": 0.1,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_attention_heads\": 12,\n",
       "  \"decoder_ffn_dim\": 3072,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"dropout\": 0.1,\n",
       "  \"early_stopping\": true,\n",
       "  \"encoder_attention_heads\": 12,\n",
       "  \"encoder_ffn_dim\": 3072,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 6,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"forced_bos_token_id\": 0,\n",
       "  \"forced_eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"input_size\": 512,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"label_max_size\": 142,\n",
       "  \"max_n_segments\": 3,\n",
       "  \"max_position_embeddings\": 1024,\n",
       "  \"model_type\": \"bart\",\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"normalize_before\": false,\n",
       "  \"normalize_embedding\": true,\n",
       "  \"num_beams\": 4,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"pre_seq_len\": 20,\n",
       "  \"prefix_projection\": false,\n",
       "  \"scale_embedding\": false,\n",
       "  \"segment_alignment\": \"left\",\n",
       "  \"sum_loss\": true,\n",
       "  \"sum_token_size\": 0,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 128,\n",
       "      \"min_length\": 12,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_cnn\": {\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 142,\n",
       "      \"min_length\": 56,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_xsum\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 62,\n",
       "      \"min_length\": 11,\n",
       "      \"num_beams\": 6\n",
       "    }\n",
       "  },\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.32.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_config = CustomBartConfig(**bart_config.to_dict())\n",
    "custom_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import logging\n",
    "import copy\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union, Iterable\n",
    "\n",
    "from transformers import (\n",
    "    BartPretrainedModel,\n",
    "    BartForConditionalGeneration, \n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "from transformers import BartConfig, T5Config\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "from model.prefix_encoder import PrefixEncoder\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# copied from transformers.modeling_bart.py\n",
    "def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
    "    \"\"\"\n",
    "    Shift input ids one token to the right.\n",
    "    \"\"\"\n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "\n",
    "    if pad_token_id is None:\n",
    "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
    "    # replace possible -100 values in labels by `pad_token_id`\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "\n",
    "    return shifted_input_ids\n",
    "# prefix-tuning/p-tuning v2 version\n",
    "class BartPrefixForConditionalGeneration(BartPretrainedModel):\n",
    "    def __init__(self, config, checkpoint):\n",
    "        super().__init__(config)\n",
    "        # copied from BartForConditionalGeneration.__init__()\n",
    "        # self.model = BartModel(config)\n",
    "        # self.register_buffer(\"final_logits_bias\", torch.zeros((1, self.model.shared.num_embeddings)))\n",
    "        # self.lm_head = nn.Linear(config.d_model, self.model.shared.num_embeddings, bias=False)\n",
    "        # self.post_init() will not overwrite the pretrained parameters when using from_pretrained()\n",
    "        \n",
    "        self.model = BartForConditionalGeneration.from_pretrained(checkpoint)\n",
    "        self.tokenizer = BartTokenizer.from_pretrained(checkpoint)\n",
    "        self.config = config\n",
    "\n",
    "        self.segment_alignment = config.segment_alignment\n",
    "        self.extract_special_tokens(tokenizer)\n",
    "        self.pre_seq_len = config.pre_seq_len\n",
    "        self.n_layer = config.num_hidden_layers\n",
    "        self.n_head = config.num_attention_heads\n",
    "        self.n_embd = config.hidden_size // config.num_attention_heads\n",
    "        # self.extend_word_embeddings(config.pre_seq_len, tokenizer)\n",
    "        \n",
    "        # tokenizer.num_special_tokens_to_add()cal the number of special tokens needed to add except [SEP]\n",
    "        # bart-base: 489\n",
    "        self.segment_size = config.input_size - self.pre_seq_len - tokenizer.num_special_tokens_to_add()\n",
    "        if 'sep_token' in tokenizer.special_tokens_map:\n",
    "            self.segment_size -= 1\n",
    "        \n",
    "        # TODO: forget some part of long range memory and add new memory\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.prefix_tokens = torch.arange(self.pre_seq_len).long()\n",
    "        self.prefix_encoder = PrefixEncoder(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "        bart_param = 0\n",
    "        all_param = 0\n",
    "        \n",
    "        # count the number of trainable parameters in bart\n",
    "        for name, param in self.model.named_parameters():\n",
    "            bart_param += param.numel() # numel() returns the total number of elements in the input tensor\n",
    "            \n",
    "        for name, param in self.named_parameters():\n",
    "            all_param += param.numel()\n",
    "            \n",
    "        trainable_param = all_param - bart_param\n",
    "        \n",
    "        print(\"Total parameters: {:,}\".format(all_param))\n",
    "        print(\"Trainable parameters: {:,} {:,%}\".format((trainable_param), trainable_param/all_param))\n",
    "\n",
    "    def get_prompt(self, batch_size):\n",
    "        prefix_tokens = self.prefix_tokens.unsqueeze(0).expand(batch_size, -1).to(self.model.device)\n",
    "        past_key_values = self.prefix_encoder(prefix_tokens)\n",
    "        bsz, seqlen, _ = past_key_values.shape\n",
    "        past_key_values = past_key_values.view(\n",
    "            bsz,\n",
    "            seqlen,\n",
    "            self.n_layer * 2,\n",
    "            self.n_head,\n",
    "            self.n_embd\n",
    "        )        \n",
    "        past_key_values = self.dropout(past_key_values)\n",
    "        # (2,batch_size,n_head,seq_len,head_dim)\n",
    "        past_key_values = past_key_values.permute([2, 0, 3, 1, 4]).split(2)\n",
    "        return past_key_values\n",
    "    \n",
    "    # TODO：split labels other warys\n",
    "    # TODO: 25% -> 50% -> 75% -> 100% -> 100% -> 100% -> 100% -> 100% -> 100% -> 100%\n",
    "    def pad_and_segment(self, input_ids, attention_mask=None, labels=None):\n",
    "        \"\"\"\n",
    "        segment input_ids into segments\n",
    "        \n",
    "        input sample:\n",
    "        segmented_batch = [\n",
    "            [sample1_seg1, sample1_seg2, sample1_seg3],\n",
    "            [sample2_seg1, sample2_seg2],\n",
    "            [sample3_seg1, sample3_seg2, sample3_seg3, sample3_seg4]\n",
    "        ]\n",
    "                   \n",
    "        output sample:\n",
    "        segmented_batch = [\n",
    "            [sample1_seg1, sample2_seg1, sample3_seg1],\n",
    "            [sample1_seg2, sample2_seg2, sample3_seg2],\n",
    "            [sample1_seg3, None, sample3_seg3],\n",
    "            [None, None, sample3_seg4]\n",
    "        ]\n",
    "        \"\"\"\n",
    "        segmented_batch = []\n",
    "        segmented_batch_attention_masks = []\n",
    "        segmented_batch_labels = []\n",
    "        \n",
    "        if attention_mask is None:\n",
    "            attention_mask = [None] * input_ids.shape[0]\n",
    "        batch_attention_mask = attention_mask\n",
    "            \n",
    "        # inference mode\n",
    "        if labels is None:\n",
    "            labels = [None] * input_ids.shape[0]\n",
    "        batch_labels = labels\n",
    "        \n",
    "        # input_ids: [batch_size, seq_len]\n",
    "        for seq, attn_mask, label in zip(input_ids, batch_attention_mask, batch_labels):\n",
    "\n",
    "            # pytorch syntax: element-wise operation\n",
    "            drop_mask = sum([seq == t for t in self.special_token_ids])\n",
    "            drop_mask = torch.tensor([1 if t != 0 else 0 for t in drop_mask])\n",
    "\n",
    "            # bool type slice for tensor type\n",
    "            # remove special tokens\n",
    "            seq = seq[(1 - drop_mask).bool()]\n",
    "            seq = seq[:self.segment_size * self.config.max_n_segments]\n",
    "            \n",
    "            if attn_mask is not None:\n",
    "                attn_mask_drop_mask = sum([attn_mask == self.pad_token_id])\n",
    "                attn_mask = attn_mask[attn_mask_drop_mask.bool()]\n",
    "                attn_mask = attn_mask[:self.segment_size * self.config.max_n_segments]\n",
    "            if label is not None:\n",
    "                label_drop_mask = sum([label == t for t in self.special_token_ids + [-100]])\n",
    "                label_drop_mask = torch.tensor([1 if t != 0 else 0 for t in label_drop_mask])\n",
    "                label = label[(1-label_drop_mask).bool()]\n",
    "                # TODO：label = label[:self.config.sum_max_size * self.config.max_n_segments]\n",
    "                label = label[:self.segment_size * self.config.max_n_segments]\n",
    "            \n",
    "            align = self.segment_alignment\n",
    "            if align in {'right', None}:\n",
    "                split_inds = (list(range(len(seq), 0, -self.segment_size)) + [0])[::-1]\n",
    "            elif align == 'left':\n",
    "                split_inds = list(range(0, len(seq), self.segment_size)) + [len(seq)]\n",
    "            elif align == 'center':\n",
    "                n_seg = math.ceil(len(seq) / self.segment_size)\n",
    "                split_inds = list(range(0, len(seq), math.ceil(len(seq) / n_seg))) + [len(seq)]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            input_segments = [seq[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "            input_segments = [self.pad_add_special_tokens(t, self.config.input_size) for t in input_segments]\n",
    "            \n",
    "            # add empty segment markers if needed\n",
    "            n_empty_segments = self.config.max_n_segments - len(input_segments)\n",
    "            # input_segments:\n",
    "            # print(\"input_segments:\", input_segments)\n",
    "            input_segments = input_segments + [self.get_full_padding_segment()] * n_empty_segments\n",
    "            \n",
    "            # segmented_batch: \n",
    "            segmented_batch.append(input_segments)\n",
    "\n",
    "            if attn_mask is not None:\n",
    "                attn_mask_segments = [attn_mask[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "                attn_mask_segments = [self.pad_add_special_tokens(t, self.config.input_size, add_to='attention_mask') for t in attn_mask_segments]\n",
    "                attn_mask_segments = attn_mask_segments + [self.get_full_padding_segment()] * n_empty_segments\n",
    "                segmented_batch_attention_masks.append(attn_mask_segments)\n",
    "            \n",
    "            # TODO: labels need to be segmented by other rules\n",
    "            if label is not None:\n",
    "                labels_segments = [label[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "                labels_segments = [self.pad_add_special_tokens(t, self.config.input_size, add_to='labels') for t in labels_segments]\n",
    "                labels_segments = labels_segments + [self.get_full_padding_segment()] * n_empty_segments\n",
    "                segmented_batch_labels.append(labels_segments)\n",
    "                \n",
    "        segmented_batch = [[sample[seg_num] for sample in segmented_batch] \n",
    "                            for seg_num in range(self.config.max_n_segments)]\n",
    "        segmented_batch_attention_masks = [[sample[seg_num] for sample in segmented_batch_attention_masks]\n",
    "                                           for seg_num in range(self.config.max_n_segments)]\n",
    "        segmented_batch_labels = [[sample[seg_num] for sample in segmented_batch_labels]\n",
    "                                  for seg_num in range(self.config.max_n_segments)]\n",
    "\n",
    "        return segmented_batch, segmented_batch_attention_masks, segmented_batch_labels\n",
    "        \n",
    "    def extract_special_tokens(self, tokenizer):\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.special_token_ids = [tokenizer.pad_token_id]\n",
    "        for token in ['cls_token', 'sep_token', 'eos_token', 'bos_token']:\n",
    "            token_id = getattr(tokenizer, f'{token}_id')\n",
    "            if token_id is not None:\n",
    "                self.register_buffer(token, torch.tensor([token_id]))\n",
    "                self.special_token_ids.append(token_id)\n",
    "            else:\n",
    "                setattr(self, token, None)\n",
    "                \n",
    "    # def extend_word_embeddings(self, tokenizer):\n",
    "    #     vocab_size = self.model.config.vocab_size\n",
    "    #     # NOTE: Really necessary???\n",
    "    #     extended_vocab_size = vocab_size + self.config.pre_seq_len\n",
    "    #     self.pre_seq_len = self.config.pre_seq_len\n",
    "    \n",
    "    def get_full_padding_segment(self,):\n",
    "        padding_segment = torch.tensor([self.pad_token_id for _ in range(self.config.input_size)])\n",
    "        return padding_segment\n",
    "    \n",
    "    # Memory mechanism like RNN\n",
    "    def forget_and_memory(self,):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    #  prefix-tuning don't need to concat prefix and input sequence\n",
    "    def pad_add_special_tokens(self, tensor, segment_size, \n",
    "                               prompts=None, prompt_attention_mask=None, # maybe better to use pre_seq_len and generate prompts attention mask?\n",
    "                               add_to='input_ids'):\n",
    "        \"\"\"\n",
    "        bart tokenizer:\n",
    "        {'bos_token': '<s>', 0\n",
    "         'eos_token': '</s>', 2\n",
    "         'unk_token': '<unk>', 3\n",
    "         'sep_token': '</s>', 0\n",
    "         'pad_token': '<pad>', 1\n",
    "         'cls_token': '<s>', 0\n",
    "         'mask_token': '<mask>' 50264\n",
    "        }\n",
    "        \"\"\"\n",
    "        input_elements = []\n",
    "        # Add special tokens: <s> and </s> to the input sequence\n",
    "        # For prefix-prop\n",
    "        if prompts is not None:\n",
    "            if add_to == 'inputs':\n",
    "                input_elements += [self.cls_token, prompts, self.sep_token, tensor, self.sep_token]\n",
    "            # For Bart, only the pad token is 0 in attention_mask\n",
    "            elif add_to == 'attention_mask':\n",
    "                mask_value = torch.ones((1), device=tensor.device)\n",
    "                input_elements += [mask_value, prompt_attention_mask, mask_value, tensor, mask_value]\n",
    "            # As a encoder-decoder model：is not needed to add prompt to labels\n",
    "            elif add_to == 'labels':\n",
    "                input_elements += [self.eos_token, tensor, self.sep_token]\n",
    "        # For prefix-tuning/p-tuning v2\n",
    "        else:\n",
    "            if add_to == 'input_ids':\n",
    "                input_elements += [self.sep_token, tensor, self.sep_token]\n",
    "            elif add_to == 'attention_mask':\n",
    "                mask_value = torch.ones((1), device=tensor.device)\n",
    "                input_elements += [mask_value, tensor, mask_value]\n",
    "            elif add_to == 'labels':\n",
    "                input_elements += [self.eos_token, tensor, self.sep_token]\n",
    "        tensor = torch.cat(input_elements)\n",
    "\n",
    "        # Add padding tokens\n",
    "        # TODO: implement summary module\n",
    "        #       now self.config.sum_size default = 0\n",
    "        pad_size = segment_size - tensor.shape[0] - self.config.sum_token_size\n",
    "        if pad_size > 0:\n",
    "            if add_to == 'input_ids':\n",
    "                tensor = F.pad(tensor, (0, pad_size), value=self.pad_token_id)\n",
    "            # TODO: 显然有错误\n",
    "            elif add_to == 'attention_mask':\n",
    "                tensor = F.pad(tensor, (0, pad_size), value=0)\n",
    "            elif add_to == 'labels':\n",
    "                # TODO: dynamic padding labels??\n",
    "                # pad_size = min(pad_size, self.config.label_max_size)\n",
    "                # for Seq2Seq labels need to be pad by -100\n",
    "                tensor = F.pad(tensor, (0, pad_size), value=-100)\n",
    "        return tensor\n",
    "\n",
    "        # TODO: this implementation just add <s> and </s> to the input sequence\n",
    "        #       maybe need to add other special tokens\n",
    "    \n",
    "    def prepare_kwargs(self, segment, kwargs):\n",
    "        segment_input_ids, segment_attention_mask, segment_label = segment\n",
    "        seg_kwargs = dict(**kwargs)\n",
    "        \n",
    "        # [sample1_seg1, sample2_seg1, sample3_seg1,....] up to batch_size\n",
    "        # Some of the segments are None like: [sample1_seg3, None, sample3_seg3]\n",
    "        non_empty_mask = [s is not None for s in segment_input_ids]\n",
    "        print(\"non_empty_mask:\", non_empty_mask)\n",
    "        # all the segments are None, due to the max_n_segments >> the number of segments        \n",
    "        if sum(non_empty_mask) == 0:\n",
    "            return None, non_empty_mask\n",
    "        \n",
    "        # convert list to tensor\n",
    "        # print(\"segment_input_ids:\", segment_input_ids)\n",
    "        for s in segment_input_ids:\n",
    "            print(\"s:\", s.shape)\n",
    "        input_ids = torch.stack([s for s in segment_input_ids if s is not None])\n",
    "        print(\"input_ids:\", input_ids.shape)\n",
    "        # input_embeds = self.model.embeddings(input_ids)\n",
    "\n",
    "        seg_kwargs['input_ids'] = input_ids\n",
    "        print(\"input_ids:\", seg_kwargs['input_ids'].shape)\n",
    "        # seg_kwargs['inputs_embeds'] = input_embeds\n",
    "        \n",
    "        # if seg_kwargs.get('token_type_ids') is not None:\n",
    "        #     seg_kwargs['token_type_ids'] = self.get_token_type_ids(input_ids)\n",
    "\n",
    "        # seg_kwargs['decoder_input_ids'] = torch.stack([el for el, m in zip(segment_label, non_empty_mask) if m])\n",
    "        # seg_kwargs['decoder_input_ids'] = seg_kwargs['decoder_input_ids'][non_empty_mask]\n",
    "        # print(\"decoder_input_ids:\", seg_kwargs['decoder_input_ids'].shape)\n",
    "        # if seg_kwargs['labels_mask'] is not None:\n",
    "        # seg_kwargs['labels_mask'] = torch.stack([el for el, m in zip(segment_labels_mask, non_empty_mask) if m])\n",
    "        # if seg_kwargs.get('token_type_ids') is not None:\n",
    "        #     seg_kwargs['token_type_ids'] = self.get_token_type_ids(input_ids)\n",
    "        # seg_kwargs['output_hidden_states'] = True\n",
    "        \n",
    "        # generate prompts\n",
    "        batch_size = seg_kwargs['input_ids'].shape[0]\n",
    "        print('batch_size:', batch_size)\n",
    "        past_key_values = self.get_prompt(batch_size)\n",
    "        prefix_attention_mask = torch.ones(batch_size, self.pre_seq_len)\n",
    "        \n",
    "        if seg_kwargs['labels'] is not None:\n",
    "            seg_kwargs['labels'] = torch.stack([el for el, m in zip(segment_label, non_empty_mask) if m])\n",
    "        \n",
    "        # attn_mask = torch.cat([prefix_attention_mask, attention_mask], dim=1)\n",
    "        # seg_kwargs['past_key_values'] = past_key_values\n",
    "        if seg_kwargs['attention_mask'] is not None:\n",
    "            seg_kwargs['attention_mask'] = self.get_attention_mask(input_ids)\n",
    "        # seg_kwargs['attention_mask'] = attn_mask\n",
    "        return seg_kwargs, non_empty_mask\n",
    "        \n",
    "    def get_attention_mask(self, tensor):\n",
    "        mask = torch.ones_like(tensor)\n",
    "        mask[tensor == self.pad_token_id] = 0\n",
    "        return mask\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
    "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = True,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, Seq2SeqLMOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
    "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
    "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
    "\n",
    "        Returns:\n",
    "        \"\"\" \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        kwargs = {\n",
    "            'attention_mask': attention_mask, \n",
    "            # 'token_type_ids': token_type_ids,\n",
    "            # 'position_ids': position_ids, \n",
    "            'inputs_embeds': inputs_embeds,\n",
    "            'labels': labels,\n",
    "            'output_attentions': output_attentions,\n",
    "            'output_hidden_states': output_hidden_states, \n",
    "            'return_dict': return_dict,\n",
    "        }\n",
    "        # segmented: [max_n_segments, batch_size, segment_size]\n",
    "        # !!! Note: the batch_size is not the same as the input batch_size\n",
    "        segmented = self.pad_and_segment(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        # NOTE: why???\n",
    "        # if self.pre_seq_len == 0:\n",
    "        #     segmented = segmented[-1:]\n",
    "        \n",
    "        model_outputs = []\n",
    "        for seg_num, segment in enumerate(zip(*segmented)):\n",
    "            print(\"seg_num:\", seg_num)\n",
    "            \n",
    "            in_ids, attn_mask, l = segment\n",
    "            print(\"batch_size:\", len(in_ids))\n",
    "            # TODO: can't control the number of gradient accumulation steps now\n",
    "            if self.config.bptt_depth != -1:\n",
    "                raise NotImplementedError\n",
    "            \n",
    "            seg_kwargs, non_empty_mask = self.prepare_kwargs(segment, kwargs)\n",
    "            # print(\"in_ids|attn_mask|l:\", seg_kwargs['input_ids'].shape, seg_kwargs['attention_mask'].shape, seg_kwargs['decoder_input_ids'].shape)\n",
    "            if sum(non_empty_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            out = self.model(**seg_kwargs)\n",
    "            print('decoder_input_ids:', decoder_input_ids)\n",
    "            # out = self.model(\n",
    "            #     input_ids=seg_kwargs['input_ids'],\n",
    "            #     attention_mask=seg_kwargs['attention_mask'],\n",
    "            #     # TODO: 只能concat attention到decoder attention mask\n",
    "            #     # past_key_values=seg_kwargs['past_key_values'],\n",
    "            #     # TODO: decoder_attention_mask: https://github.com/huggingface/transformers/issues/25271\n",
    "            #     decoder_input_ids=decoder_input_ids\n",
    "            # )\n",
    "            # self.prefix_tokens = out.encoder_last_hidden_state[-1][:, 1:self.pre_seq_len+1]\n",
    "            # self.prefix_tokens = out.last_hidden_state[:, :self.pre_seq_len]\n",
    "            print('prefix_tokens:', self.prefix_tokens.shape)\n",
    "            out['seg_kwargs'] = seg_kwargs\n",
    "            model_outputs.append(out)\n",
    "            print('out:', out)\n",
    "        out = self.process_outputs(model_outputs, output_attentions, output_hidden_states)\n",
    "        print('model is finished')\n",
    "        return out\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        max_length: Optional[int] = None,\n",
    "        min_length: Optional[int] = None,\n",
    "        do_sample: Optional[bool] = None,\n",
    "        early_stopping: Optional[bool] = None,\n",
    "        num_beams: Optional[int] = None,\n",
    "        temperature: Optional[float] = None,\n",
    "        top_k: Optional[int] = None,\n",
    "        top_p: Optional[float] = None,\n",
    "        repetition_penalty: Optional[float] = None,\n",
    "        bad_words_ids: Optional[Iterable[int]] = None,\n",
    "        bos_token_id: Optional[int] = None,\n",
    "        pad_token_id: Optional[int] = None,\n",
    "        eos_token_id: Optional[int] = None,\n",
    "        length_penalty: Optional[float] = None,\n",
    "        no_repeat_ngram_size: Optional[int] = None,\n",
    "        num_return_sequences: Optional[int] = None,\n",
    "        attention_mask: Optional[torch.LongTensor] = None,\n",
    "        decoder_start_token_id: Optional[int] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        **model_specific_kwargs\n",
    "    ) -> torch.LongTensor:\n",
    "\n",
    "\n",
    "        kwargs = {\n",
    "            'input_ids': input_ids,\n",
    "            'num_beams': num_beams,\n",
    "            'min_length': min_length,\n",
    "            'max_length': max_length,\n",
    "            'labels': None,\n",
    "            'attention_mask': None\n",
    "        }\n",
    "        \n",
    "        segmented = self.pad_and_segment(\n",
    "            input_ids=input_ids,\n",
    "        )\n",
    "        \n",
    "        model_outputs = []\n",
    "        for seg_num, segment in enumerate(zip(*segmented)):\n",
    "            in_ids, attn_mask, l = segment\n",
    "            \n",
    "            if self.config.bptt_depth != -1:\n",
    "                raise NotImplementedError\n",
    "            \n",
    "            seg_kwargs, non_empty_mask = self.prepare_kwargs(segment, kwargs)\n",
    "            if sum(non_empty_mask) == 0:\n",
    "                continue\n",
    "            \n",
    "            out = self.model.generate(**seg_kwargs)\n",
    "            \n",
    "            model_outputs.append(out)\n",
    "            print('out:', out)\n",
    "        print(\"model_outputs: \", self.tokenizer.decode(model_outputs[-1][-1], skip_special_tokens=True))\n",
    "        \n",
    "    def process_outputs(self, model_outputs, output_attentions, output_hidden_states):\n",
    "        out = model_outputs[-1] # get the last segment output\n",
    "        \n",
    "        bs, seq_len = input_ids.shape\n",
    "        \n",
    "        losses = []\n",
    "        logits = []\n",
    "        labels_segm = []\n",
    "        \n",
    "        for out in model_outputs:\n",
    "            losses.append(out['loss'])\n",
    "            logits.append(out['logits'].detach())\n",
    "            labels_segm += [out['seg_kwargs']['labels']]\n",
    "        \n",
    "        if not output_hidden_states:\n",
    "            for key in out.keys():\n",
    "                if 'hidden_state' in key:\n",
    "                    out[key] = None\n",
    "                    \n",
    "        for i, l in enumerate(losses):\n",
    "            out[f'loss_{i}'] = l.mean()\n",
    "            \n",
    "        out['loss'] = torch.stack(losses).mean()\n",
    "        \n",
    "        for i in range(len(logits)):\n",
    "            logits[i] = F.pad(logits[i], (0, 0, 0, 0, 0, bs - logits[i].shape[0]))\n",
    "            labels_segm[i] = F.pad(labels_segm[i], (0, 0, 0, bs - labels_segm[i].shape[0]), value=-100)\n",
    "        \n",
    "        out['logits'] = torch.cat(logits, dim=1)\n",
    "        # Warning: rmt logits, labels, masks are not in the same order as in input data:\n",
    "        # the first dimension is number of segments!\n",
    "        # so, torch.cat will result in segm0, segm0,.. and only after all segm0 will come segm1, ... .\n",
    "        # not segm0, segm1, segm0, segm1 as in input data\n",
    "        out['logits_segm'] = [logits]\n",
    "        out['labels_segm'] = [labels_segm]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 139,604,736\n",
      "Trainable parameters: 184,320 0.132030%\n"
     ]
    }
   ],
   "source": [
    "# from model.summarization import BartPrefixForConditionalGeneration\n",
    "checkpoint = 'facebook/bart-base'\n",
    "model = BartPrefixForConditionalGeneration(    \n",
    "    checkpoint=checkpoint,\n",
    "    config=custom_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 2, 2, 0]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.special_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids.shape: torch.Size([32, 1024])\n",
      "attention_mask.shape: torch.Size([32, 1024])\n",
      "labels.shape: torch.Size([32, 128])\n",
      "seg_num: 0\n",
      "batch_size: 32\n",
      "non_empty_mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "batch_size: 32\n",
      "decoder_input_ids: None\n",
      "prefix_tokens: torch.Size([20])\n",
      "out: Seq2SeqLMOutput(loss=tensor(4.4358), logits=tensor([[[32.9156,  5.6515, 17.1001,  ...,  5.6693,  5.4775,  1.9122],\n",
      "         [ 8.5646, -3.1311, 14.0776,  ..., -1.9482, -1.6643, -1.6928],\n",
      "         [-8.5718, -4.6513, -0.6265,  ..., -5.6180, -5.3114, -1.3357],\n",
      "         ...,\n",
      "         [-4.4996, -4.6645,  4.5209,  ..., -4.9903, -4.7297, -3.5554],\n",
      "         [-4.4911, -4.4550,  4.4576,  ..., -4.7867, -4.5467, -3.4890],\n",
      "         [-3.8328, -4.3564,  5.2950,  ..., -4.7480, -4.4398, -3.3219]],\n",
      "\n",
      "        [[34.3656,  6.2473, 16.4431,  ...,  6.4064,  6.1794,  1.7232],\n",
      "         [ 6.0948, -3.2293, 13.6413,  ..., -1.9240, -1.7141, -1.6305],\n",
      "         [-8.0149, -5.0904,  2.4178,  ..., -5.6193, -5.3988, -5.1694],\n",
      "         ...,\n",
      "         [-2.3826, -3.3837,  3.9139,  ..., -3.6298, -3.4162, -2.0758],\n",
      "         [-2.8857, -3.2850,  3.8356,  ..., -3.5813, -3.4092, -2.3186],\n",
      "         [-3.0224, -3.4809,  4.1883,  ..., -3.8638, -3.6452, -2.2451]],\n",
      "\n",
      "        [[34.2228,  5.9932, 17.1363,  ...,  6.2339,  6.0574,  2.2311],\n",
      "         [ 2.6946, -3.1837, 11.3865,  ..., -1.4047, -0.8492,  1.1100],\n",
      "         [-7.8702, -5.5713, -0.9993,  ..., -6.4380, -6.0332, -0.5956],\n",
      "         ...,\n",
      "         [-2.2932, -4.4909,  4.9428,  ..., -4.3208, -3.8128, -4.2939],\n",
      "         [-2.3571, -4.3725,  4.9703,  ..., -4.2314, -3.8253, -4.2073],\n",
      "         [-2.2491, -4.3503,  5.0709,  ..., -4.4300, -3.8990, -4.1816]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[33.2030,  5.8352, 16.8577,  ...,  5.6998,  5.6921,  2.1406],\n",
      "         [ 7.2899, -2.4729, 11.3004,  ..., -1.6440, -0.9058, -2.5438],\n",
      "         [-7.4541, -5.0755,  0.5867,  ..., -5.4343, -5.2108, -4.6952],\n",
      "         ...,\n",
      "         [-3.7635, -3.4068,  3.2195,  ..., -3.8441, -3.4988, -3.5486],\n",
      "         [-4.2075, -3.4418,  2.9708,  ..., -3.9410, -3.5978, -3.7239],\n",
      "         [-4.1081, -3.4474,  3.1160,  ..., -3.9785, -3.6298, -3.6229]],\n",
      "\n",
      "        [[34.2552,  6.1010, 16.5128,  ...,  6.1822,  6.1631,  2.0070],\n",
      "         [ 7.9707, -2.4994, 14.0897,  ..., -0.9464, -0.9175, -0.1168],\n",
      "         [-2.6070, -5.2362,  1.4291,  ..., -5.4519, -5.5793, -4.9229],\n",
      "         ...,\n",
      "         [-2.6330, -3.1841,  3.3958,  ..., -3.2240, -3.3059, -1.7789],\n",
      "         [-2.8438, -3.1288,  3.1684,  ..., -3.1517, -3.3117, -1.8942],\n",
      "         [-2.7531, -3.2989,  3.3539,  ..., -3.4281, -3.5362, -1.7282]],\n",
      "\n",
      "        [[34.0733,  5.8370, 16.0993,  ...,  5.8989,  5.6725,  1.2133],\n",
      "         [ 9.6630, -2.8382, 11.9482,  ..., -1.4402, -1.6568, -0.6403],\n",
      "         [-1.6217, -4.9660,  1.2210,  ..., -4.2743, -4.2845, -4.9953],\n",
      "         ...,\n",
      "         [-5.5394, -2.9852,  4.0620,  ..., -2.6970, -2.6277, -4.8008],\n",
      "         [-5.0844, -2.7386,  4.4659,  ..., -2.4286, -2.3970, -4.3942],\n",
      "         [-5.2730, -2.8267,  4.7195,  ..., -2.5821, -2.5717, -4.5899]]]), past_key_values=None, decoder_hidden_states=(tensor([[[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.7090e-01,  3.2624e-01,  4.7603e-01,  ..., -6.2831e-02,\n",
      "           1.0224e-01, -1.2863e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.9464e-01,  3.2075e-01,  1.1918e-01,  ..., -8.8841e-02,\n",
      "          -9.6665e-01,  3.6767e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 7.2743e-01,  5.2758e-01,  6.4691e-01,  ..., -1.8242e-01,\n",
      "          -3.7763e-01,  2.9052e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 3.7580e-01, -3.4123e-01,  3.5496e-01,  ..., -6.7475e-01,\n",
      "           1.9052e-01, -6.2882e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [-4.8842e-01, -6.5146e-02, -1.5177e-01,  ...,  1.9739e-01,\n",
      "           1.1390e-01,  6.5198e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 3.4441e-01,  1.2018e-01, -6.0789e-01,  ..., -7.0074e-01,\n",
      "           4.2079e-02,  2.3514e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]]]), tensor([[[-2.3267e-03, -4.2727e-03,  1.0288e-02,  ...,  7.1663e-03,\n",
      "           1.1418e-02, -1.2811e-02],\n",
      "         [ 9.8589e-02, -1.4794e-01,  7.9496e-02,  ..., -1.7988e-02,\n",
      "          -1.5280e-01, -1.2821e-02],\n",
      "         [ 6.9704e-02,  5.2941e-01,  2.0281e-01,  ...,  3.0970e-02,\n",
      "           1.3471e-01,  6.7978e-02],\n",
      "         ...,\n",
      "         [ 4.0746e-02, -3.2988e-01,  2.5241e-01,  ...,  6.3770e-01,\n",
      "          -9.0018e-01, -2.7156e-01],\n",
      "         [ 1.6447e-01, -3.2367e-01,  1.8493e-01,  ...,  6.7545e-01,\n",
      "          -1.0436e+00, -1.1253e-01],\n",
      "         [ 4.1894e-01, -2.4531e-01,  1.8713e-01,  ...,  5.9632e-01,\n",
      "          -9.3883e-01, -4.2020e-02]],\n",
      "\n",
      "        [[-2.6304e-03, -4.0929e-03,  1.1034e-02,  ...,  6.9469e-03,\n",
      "           1.2235e-02, -1.2591e-02],\n",
      "         [ 8.9159e-02, -1.1843e-01,  6.6816e-02,  ..., -1.3921e-02,\n",
      "          -1.4823e-01,  8.0146e-03],\n",
      "         [ 1.1550e-01,  5.1509e-01,  2.4426e-01,  ..., -7.3271e-02,\n",
      "          -8.0634e-01,  1.3873e-01],\n",
      "         ...,\n",
      "         [-1.6388e-01, -2.2118e-01,  2.0295e-01,  ...,  5.7845e-01,\n",
      "          -9.2553e-01, -2.7298e-01],\n",
      "         [-2.9101e-02, -2.4668e-01,  1.3616e-01,  ...,  6.1156e-01,\n",
      "          -1.0814e+00, -1.6299e-01],\n",
      "         [ 2.2939e-01, -1.4049e-01,  1.8002e-01,  ...,  5.2902e-01,\n",
      "          -9.8293e-01, -7.0143e-02]],\n",
      "\n",
      "        [[-2.7002e-03, -4.0850e-03,  9.8615e-03,  ...,  8.2825e-03,\n",
      "           1.1626e-02, -1.2155e-02],\n",
      "         [ 8.6875e-02, -1.3737e-01,  8.6883e-02,  ..., -2.4794e-03,\n",
      "          -1.5818e-01,  2.3642e-02],\n",
      "         [ 3.0507e-01,  7.9640e-01,  1.0072e+00,  ..., -2.8137e-01,\n",
      "          -3.3952e-01,  2.3645e-01],\n",
      "         ...,\n",
      "         [ 4.6841e-02, -2.1636e-01,  2.4303e-01,  ...,  6.6306e-01,\n",
      "          -6.9856e-01, -2.3070e-01],\n",
      "         [ 1.9536e-01, -2.7267e-01,  1.9395e-01,  ...,  6.6043e-01,\n",
      "          -8.9012e-01, -1.2508e-01],\n",
      "         [ 3.9899e-01, -1.8606e-01,  2.0116e-01,  ...,  6.1062e-01,\n",
      "          -7.7643e-01, -4.0493e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.8433e-03, -4.2672e-03,  1.0760e-02,  ...,  7.8080e-03,\n",
      "           1.1067e-02, -1.2050e-02],\n",
      "         [ 1.0531e-01, -1.2579e-01,  6.8524e-02,  ..., -9.8168e-03,\n",
      "          -1.4554e-01,  1.6012e-02],\n",
      "         [ 2.5623e-01,  1.7864e-02,  2.9599e-01,  ..., -5.8729e-01,\n",
      "           1.7296e-01,  1.2260e-01],\n",
      "         ...,\n",
      "         [ 4.0147e-02, -2.7437e-01,  1.9446e-01,  ...,  5.8218e-01,\n",
      "          -7.5537e-01, -1.6003e-01],\n",
      "         [ 2.1967e-01, -2.8751e-01,  1.3103e-01,  ...,  6.1229e-01,\n",
      "          -9.4073e-01, -6.3743e-03],\n",
      "         [ 4.1655e-01, -2.4288e-01,  1.2630e-01,  ...,  5.2148e-01,\n",
      "          -8.0317e-01,  7.2026e-02]],\n",
      "\n",
      "        [[-2.5338e-03, -3.6328e-03,  1.0910e-02,  ...,  7.6838e-03,\n",
      "           1.1411e-02, -1.2817e-02],\n",
      "         [ 8.2417e-02, -1.2310e-01,  8.0220e-02,  ..., -1.8743e-02,\n",
      "          -1.3512e-01,  9.8149e-03],\n",
      "         [-2.6425e-01, -3.4490e-02,  1.3560e-01,  ...,  5.0382e-02,\n",
      "           1.9419e-01,  5.1674e-01],\n",
      "         ...,\n",
      "         [-4.9238e-02, -3.4604e-01,  2.7326e-01,  ...,  6.4564e-01,\n",
      "          -8.6659e-01, -2.6584e-01],\n",
      "         [ 9.7096e-02, -3.2422e-01,  2.5783e-01,  ...,  6.5841e-01,\n",
      "          -1.0269e+00, -1.0839e-01],\n",
      "         [ 3.4682e-01, -2.5544e-01,  2.3618e-01,  ...,  5.4397e-01,\n",
      "          -9.2919e-01, -6.4867e-02]],\n",
      "\n",
      "        [[-2.7980e-03, -3.6718e-03,  1.0935e-02,  ...,  7.1234e-03,\n",
      "           1.2129e-02, -1.2845e-02],\n",
      "         [ 8.7127e-02, -1.1698e-01,  8.4068e-02,  ..., -1.0248e-02,\n",
      "          -1.2604e-01,  7.1362e-03],\n",
      "         [ 2.4441e-01,  3.9000e-01, -2.4820e-01,  ..., -7.7117e-01,\n",
      "           3.0790e-01, -2.8637e-02],\n",
      "         ...,\n",
      "         [ 6.4211e-04, -1.8346e-01,  3.8256e-01,  ...,  6.4208e-01,\n",
      "          -7.1444e-01, -2.5540e-01],\n",
      "         [ 1.4483e-01, -2.3064e-01,  3.2132e-01,  ...,  6.5005e-01,\n",
      "          -8.8288e-01, -1.2875e-01],\n",
      "         [ 3.5712e-01, -1.3048e-01,  3.0610e-01,  ...,  6.0794e-01,\n",
      "          -7.8697e-01, -4.1560e-02]]]), tensor([[[ 1.2933e-02, -4.1641e-03, -8.8017e-03,  ...,  2.2942e-02,\n",
      "           6.6053e-03, -4.0118e-02],\n",
      "         [ 1.7580e-02, -6.6577e-03, -1.9672e-03,  ...,  2.6604e-02,\n",
      "           4.7835e-03, -4.0678e-02],\n",
      "         [-3.2006e-01,  6.2728e-01, -1.4839e-01,  ..., -2.7435e-01,\n",
      "           2.9688e-01, -1.1709e-01],\n",
      "         ...,\n",
      "         [-8.5442e-02, -2.4529e-01,  8.4214e-02,  ...,  4.1140e-01,\n",
      "          -5.9929e-01, -4.5551e-02],\n",
      "         [-1.0343e-01, -2.3831e-01,  2.7123e-02,  ...,  3.0978e-01,\n",
      "          -6.4595e-01,  1.0671e-02],\n",
      "         [-5.0804e-03, -2.1629e-01, -3.3578e-02,  ...,  2.2362e-01,\n",
      "          -5.8641e-01, -5.8897e-02]],\n",
      "\n",
      "        [[ 1.3073e-02, -4.4141e-03, -8.9519e-03,  ...,  2.2898e-02,\n",
      "           6.3859e-03, -3.9830e-02],\n",
      "         [ 1.8842e-02, -6.9789e-03,  1.8568e-04,  ...,  2.7269e-02,\n",
      "           4.8258e-03, -3.5714e-02],\n",
      "         [-5.7580e-02,  2.3195e-01,  1.9335e-01,  ..., -1.6495e-01,\n",
      "          -2.5505e-01, -2.7165e-01],\n",
      "         ...,\n",
      "         [-2.1107e-01, -2.0511e-01,  2.2023e-01,  ...,  3.9387e-01,\n",
      "          -3.3925e-01,  1.0340e-02],\n",
      "         [-2.4147e-01, -2.2548e-01,  1.7101e-01,  ...,  2.9900e-01,\n",
      "          -4.1463e-01,  3.3402e-02],\n",
      "         [-1.4276e-01, -1.7913e-01,  1.5521e-01,  ...,  2.3955e-01,\n",
      "          -3.7957e-01, -9.5585e-02]],\n",
      "\n",
      "        [[ 1.3047e-02, -4.4679e-03, -8.8822e-03,  ...,  2.3257e-02,\n",
      "           6.7900e-03, -4.0445e-02],\n",
      "         [ 1.9068e-02, -7.7556e-03,  3.8142e-05,  ...,  2.6485e-02,\n",
      "           6.3309e-03, -3.8184e-02],\n",
      "         [-1.9561e-02,  8.0853e-01,  1.2077e+00,  ..., -1.2524e-01,\n",
      "          -1.6656e-01,  2.5996e-01],\n",
      "         ...,\n",
      "         [-2.3184e-01, -9.9619e-02,  5.4420e-02,  ...,  1.2018e-01,\n",
      "          -3.3313e-01, -4.4149e-03],\n",
      "         [-2.1046e-01, -1.4215e-01,  6.2719e-02,  ...,  7.4200e-02,\n",
      "          -4.1267e-01,  3.2813e-02],\n",
      "         [-1.5623e-01, -1.4162e-01, -3.6608e-02,  ...,  1.8111e-02,\n",
      "          -4.0715e-01, -6.1504e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.2825e-02, -4.2811e-03, -8.9566e-03,  ...,  2.3040e-02,\n",
      "           6.5253e-03, -4.0259e-02],\n",
      "         [ 1.9407e-02, -7.7268e-03, -2.8337e-03,  ...,  2.8743e-02,\n",
      "           4.6954e-03, -3.8463e-02],\n",
      "         [ 6.1159e-02,  2.2679e-02,  1.4610e-01,  ..., -3.8763e-01,\n",
      "           4.2716e-01,  3.7754e-01],\n",
      "         ...,\n",
      "         [-3.6790e-01, -5.5043e-03,  3.0892e-03,  ...,  4.2474e-01,\n",
      "          -4.7656e-01,  1.8679e-01],\n",
      "         [-3.4926e-01, -1.4375e-02, -8.3386e-02,  ...,  3.5761e-01,\n",
      "          -5.5163e-01,  2.2457e-01],\n",
      "         [-2.7519e-01, -7.0657e-02, -1.3778e-01,  ...,  2.6614e-01,\n",
      "          -5.1467e-01,  1.6920e-01]],\n",
      "\n",
      "        [[ 1.3432e-02, -4.5186e-03, -8.8623e-03,  ...,  2.3159e-02,\n",
      "           6.5203e-03, -3.9973e-02],\n",
      "         [ 1.8517e-02, -6.4028e-03, -1.1410e-03,  ...,  2.6670e-02,\n",
      "           4.5015e-03, -3.8494e-02],\n",
      "         [-1.4154e-01, -2.2733e-01,  2.3653e-01,  ..., -4.1095e-02,\n",
      "           2.4115e-01,  2.6711e-01],\n",
      "         ...,\n",
      "         [-2.1777e-01, -1.9422e-01,  2.3131e-01,  ...,  5.1731e-01,\n",
      "          -6.0854e-01,  1.9837e-01],\n",
      "         [-2.5115e-01, -1.8486e-01,  2.0542e-01,  ...,  4.2749e-01,\n",
      "          -6.7203e-01,  2.5702e-01],\n",
      "         [-1.7814e-01, -1.3963e-01,  1.7338e-01,  ...,  3.2910e-01,\n",
      "          -6.2161e-01,  1.6177e-01]],\n",
      "\n",
      "        [[ 1.3132e-02, -4.2187e-03, -8.8662e-03,  ...,  2.3206e-02,\n",
      "           6.5834e-03, -4.0637e-02],\n",
      "         [ 1.5483e-02, -7.5445e-03, -6.3021e-04,  ...,  2.7011e-02,\n",
      "           7.2188e-03, -3.4923e-02],\n",
      "         [ 2.1057e-01,  3.4594e-01, -9.6609e-02,  ..., -5.3328e-01,\n",
      "           2.0719e-01,  1.9996e-01],\n",
      "         ...,\n",
      "         [-3.7777e-01, -8.0991e-02,  1.8790e-01,  ...,  1.5678e-01,\n",
      "          -1.4975e-01, -1.1733e-01],\n",
      "         [-3.4558e-01, -1.1022e-01,  1.9601e-01,  ...,  6.1728e-02,\n",
      "          -1.9542e-01, -1.1045e-01],\n",
      "         [-3.2776e-01, -6.4904e-02,  7.8379e-02,  ..., -1.3968e-02,\n",
      "          -2.1129e-01, -1.7312e-01]]]), tensor([[[ 4.8966e-03, -1.1674e-02, -1.6678e-02,  ...,  7.8910e-03,\n",
      "          -3.6389e-02, -9.1774e-03],\n",
      "         [-3.5636e-03,  3.8312e-02, -1.8706e-02,  ...,  1.5347e-02,\n",
      "           1.1362e-01,  2.9074e-03],\n",
      "         [-4.0345e-01,  7.2363e-01, -3.0450e-01,  ..., -4.0316e-01,\n",
      "           1.5828e-01, -3.6843e-01],\n",
      "         ...,\n",
      "         [-3.6802e-01, -3.7518e-01, -3.6877e-01,  ...,  2.3321e-01,\n",
      "          -8.7444e-01, -1.5000e-02],\n",
      "         [-3.7991e-01, -3.2677e-01, -3.7752e-01,  ...,  1.5629e-01,\n",
      "          -9.3001e-01,  2.0100e-02],\n",
      "         [-3.6868e-01, -3.0362e-01, -4.2231e-01,  ...,  2.8027e-02,\n",
      "          -8.4167e-01, -1.2102e-01]],\n",
      "\n",
      "        [[ 4.8520e-03, -1.1526e-02, -1.6704e-02,  ...,  8.2833e-03,\n",
      "          -3.6050e-02, -9.0938e-03],\n",
      "         [-1.0140e-02,  1.8019e-02, -1.7997e-02,  ...,  7.6434e-02,\n",
      "           9.9491e-02, -7.2284e-03],\n",
      "         [ 4.7185e-02,  3.1138e-01,  4.4140e-02,  ...,  1.5095e-01,\n",
      "           1.8687e-01, -5.1289e-01],\n",
      "         ...,\n",
      "         [-5.0517e-01, -2.1578e-01, -2.2747e-01,  ...,  4.1705e-02,\n",
      "          -5.1247e-01, -3.2279e-01],\n",
      "         [-4.6477e-01, -2.1440e-01, -2.3669e-01,  ..., -1.0986e-02,\n",
      "          -6.0514e-01, -2.7180e-01],\n",
      "         [-4.8205e-01, -1.8366e-01, -2.4515e-01,  ..., -5.5286e-02,\n",
      "          -5.4119e-01, -3.7776e-01]],\n",
      "\n",
      "        [[ 5.1385e-03, -1.1698e-02, -1.7125e-02,  ...,  8.1969e-03,\n",
      "          -3.6454e-02, -9.2480e-03],\n",
      "         [ 3.1782e-03, -1.0160e-03, -2.2444e-03,  ...,  2.4178e-02,\n",
      "           1.2261e-01,  9.7150e-03],\n",
      "         [-1.3563e-01,  7.4177e-01,  9.1669e-01,  ...,  9.7367e-02,\n",
      "          -9.2329e-02,  2.0908e-01],\n",
      "         ...,\n",
      "         [-4.3380e-01, -1.7022e-01, -1.9637e-01,  ...,  5.6637e-02,\n",
      "          -5.8060e-01, -1.2380e-02],\n",
      "         [-4.3478e-01, -1.9553e-01, -1.8658e-01,  ...,  7.1062e-02,\n",
      "          -6.6438e-01,  1.3411e-02],\n",
      "         [-4.1282e-01, -1.6532e-01, -2.3722e-01,  ..., -2.2163e-02,\n",
      "          -6.6584e-01, -4.3009e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.8304e-03, -1.1803e-02, -1.6433e-02,  ...,  7.9782e-03,\n",
      "          -3.6491e-02, -9.2164e-03],\n",
      "         [ 6.2787e-02,  3.4420e-02,  4.3138e-02,  ..., -2.7456e-03,\n",
      "           1.5783e-01,  6.4267e-04],\n",
      "         [ 2.8437e-01, -9.6406e-02,  2.1571e-01,  ..., -2.3571e-01,\n",
      "           5.2386e-01,  2.6453e-01],\n",
      "         ...,\n",
      "         [-6.5424e-01, -1.1008e-01, -3.1383e-01,  ...,  2.1263e-02,\n",
      "          -6.5172e-01, -1.4165e-01],\n",
      "         [-5.8400e-01, -8.6783e-02, -3.5318e-01,  ..., -1.6653e-02,\n",
      "          -6.7806e-01, -1.1936e-01],\n",
      "         [-5.6143e-01, -1.3495e-01, -3.7329e-01,  ..., -7.7678e-02,\n",
      "          -6.4778e-01, -2.0710e-01]],\n",
      "\n",
      "        [[ 4.9905e-03, -1.1694e-02, -1.6677e-02,  ...,  7.9906e-03,\n",
      "          -3.6564e-02, -9.0872e-03],\n",
      "         [-1.7205e-02, -2.1765e-02,  3.1419e-04,  ...,  6.6990e-02,\n",
      "           8.6178e-02,  6.1128e-02],\n",
      "         [ 1.4786e-01, -2.7210e-01,  3.9295e-01,  ..., -1.8871e-01,\n",
      "           4.0001e-01, -8.7407e-02],\n",
      "         ...,\n",
      "         [-4.3090e-01, -2.0212e-01, -2.2082e-01,  ...,  2.0402e-01,\n",
      "          -5.9730e-01, -3.1822e-01],\n",
      "         [-3.6501e-01, -1.5150e-01, -2.1434e-01,  ...,  1.1735e-01,\n",
      "          -6.6605e-01, -2.4516e-01],\n",
      "         [-4.1689e-01, -1.3279e-01, -2.4531e-01,  ...,  6.2577e-02,\n",
      "          -6.1305e-01, -3.6731e-01]],\n",
      "\n",
      "        [[ 4.7881e-03, -1.1784e-02, -1.6535e-02,  ...,  8.3153e-03,\n",
      "          -3.6315e-02, -9.1591e-03],\n",
      "         [-7.6815e-03,  4.3947e-02,  5.1480e-02,  ..., -2.4509e-03,\n",
      "           1.2879e-01, -4.3913e-02],\n",
      "         [ 3.4116e-01,  4.8705e-01, -1.7690e-01,  ..., -6.0898e-01,\n",
      "           6.3430e-01, -3.4723e-01],\n",
      "         ...,\n",
      "         [-3.1624e-01, -3.8414e-01, -1.8052e-02,  ...,  1.0601e-01,\n",
      "          -5.0363e-01, -3.6207e-01],\n",
      "         [-2.9419e-01, -3.8758e-01,  1.8127e-02,  ...,  9.9513e-02,\n",
      "          -6.1696e-01, -3.6006e-01],\n",
      "         [-2.7695e-01, -3.4214e-01, -7.6129e-02,  ...,  3.4262e-03,\n",
      "          -5.6207e-01, -4.3173e-01]]]), tensor([[[ 1.0585e-02, -1.4943e-03, -4.4730e-03,  ...,  9.4874e-03,\n",
      "          -4.1568e-01, -5.6901e-03],\n",
      "         [-1.1507e-01,  4.5113e-02, -4.0833e-01,  ..., -7.2363e-05,\n",
      "          -6.4735e-01,  1.6696e-01],\n",
      "         [-5.1597e-01,  5.9216e-01, -8.3873e-03,  ..., -1.6969e-01,\n",
      "          -3.8608e-01, -4.0996e-01],\n",
      "         ...,\n",
      "         [-5.6839e-01, -7.0628e-01, -5.6047e-01,  ...,  2.6442e-01,\n",
      "          -6.1082e-01,  2.1711e-01],\n",
      "         [-5.5705e-01, -6.8135e-01, -5.7904e-01,  ...,  1.6061e-01,\n",
      "          -6.0484e-01,  2.0628e-01],\n",
      "         [-5.3059e-01, -6.2155e-01, -6.4651e-01,  ...,  7.6721e-02,\n",
      "          -5.7260e-01,  7.7254e-02]],\n",
      "\n",
      "        [[ 1.0786e-02, -1.2520e-03, -4.3027e-03,  ...,  9.4254e-03,\n",
      "          -4.1566e-01, -5.4727e-03],\n",
      "         [-1.3888e-01,  2.0732e-02, -4.5002e-01,  ...,  1.0044e-01,\n",
      "          -6.6982e-01,  1.4689e-01],\n",
      "         [-8.2632e-02,  2.4506e-01, -1.3602e-01,  ...,  1.9111e-01,\n",
      "          -4.6734e-01, -3.8787e-01],\n",
      "         ...,\n",
      "         [-5.4512e-01, -4.0557e-01, -4.6755e-01,  ...,  2.9203e-01,\n",
      "          -4.5903e-01, -7.3795e-02],\n",
      "         [-5.4370e-01, -4.1132e-01, -4.9289e-01,  ...,  2.4736e-01,\n",
      "          -4.6668e-01, -4.6686e-02],\n",
      "         [-5.3854e-01, -3.6368e-01, -5.3694e-01,  ...,  1.5756e-01,\n",
      "          -4.3984e-01, -1.5557e-01]],\n",
      "\n",
      "        [[ 1.0419e-02, -1.1781e-03, -4.6602e-03,  ...,  9.4046e-03,\n",
      "          -4.1572e-01, -5.8368e-03],\n",
      "         [-1.2798e-01,  6.9648e-02, -2.4785e-01,  ...,  9.5435e-02,\n",
      "          -6.8153e-01,  2.8922e-01],\n",
      "         [ 3.5224e-02,  8.9098e-01,  9.2125e-01,  ...,  1.1565e-01,\n",
      "          -4.9097e-01,  1.6987e-01],\n",
      "         ...,\n",
      "         [-3.7054e-01, -4.3702e-01, -3.3425e-01,  ...,  8.2165e-02,\n",
      "          -5.0448e-01,  1.2530e-01],\n",
      "         [-3.7836e-01, -4.5652e-01, -3.2818e-01,  ...,  9.0096e-02,\n",
      "          -5.1628e-01,  1.4001e-01],\n",
      "         [-3.7433e-01, -4.0442e-01, -3.8634e-01,  ...,  2.2608e-02,\n",
      "          -5.0594e-01,  9.6614e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0661e-02, -1.2299e-03, -4.4285e-03,  ...,  9.3492e-03,\n",
      "          -4.1574e-01, -5.8104e-03],\n",
      "         [-9.0054e-02, -7.9266e-04, -3.6588e-01,  ..., -4.3530e-03,\n",
      "          -6.3785e-01,  1.7021e-01],\n",
      "         [ 1.6129e-01, -6.4305e-02, -6.9006e-03,  ..., -3.7205e-01,\n",
      "          -3.8297e-01,  1.1552e-01],\n",
      "         ...,\n",
      "         [-6.9185e-01, -3.8840e-01, -5.4076e-01,  ...,  1.6264e-01,\n",
      "          -4.5651e-01,  5.6987e-02],\n",
      "         [-5.8445e-01, -3.3965e-01, -5.8081e-01,  ...,  9.8591e-02,\n",
      "          -4.5438e-01,  6.7275e-02],\n",
      "         [-5.8478e-01, -3.5625e-01, -6.1810e-01,  ...,  6.8202e-03,\n",
      "          -4.4061e-01, -2.9258e-02]],\n",
      "\n",
      "        [[ 1.0468e-02, -1.2041e-03, -4.6152e-03,  ...,  9.2344e-03,\n",
      "          -4.1570e-01, -5.7017e-03],\n",
      "         [-9.8916e-02,  2.8462e-02, -2.5627e-01,  ...,  8.9861e-02,\n",
      "          -6.8596e-01,  2.8541e-01],\n",
      "         [ 3.5326e-01, -1.1538e-01,  3.6926e-01,  ..., -1.4961e-01,\n",
      "          -4.2786e-01, -8.6723e-02],\n",
      "         ...,\n",
      "         [-5.3802e-01, -4.4640e-01, -3.5707e-01,  ...,  3.1128e-01,\n",
      "          -4.1843e-01, -9.9667e-02],\n",
      "         [-4.9206e-01, -3.8298e-01, -3.4782e-01,  ...,  1.6872e-01,\n",
      "          -4.1695e-01, -7.2864e-02],\n",
      "         [-5.2103e-01, -3.5651e-01, -4.2368e-01,  ...,  1.2701e-01,\n",
      "          -4.0417e-01, -1.6703e-01]],\n",
      "\n",
      "        [[ 1.0867e-02, -1.5301e-03, -4.3392e-03,  ...,  9.4361e-03,\n",
      "          -4.1567e-01, -5.4771e-03],\n",
      "         [-1.4393e-01,  1.8233e-02, -2.2249e-01,  ...,  7.4291e-03,\n",
      "          -6.3397e-01, -1.9939e-02],\n",
      "         [ 6.4656e-01,  5.6867e-01, -2.4198e-01,  ..., -4.2165e-01,\n",
      "          -3.3022e-01, -3.3395e-01],\n",
      "         ...,\n",
      "         [-4.7832e-01, -6.4225e-01,  4.7387e-02,  ..., -1.3359e-01,\n",
      "          -4.6080e-01, -6.2529e-01],\n",
      "         [-4.6473e-01, -6.6576e-01,  7.5708e-02,  ..., -1.6422e-01,\n",
      "          -4.8644e-01, -5.9917e-01],\n",
      "         [-4.7583e-01, -6.1142e-01, -3.7764e-02,  ..., -2.1521e-01,\n",
      "          -4.5483e-01, -7.1925e-01]]]), tensor([[[ 2.0213e-04, -1.3040e-02, -8.0120e-03,  ..., -1.7208e-02,\n",
      "          -6.9002e-02, -2.5203e-02],\n",
      "         [ 6.0620e-02,  2.0980e-01, -1.8038e-01,  ..., -8.2346e-02,\n",
      "          -5.1082e-01,  1.7469e-01],\n",
      "         [-2.7549e-01,  5.4619e-01,  1.4391e-01,  ..., -2.0002e-01,\n",
      "          -2.8021e-01, -6.0860e-02],\n",
      "         ...,\n",
      "         [-5.9495e-01, -3.2014e-01, -5.2668e-01,  ...,  3.8741e-01,\n",
      "          -2.2206e-01,  6.1623e-01],\n",
      "         [-6.0604e-01, -2.8462e-01, -5.5555e-01,  ...,  3.0373e-01,\n",
      "          -2.0312e-01,  6.2699e-01],\n",
      "         [-5.4771e-01, -2.4313e-01, -5.8596e-01,  ...,  2.3075e-01,\n",
      "          -1.9163e-01,  5.3825e-01]],\n",
      "\n",
      "        [[ 1.2595e-03, -1.3133e-02, -8.3883e-03,  ..., -1.5876e-02,\n",
      "          -6.8855e-02, -2.4642e-02],\n",
      "         [ 2.2455e-02,  1.3438e-01, -3.5431e-01,  ...,  5.8036e-02,\n",
      "          -4.9200e-01,  2.1186e-01],\n",
      "         [ 1.1543e-01,  3.0218e-01, -2.9117e-01,  ...,  1.5393e-01,\n",
      "          -3.1967e-01, -1.1368e-01],\n",
      "         ...,\n",
      "         [-4.9010e-01, -9.8152e-02, -4.3657e-01,  ...,  4.7666e-01,\n",
      "          -9.9187e-02,  2.8951e-01],\n",
      "         [-4.7686e-01, -8.3144e-02, -4.4714e-01,  ...,  4.4913e-01,\n",
      "          -9.2926e-02,  3.3801e-01],\n",
      "         [-4.6146e-01, -6.1550e-02, -4.9540e-01,  ...,  3.7142e-01,\n",
      "          -6.1782e-02,  2.7972e-01]],\n",
      "\n",
      "        [[ 1.1441e-03, -1.3460e-02, -8.7797e-03,  ..., -1.5696e-02,\n",
      "          -6.9031e-02, -2.3609e-02],\n",
      "         [ 1.3071e-01,  3.5614e-01, -1.7032e-01,  ...,  1.2067e-01,\n",
      "          -4.6451e-01,  1.0008e-01],\n",
      "         [ 2.0537e-01,  1.0457e+00,  9.2212e-01,  ...,  3.0538e-01,\n",
      "          -3.7449e-01,  1.3719e-01],\n",
      "         ...,\n",
      "         [-4.8380e-01, -6.6980e-02, -3.4834e-01,  ...,  2.4470e-01,\n",
      "          -2.2100e-01,  5.4660e-01],\n",
      "         [-4.9330e-01, -7.9292e-02, -3.3284e-01,  ...,  2.5372e-01,\n",
      "          -2.1365e-01,  6.0101e-01],\n",
      "         [-5.0731e-01, -4.1907e-02, -3.6793e-01,  ...,  1.8897e-01,\n",
      "          -2.0568e-01,  5.2874e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.5082e-04, -1.3267e-02, -8.2613e-03,  ..., -1.6638e-02,\n",
      "          -6.8943e-02, -2.4790e-02],\n",
      "         [ 4.7245e-02,  8.8658e-02, -2.8164e-01,  ..., -1.2131e-01,\n",
      "          -5.2841e-01,  1.3887e-01],\n",
      "         [ 3.3893e-01, -7.4103e-02, -8.6719e-02,  ..., -2.6444e-01,\n",
      "          -2.3187e-01,  6.7941e-02],\n",
      "         ...,\n",
      "         [-6.9999e-01,  1.5246e-02, -6.2937e-01,  ...,  3.4137e-01,\n",
      "          -1.0642e-01,  3.9772e-01],\n",
      "         [-6.3073e-01,  6.7685e-02, -6.7185e-01,  ...,  2.8419e-01,\n",
      "          -9.2023e-02,  4.0875e-01],\n",
      "         [-6.2361e-01,  4.9218e-02, -6.7369e-01,  ...,  2.0364e-01,\n",
      "          -6.3289e-02,  3.1231e-01]],\n",
      "\n",
      "        [[ 7.8312e-04, -1.3021e-02, -8.1818e-03,  ..., -1.6596e-02,\n",
      "          -6.8975e-02, -2.3943e-02],\n",
      "         [ 1.1984e-01,  2.7723e-01, -1.6730e-01,  ...,  1.9470e-01,\n",
      "          -4.7939e-01,  2.4324e-01],\n",
      "         [ 4.4454e-01,  7.1691e-02,  2.8742e-01,  ..., -2.1169e-01,\n",
      "          -1.6188e-01, -1.1986e-01],\n",
      "         ...,\n",
      "         [-5.4342e-01, -1.2676e-01, -3.5263e-01,  ...,  4.0645e-01,\n",
      "           1.1220e-02,  2.5528e-01],\n",
      "         [-5.3717e-01, -6.4293e-02, -3.7597e-01,  ...,  2.8778e-01,\n",
      "           3.8077e-02,  2.9829e-01],\n",
      "         [-5.2478e-01, -6.5376e-02, -3.9292e-01,  ...,  2.6484e-01,\n",
      "           3.9879e-02,  2.6358e-01]],\n",
      "\n",
      "        [[ 1.0664e-03, -1.3748e-02, -8.4428e-03,  ..., -1.6779e-02,\n",
      "          -6.9181e-02, -2.4762e-02],\n",
      "         [-1.1646e-02,  7.5527e-02, -7.1701e-02,  ..., -1.3128e-01,\n",
      "          -3.8379e-01,  2.5709e-01],\n",
      "         [ 7.0822e-01,  6.0976e-01, -3.3515e-01,  ..., -3.0832e-01,\n",
      "          -9.3389e-02, -1.6902e-01],\n",
      "         ...,\n",
      "         [-6.1661e-01, -4.1179e-01, -1.6944e-01,  ..., -8.3697e-02,\n",
      "          -1.4477e-01, -8.7501e-02],\n",
      "         [-6.2507e-01, -4.3497e-01, -1.5082e-01,  ..., -1.0928e-01,\n",
      "          -1.4851e-01, -5.5376e-02],\n",
      "         [-6.1825e-01, -3.7006e-01, -2.4699e-01,  ..., -1.5042e-01,\n",
      "          -1.2139e-01, -1.0273e-01]]]), tensor([[[ 2.3006,  2.6213,  1.3226,  ...,  1.6454,  0.1663, -0.6781],\n",
      "         [ 0.4999,  0.2036,  0.5019,  ...,  0.8640, -0.1887,  0.3510],\n",
      "         [-0.6206,  2.2243,  1.0307,  ..., -0.5662, -1.3982,  1.0684],\n",
      "         ...,\n",
      "         [ 0.0217, -1.1611,  0.5753,  ..., -0.0468,  1.4612,  1.0967],\n",
      "         [-0.0392, -1.0853,  0.4828,  ..., -0.1402,  1.6380,  1.0221],\n",
      "         [ 0.2242, -1.0564,  0.4836,  ..., -0.2492,  1.7843,  0.8561]],\n",
      "\n",
      "        [[ 2.8028,  2.7222,  1.1821,  ...,  2.3798, -0.1493, -0.1707],\n",
      "         [ 0.3893, -1.1454, -0.1824,  ...,  0.7556,  0.1157,  0.7297],\n",
      "         [ 0.3394, -0.0852, -0.6636,  ...,  0.2194,  1.4046,  1.0707],\n",
      "         ...,\n",
      "         [ 0.3385, -0.6735,  0.4424,  ...,  1.0259,  3.1451,  0.0603],\n",
      "         [ 0.3613, -0.6005,  0.4629,  ...,  0.9987,  3.1036,  0.0652],\n",
      "         [ 0.4626, -0.5531,  0.3222,  ...,  0.8437,  3.2544,  0.0354]],\n",
      "\n",
      "        [[ 3.0024,  2.3109,  1.4562,  ...,  1.6568,  0.0100, -0.2238],\n",
      "         [-0.8540,  0.6157,  0.8918,  ...,  0.5007, -0.5031,  0.9520],\n",
      "         [ 0.7699,  3.5724,  2.6252,  ...,  1.8216, -0.5675,  0.0990],\n",
      "         ...,\n",
      "         [-0.9695, -0.1933,  0.2131,  ...,  0.3608,  1.9894,  2.2674],\n",
      "         [-1.0236, -0.3218,  0.3046,  ...,  0.4981,  2.0158,  2.2197],\n",
      "         [-0.9707, -0.2294,  0.1676,  ...,  0.3749,  2.0387,  2.0133]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.9087,  2.3964,  1.0205,  ...,  1.4720,  0.0069, -0.8811],\n",
      "         [-0.4171, -0.1377,  0.8215,  ..., -0.1174, -3.7932, -0.2922],\n",
      "         [ 0.6913, -0.4522,  0.7174,  ..., -0.6510,  0.7149,  0.8328],\n",
      "         ...,\n",
      "         [-0.8143, -0.2286, -0.3419,  ...,  0.1828,  1.8794,  0.0785],\n",
      "         [-0.6016, -0.1382, -0.3733,  ...,  0.1102,  1.9989,  0.0908],\n",
      "         [-0.5729, -0.1960, -0.3080,  ...,  0.0115,  2.1140, -0.0393]],\n",
      "\n",
      "        [[ 2.7602,  2.5611,  1.2364,  ...,  1.9141,  0.2384, -0.5066],\n",
      "         [ 0.9406, -0.1878,  0.8476,  ...,  1.0537,  0.9144,  1.0364],\n",
      "         [ 2.1052,  1.0866,  0.6002,  ..., -0.3008,  1.1743,  0.3062],\n",
      "         ...,\n",
      "         [-0.5927,  0.2701,  0.7314,  ...,  0.3119,  2.4681, -0.4368],\n",
      "         [-0.5271,  0.4318,  0.6293,  ...,  0.1541,  2.6687, -0.3034],\n",
      "         [-0.4474,  0.3440,  0.6082,  ...,  0.0846,  2.5060, -0.3144]],\n",
      "\n",
      "        [[ 2.8367,  2.5320,  1.7529,  ...,  1.5691,  0.1584, -0.7445],\n",
      "         [ 0.8722, -0.7697,  1.6551,  ..., -0.6838, -0.9896,  1.0037],\n",
      "         [ 2.2618,  3.2115, -0.6348,  ..., -1.3560,  1.3438,  0.3704],\n",
      "         ...,\n",
      "         [-1.5893, -1.2352,  0.9632,  ..., -0.3545,  2.8833, -0.1707],\n",
      "         [-1.5452, -1.1425,  0.9347,  ..., -0.4526,  2.9785, -0.2039],\n",
      "         [-1.4367, -1.2075,  0.7830,  ..., -0.5355,  3.0660, -0.1618]]])), decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-3.7235e-02,  8.1542e-03, -1.3527e-03,  ...,  1.1891e-02,\n",
      "          -1.6380e-03, -1.4861e-02],\n",
      "         [ 2.4835e-02,  3.4918e-01,  4.5128e-01,  ..., -4.6674e-01,\n",
      "          -1.5290e-01,  2.5953e-02],\n",
      "         [-3.7211e-01, -4.0502e-02,  8.1073e-02,  ..., -1.9474e-01,\n",
      "          -1.6444e-01,  7.6535e-02],\n",
      "         ...,\n",
      "         [ 1.9765e-01,  1.1269e-01,  5.8597e-02,  ...,  2.0695e-01,\n",
      "           4.8123e-01,  3.7356e-02],\n",
      "         [ 1.0558e-01,  1.5402e-01, -1.7335e-02,  ...,  1.1963e-01,\n",
      "           3.7779e-01, -5.0927e-02],\n",
      "         [ 5.1015e-02,  2.4712e-01, -4.0377e-02,  ...,  6.8139e-02,\n",
      "           2.6082e-01, -8.5279e-02]],\n",
      "\n",
      "        [[-3.6576e-02,  1.0526e-02, -1.4600e-03,  ...,  1.2379e-02,\n",
      "          -2.1449e-03, -1.2331e-02],\n",
      "         [ 6.2180e-02,  3.6709e-01,  4.1201e-01,  ..., -4.2919e-01,\n",
      "          -5.6278e-02,  1.0628e-01],\n",
      "         [-3.2559e-01,  4.4229e-02,  4.9966e-02,  ..., -1.5652e-01,\n",
      "          -8.8720e-02,  7.3068e-02],\n",
      "         ...,\n",
      "         [ 7.8774e-02,  1.5810e-01,  4.6244e-02,  ..., -2.3329e-02,\n",
      "           2.0875e-01, -7.0495e-03],\n",
      "         [ 6.2422e-02,  1.2203e-01,  3.7049e-02,  ..., -3.3195e-03,\n",
      "           1.4107e-01, -3.9257e-02],\n",
      "         [ 5.3137e-02,  1.1233e-01,  2.6811e-02,  ..., -1.7359e-02,\n",
      "           1.3386e-01, -7.4425e-02]],\n",
      "\n",
      "        [[-3.6490e-02,  7.9414e-03, -9.3970e-04,  ...,  1.1303e-02,\n",
      "          -3.2149e-04, -1.5862e-02],\n",
      "         [-1.9260e-01,  3.1482e-01,  2.9044e-01,  ..., -2.8045e-01,\n",
      "          -1.1530e-01,  3.5499e-01],\n",
      "         [ 4.8746e-02,  1.6123e-01,  6.7186e-02,  ..., -1.9046e-01,\n",
      "          -4.9584e-02,  1.8775e-01],\n",
      "         ...,\n",
      "         [ 7.0582e-02,  1.4136e-01, -3.3076e-02,  ...,  1.5669e-02,\n",
      "           9.8290e-02, -4.9653e-03],\n",
      "         [ 5.3133e-02,  1.4068e-01, -3.3051e-02,  ...,  3.4082e-03,\n",
      "           1.1081e-01, -3.4460e-02],\n",
      "         [ 9.2120e-02,  1.1603e-01, -1.2473e-01,  ...,  9.7656e-03,\n",
      "           2.9256e-01, -7.4455e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.6752e-02,  9.9508e-03, -6.8104e-04,  ...,  1.1369e-02,\n",
      "          -1.7645e-03, -1.3769e-02],\n",
      "         [ 1.6554e-01, -1.6670e-01,  3.3819e-01,  ..., -5.5318e-01,\n",
      "          -4.9793e-01,  1.1653e-01],\n",
      "         [-3.1584e-02,  7.3456e-02,  9.2152e-02,  ..., -3.1608e-01,\n",
      "          -2.8408e-01, -1.1483e-01],\n",
      "         ...,\n",
      "         [ 2.3135e-02,  1.9391e-01,  6.2510e-03,  ...,  2.2865e-03,\n",
      "           1.1600e-01, -5.8778e-02],\n",
      "         [ 6.2397e-02,  2.4464e-01, -4.5243e-02,  ...,  4.9608e-04,\n",
      "           2.2251e-01,  2.6583e-02],\n",
      "         [ 1.2893e-01,  2.3392e-01, -3.7631e-02,  ..., -1.2027e-02,\n",
      "           2.9862e-01,  7.4518e-02]],\n",
      "\n",
      "        [[-3.7299e-02,  8.5531e-03, -2.0997e-03,  ...,  1.1007e-02,\n",
      "          -1.0913e-03, -1.5051e-02],\n",
      "         [ 4.6963e-02,  4.2387e-01,  4.1335e-01,  ..., -5.2368e-01,\n",
      "          -1.4853e-01, -8.1937e-03],\n",
      "         [-2.8226e-01,  4.9414e-02,  8.3116e-02,  ..., -1.4922e-01,\n",
      "          -2.1526e-01, -8.2774e-02],\n",
      "         ...,\n",
      "         [ 1.8378e-01,  2.1419e-01, -7.2218e-02,  ...,  6.9944e-02,\n",
      "           2.8072e-01, -9.8603e-03],\n",
      "         [ 4.9650e-02,  1.7745e-01, -7.5505e-03,  ...,  2.3934e-02,\n",
      "           6.3067e-02, -4.9322e-02],\n",
      "         [ 2.5826e-01,  2.6106e-01,  6.3293e-03,  ..., -7.9971e-04,\n",
      "           2.3242e-01,  9.5698e-02]],\n",
      "\n",
      "        [[-3.6137e-02,  9.8568e-03, -2.3142e-03,  ...,  1.2413e-02,\n",
      "          -1.9899e-03, -1.2170e-02],\n",
      "         [-2.0230e-02, -3.8355e-01,  4.0208e-01,  ..., -3.4390e-01,\n",
      "           4.9255e-02, -1.8466e-02],\n",
      "         [ 6.6516e-01, -5.9350e-02,  4.2499e-01,  ..., -2.4551e-01,\n",
      "           4.4081e-02,  1.3745e-01],\n",
      "         ...,\n",
      "         [ 1.1658e-01,  1.0918e-01,  6.3575e-02,  ...,  1.1055e-01,\n",
      "           2.5185e-01,  1.8746e-01],\n",
      "         [ 1.5055e-03,  1.2658e-01, -2.8923e-03,  ...,  6.5025e-02,\n",
      "           3.0038e-01,  4.2531e-02],\n",
      "         [ 9.1361e-02,  6.3858e-02, -8.6595e-02,  ...,  1.5292e-01,\n",
      "           4.1763e-01, -6.8470e-03]]]), encoder_hidden_states=(tensor([[[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.6842,  0.0244,  0.5646,  ..., -0.2659, -0.1468, -0.3223],\n",
      "         [-0.3948, -0.1109,  0.3872,  ..., -0.2016, -0.0933,  0.0181],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.6842,  0.0244,  0.5646,  ..., -0.2659, -0.1468, -0.3223],\n",
      "         [-0.3948, -0.1109,  0.3872,  ..., -0.2016, -0.0933,  0.0181],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.0258, -0.1399,  0.0230,  ..., -0.1057, -0.2303,  0.3949],\n",
      "         [ 0.1203, -0.2499, -0.3727,  ..., -0.4963, -0.1258,  0.3642],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.1303, -0.0742,  0.2944,  ..., -0.2708, -0.8310, -0.5295],\n",
      "         [ 0.2395, -0.0750, -0.2116,  ...,  0.1829,  0.3829,  0.8363],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.6842,  0.0244,  0.5646,  ..., -0.2659, -0.1468, -0.3223],\n",
      "         [-0.3948, -0.1109,  0.3872,  ..., -0.2016, -0.0933,  0.0181],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.6324, -0.2242,  0.5170,  ...,  0.1555, -0.1574, -0.0741],\n",
      "         [ 0.9225, -0.1728,  0.6435,  ...,  0.1937,  0.0772, -0.1261],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]]]), tensor([[[-0.0202, -0.0268,  0.0509,  ...,  0.0281, -0.0305,  0.0183],\n",
      "         [ 0.5911,  0.0472,  0.6619,  ...,  0.1915,  0.0804, -0.0945],\n",
      "         [-0.3327,  0.3711,  0.0081,  ...,  0.2563, -0.2717,  0.2168],\n",
      "         ...,\n",
      "         [ 0.3661,  0.5291,  0.1012,  ...,  0.3007,  0.5348, -0.2120],\n",
      "         [ 0.4813,  0.4671,  0.0908,  ...,  0.6295,  0.5571, -0.1842],\n",
      "         [ 0.2863,  0.3115, -0.0610,  ...,  0.8490,  0.4860, -0.2164]],\n",
      "\n",
      "        [[-0.0406, -0.0235,  0.0605,  ...,  0.0242, -0.0201,  0.0202],\n",
      "         [ 0.4783,  0.1208,  0.6736,  ...,  0.2664,  0.1359, -0.0410],\n",
      "         [-0.4391,  0.2900, -0.0248,  ...,  0.2406, -0.2609,  0.2175],\n",
      "         ...,\n",
      "         [ 0.1528,  0.7017,  0.0981,  ...,  0.3639,  0.4679, -0.2351],\n",
      "         [ 0.3662,  0.6315,  0.0119,  ...,  0.5861,  0.5130, -0.1252],\n",
      "         [ 0.1642,  0.4324, -0.0395,  ...,  0.8473,  0.5083, -0.1336]],\n",
      "\n",
      "        [[-0.0450, -0.0275,  0.0478,  ...,  0.0270, -0.0241,  0.0259],\n",
      "         [-0.2944, -0.0457,  0.4293,  ...,  0.0067, -0.3321,  0.2655],\n",
      "         [ 0.0812, -0.2580, -0.2038,  ..., -0.3611, -0.1951,  0.4710],\n",
      "         ...,\n",
      "         [ 0.2904,  0.6406,  0.1208,  ...,  0.4388,  0.3643, -0.2030],\n",
      "         [ 0.2196,  0.6847,  0.1201,  ...,  0.5951,  0.3789, -0.0457],\n",
      "         [ 0.2825,  0.4052, -0.0517,  ...,  0.8240,  0.3963,  0.0606]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0514, -0.0258,  0.0534,  ...,  0.0266, -0.0237,  0.0198],\n",
      "         [ 0.3171, -0.1170,  0.1636,  ..., -0.0459, -1.2791, -0.2585],\n",
      "         [ 0.1623, -0.3430, -0.0499,  ...,  0.2770, -0.0075,  0.1034],\n",
      "         ...,\n",
      "         [ 0.1350,  0.4839,  0.0819,  ...,  0.4522,  0.4116, -0.3614],\n",
      "         [ 0.4482,  0.5423, -0.0034,  ...,  0.5535,  0.3371, -0.0608],\n",
      "         [ 0.5429,  0.3488, -0.1128,  ...,  0.6976,  0.2425,  0.2339]],\n",
      "\n",
      "        [[-0.0259, -0.0284,  0.0535,  ...,  0.0297, -0.0278,  0.0217],\n",
      "         [ 0.5625,  0.0914,  0.6747,  ...,  0.2027,  0.1103, -0.0308],\n",
      "         [-0.2600,  0.2895, -0.0231,  ...,  0.2595, -0.2951,  0.2183],\n",
      "         ...,\n",
      "         [ 0.3694,  0.6220, -0.0189,  ...,  0.4781,  0.6239, -0.2685],\n",
      "         [ 0.3454,  0.4401, -0.0940,  ...,  0.7154,  0.4822, -0.1498],\n",
      "         [ 0.5372,  0.4367, -0.1338,  ...,  0.7627,  0.3559,  0.1824]],\n",
      "\n",
      "        [[-0.0452, -0.0230,  0.0560,  ...,  0.0248, -0.0279,  0.0191],\n",
      "         [ 0.6422, -0.1727,  0.9336,  ...,  0.2353, -0.0173,  0.0314],\n",
      "         [ 1.3177,  0.2722,  0.6868,  ...,  0.4140, -0.1460, -0.0481],\n",
      "         ...,\n",
      "         [ 0.4891,  0.7299,  0.1362,  ...,  0.3954,  0.4188, -0.1258],\n",
      "         [ 0.4511,  0.5769,  0.1083,  ...,  0.5471,  0.4014, -0.0996],\n",
      "         [ 0.5500,  0.4015, -0.1396,  ...,  0.9079,  0.4988,  0.0092]]]), tensor([[[-5.8594e-02, -1.1977e-03,  3.1805e-02,  ..., -4.0100e-02,\n",
      "          -5.7330e-02,  3.0096e-03],\n",
      "         [ 6.2778e-01,  3.6348e-01,  6.5269e-01,  ..., -2.7704e-01,\n",
      "           9.1579e-02, -1.1647e-01],\n",
      "         [-6.4092e-01,  7.3752e-02,  2.6319e-01,  ...,  1.1220e-01,\n",
      "          -3.3082e-01,  2.2861e-01],\n",
      "         ...,\n",
      "         [ 3.9468e-01,  4.4624e-01,  2.2236e-01,  ...,  1.9034e-01,\n",
      "           7.8548e-01, -2.1276e-01],\n",
      "         [ 3.9629e-01,  4.1989e-01,  6.1214e-02,  ...,  3.5098e-01,\n",
      "           8.0635e-01, -1.9508e-01],\n",
      "         [ 1.9096e-01,  5.2617e-01, -7.0977e-02,  ...,  5.7719e-01,\n",
      "           7.5359e-01, -3.3812e-01]],\n",
      "\n",
      "        [[-6.8733e-02,  1.0783e-02,  3.7033e-02,  ..., -3.7364e-02,\n",
      "          -4.9532e-02,  5.1219e-03],\n",
      "         [ 5.6451e-01,  2.4651e-01,  7.2158e-01,  ..., -1.2061e-01,\n",
      "           1.6298e-01, -6.6258e-02],\n",
      "         [-6.4025e-01, -2.6427e-02,  3.4421e-01,  ...,  2.5967e-01,\n",
      "          -2.7184e-01,  1.4779e-01],\n",
      "         ...,\n",
      "         [ 8.3530e-02,  6.8333e-01,  1.1928e-01,  ...,  1.0348e-01,\n",
      "           6.7444e-01, -1.3986e-01],\n",
      "         [ 2.2468e-01,  5.8410e-01, -1.4400e-02,  ...,  2.1648e-01,\n",
      "           7.6027e-01, -1.0461e-01],\n",
      "         [ 1.1888e-01,  5.6182e-01, -3.5554e-02,  ...,  4.6850e-01,\n",
      "           7.4799e-01, -2.4278e-01]],\n",
      "\n",
      "        [[-7.1861e-02, -8.5170e-04,  3.2412e-02,  ..., -3.4721e-02,\n",
      "          -5.0944e-02,  3.2236e-04],\n",
      "         [-2.4005e-01,  4.0635e-01,  5.4951e-01,  ..., -1.1134e-01,\n",
      "           3.8812e-02,  5.1659e-01],\n",
      "         [ 1.8381e-01,  7.2420e-02, -7.3625e-02,  ..., -3.6638e-01,\n",
      "           3.5827e-02,  4.2174e-02],\n",
      "         ...,\n",
      "         [ 2.4430e-01,  5.9495e-01,  1.4885e-01,  ...,  2.0719e-01,\n",
      "           6.3658e-01, -1.9517e-01],\n",
      "         [ 1.6656e-01,  6.2778e-01,  6.7529e-03,  ...,  2.6688e-01,\n",
      "           7.0126e-01, -8.8568e-02],\n",
      "         [ 2.7327e-01,  4.6210e-01, -1.2233e-01,  ...,  4.7460e-01,\n",
      "           6.8313e-01, -1.5811e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.6117e-02,  7.1789e-03,  3.4736e-02,  ..., -2.8623e-02,\n",
      "          -4.4860e-02, -2.2458e-03],\n",
      "         [ 5.1037e-01, -6.1014e-02,  2.7344e-01,  ...,  2.2326e-01,\n",
      "          -1.2337e+00, -5.2922e-01],\n",
      "         [ 3.9147e-01, -1.2587e-01,  7.4566e-02,  ...,  1.6663e-01,\n",
      "          -1.4645e-01,  4.7881e-02],\n",
      "         ...,\n",
      "         [ 9.8638e-02,  5.7102e-01,  7.9626e-02,  ...,  3.4160e-01,\n",
      "           6.2863e-01, -3.9676e-01],\n",
      "         [ 3.5736e-01,  4.9275e-01, -1.4115e-02,  ...,  4.0560e-01,\n",
      "           6.0324e-01, -2.5645e-01],\n",
      "         [ 4.9826e-01,  5.4550e-01, -9.0078e-02,  ...,  3.9997e-01,\n",
      "           5.4749e-01,  1.2076e-01]],\n",
      "\n",
      "        [[-6.1107e-02,  3.9724e-03,  2.9037e-02,  ..., -4.3098e-02,\n",
      "          -6.1082e-02, -6.9806e-05],\n",
      "         [ 5.7864e-01,  2.6732e-01,  6.6677e-01,  ..., -2.0136e-01,\n",
      "           8.1128e-02, -3.7998e-02],\n",
      "         [-3.5014e-01,  1.3726e-01,  2.6188e-01,  ...,  2.3025e-01,\n",
      "          -3.7579e-01,  2.0420e-01],\n",
      "         ...,\n",
      "         [ 4.2413e-01,  3.7967e-01,  8.9859e-02,  ...,  2.4082e-01,\n",
      "           8.2259e-01, -3.2107e-01],\n",
      "         [ 3.1070e-01,  3.4683e-01, -3.8539e-02,  ...,  3.8180e-01,\n",
      "           6.6546e-01, -1.5721e-01],\n",
      "         [ 5.5774e-01,  5.1800e-01, -6.1755e-03,  ...,  4.4103e-01,\n",
      "           5.5738e-01, -1.3110e-01]],\n",
      "\n",
      "        [[-6.3546e-02,  7.5144e-03,  3.2923e-02,  ..., -3.7748e-02,\n",
      "          -5.6089e-02, -5.6596e-03],\n",
      "         [ 6.2075e-01, -2.4617e-01,  1.0048e+00,  ...,  2.2181e-01,\n",
      "           1.6357e-01,  1.0069e-01],\n",
      "         [ 1.4369e+00,  3.0098e-01,  5.8650e-01,  ..., -3.6604e-02,\n",
      "          -1.1887e-01,  1.1748e-01],\n",
      "         ...,\n",
      "         [ 5.1614e-01,  6.0769e-01,  2.2157e-01,  ...,  2.7873e-01,\n",
      "           6.6365e-01, -2.3698e-01],\n",
      "         [ 4.1478e-01,  5.6645e-01,  8.4270e-02,  ...,  3.2320e-01,\n",
      "           6.5042e-01, -2.3819e-01],\n",
      "         [ 5.4878e-01,  4.8732e-01, -6.0410e-02,  ...,  6.1617e-01,\n",
      "           7.1676e-01, -1.8311e-01]]]), tensor([[[-6.4279e-02,  1.9887e-02,  7.3434e-03,  ..., -1.3984e-02,\n",
      "          -7.1762e-03,  5.9377e-03],\n",
      "         [ 2.7678e-01,  4.1030e-01,  6.7923e-01,  ..., -3.5459e-01,\n",
      "           1.4669e-02,  2.0545e-01],\n",
      "         [-8.9202e-01,  1.3387e-01, -4.3172e-02,  ..., -3.0804e-02,\n",
      "          -1.9740e-01,  4.9803e-01],\n",
      "         ...,\n",
      "         [-6.8848e-03, -6.3734e-02,  1.8757e-01,  ...,  1.4627e-01,\n",
      "           6.9431e-01,  1.0980e-01],\n",
      "         [ 9.9957e-02, -1.1705e-01,  8.1757e-02,  ...,  4.3083e-01,\n",
      "           7.7394e-01,  1.9237e-01],\n",
      "         [-3.1252e-02,  5.3427e-02, -6.5624e-02,  ...,  4.7971e-01,\n",
      "           6.4980e-01,  1.7367e-01]],\n",
      "\n",
      "        [[-6.4919e-02,  2.7568e-02,  6.8686e-03,  ..., -1.5708e-02,\n",
      "          -7.7404e-03,  1.4209e-03],\n",
      "         [ 5.2130e-02,  1.1412e-01,  8.6229e-01,  ..., -8.9756e-02,\n",
      "           1.4038e-01,  2.1416e-01],\n",
      "         [-8.1192e-01,  1.1771e-01,  7.9003e-02,  ...,  2.1372e-01,\n",
      "          -1.5613e-01,  3.3412e-01],\n",
      "         ...,\n",
      "         [-8.4427e-02,  9.5612e-02,  1.3883e-01,  ...,  2.6410e-01,\n",
      "           5.3771e-01,  2.1263e-01],\n",
      "         [-4.6147e-02, -6.8219e-02,  7.1823e-02,  ...,  3.1928e-01,\n",
      "           7.1687e-01,  2.1292e-01],\n",
      "         [-1.4259e-01, -3.6798e-02,  2.6857e-02,  ...,  4.1326e-01,\n",
      "           6.1468e-01,  2.1596e-01]],\n",
      "\n",
      "        [[-6.7334e-02,  2.1194e-02,  7.4408e-03,  ..., -1.9588e-02,\n",
      "          -5.7877e-03,  9.7365e-05],\n",
      "         [-5.5996e-01,  5.9034e-01,  4.5993e-01,  ..., -4.5972e-01,\n",
      "          -2.3738e-02,  5.6494e-01],\n",
      "         [-4.2256e-02,  1.4186e-01, -8.3947e-02,  ..., -3.1078e-01,\n",
      "          -4.6661e-02,  1.6848e-01],\n",
      "         ...,\n",
      "         [-1.8667e-02, -1.4067e-01,  1.7788e-01,  ...,  2.4221e-01,\n",
      "           4.3717e-01, -3.7859e-02],\n",
      "         [-2.0704e-02, -1.8914e-01,  4.7523e-02,  ...,  2.8991e-01,\n",
      "           5.5828e-01,  1.0965e-02],\n",
      "         [-8.9777e-02, -2.2293e-01, -3.2252e-02,  ...,  3.5879e-01,\n",
      "           6.6032e-01,  6.6676e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.4610e-02,  2.1388e-02,  8.4106e-03,  ..., -2.1620e-02,\n",
      "          -6.9148e-03, -2.9739e-03],\n",
      "         [ 4.5306e-01,  3.4409e-01,  4.1997e-01,  ...,  1.2927e-01,\n",
      "          -1.0190e+00, -5.8597e-02],\n",
      "         [-6.7011e-02,  3.9159e-01,  7.8751e-02,  ...,  1.1065e-01,\n",
      "          -3.0411e-01,  2.9294e-01],\n",
      "         ...,\n",
      "         [-2.1589e-01, -3.9016e-02,  1.3842e-01,  ...,  2.1016e-01,\n",
      "           5.1956e-01,  4.6372e-02],\n",
      "         [-1.4776e-02, -6.9849e-02,  7.0010e-02,  ...,  3.8236e-01,\n",
      "           5.3617e-01,  2.1488e-01],\n",
      "         [ 1.4315e-01, -1.9874e-02, -4.4576e-03,  ...,  4.0907e-01,\n",
      "           5.1316e-01,  5.9725e-01]],\n",
      "\n",
      "        [[-6.4481e-02,  1.9245e-02,  7.4186e-03,  ..., -1.7616e-02,\n",
      "          -9.4368e-03,  8.9949e-04],\n",
      "         [ 2.2309e-01,  3.5307e-01,  6.6524e-01,  ..., -3.1296e-01,\n",
      "          -3.5242e-02,  7.4434e-02],\n",
      "         [-6.0842e-01,  2.1549e-01,  4.4495e-02,  ...,  1.1983e-01,\n",
      "          -2.4837e-01,  4.4603e-01],\n",
      "         ...,\n",
      "         [ 5.3287e-02, -1.0468e-01,  8.5261e-02,  ...,  1.5157e-01,\n",
      "           7.6588e-01,  2.6265e-02],\n",
      "         [ 3.3542e-02, -2.1298e-01,  2.1702e-02,  ...,  3.7286e-01,\n",
      "           5.4390e-01,  1.0430e-01],\n",
      "         [ 2.4664e-01, -1.6853e-02,  3.3459e-02,  ...,  3.9481e-01,\n",
      "           4.5378e-01,  1.9726e-01]],\n",
      "\n",
      "        [[-6.4894e-02,  2.1084e-02,  7.3804e-03,  ..., -1.8262e-02,\n",
      "          -7.5009e-03, -5.2001e-03],\n",
      "         [ 4.4468e-01, -7.6253e-02,  7.6699e-01,  ...,  3.3554e-02,\n",
      "           1.4045e-01, -6.2213e-02],\n",
      "         [ 1.3204e+00,  1.6958e-01,  6.7872e-01,  ..., -9.2448e-02,\n",
      "          -9.0656e-02,  1.8432e-01],\n",
      "         ...,\n",
      "         [ 6.6289e-02, -5.4014e-02,  2.1558e-01,  ...,  2.1230e-01,\n",
      "           5.1479e-01,  5.0067e-02],\n",
      "         [-3.6071e-04, -1.2184e-01,  1.1311e-01,  ...,  3.5510e-01,\n",
      "           5.4759e-01,  5.9297e-02],\n",
      "         [ 1.2637e-01, -1.0460e-01, -6.4957e-02,  ...,  5.7293e-01,\n",
      "           6.3857e-01,  1.7799e-01]]]), tensor([[[-0.0855,  0.0259, -0.0123,  ...,  0.0491,  0.0065, -0.0054],\n",
      "         [ 0.1375,  0.6239,  0.8241,  ..., -0.6668, -0.1043,  0.3532],\n",
      "         [-0.7968,  0.0291, -0.1667,  ..., -0.0330, -0.3544,  0.6161],\n",
      "         ...,\n",
      "         [ 0.2784, -0.1170,  0.2710,  ...,  0.4426,  0.9920,  0.0842],\n",
      "         [ 0.2879, -0.1264,  0.1300,  ...,  0.6530,  1.0147,  0.1632],\n",
      "         [ 0.1735,  0.1373, -0.0305,  ...,  0.6702,  0.8940,  0.1501]],\n",
      "\n",
      "        [[-0.0895,  0.0260, -0.0097,  ...,  0.0480,  0.0048, -0.0016],\n",
      "         [ 0.1067,  0.3894,  0.8442,  ..., -0.5058,  0.0130,  0.5873],\n",
      "         [-0.6832,  0.0348, -0.0808,  ...,  0.1593, -0.1667,  0.6367],\n",
      "         ...,\n",
      "         [ 0.0602,  0.2572,  0.1362,  ...,  0.2606,  0.6958,  0.3996],\n",
      "         [ 0.0555,  0.1240,  0.0835,  ...,  0.4189,  0.8045,  0.2593],\n",
      "         [-0.0270,  0.2050,  0.0299,  ...,  0.4431,  0.7222,  0.1905]],\n",
      "\n",
      "        [[-0.0875,  0.0267, -0.0129,  ...,  0.0476,  0.0043, -0.0100],\n",
      "         [-0.6745,  0.3234,  0.4878,  ..., -0.4273, -0.2667,  0.8976],\n",
      "         [ 0.0681,  0.0390, -0.0478,  ..., -0.0572,  0.0068,  0.3166],\n",
      "         ...,\n",
      "         [ 0.1954,  0.0300,  0.0992,  ...,  0.2493,  0.5411,  0.1661],\n",
      "         [ 0.1728, -0.0798,  0.0077,  ...,  0.2977,  0.6502,  0.1445],\n",
      "         [ 0.1137, -0.1641, -0.0461,  ...,  0.4496,  0.8336,  0.0374]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0883,  0.0288, -0.0111,  ...,  0.0492,  0.0049, -0.0079],\n",
      "         [ 0.3266,  0.2465,  0.4181,  ...,  0.2325, -1.2135,  0.0567],\n",
      "         [-0.0624,  0.4115,  0.0877,  ...,  0.0030, -0.4179,  0.2451],\n",
      "         ...,\n",
      "         [-0.0338,  0.1726,  0.1244,  ...,  0.3579,  0.6428,  0.1531],\n",
      "         [ 0.1878, -0.0020, -0.0086,  ...,  0.6484,  0.6722,  0.1846],\n",
      "         [ 0.3619,  0.1188, -0.0286,  ...,  0.6111,  0.7898,  0.3987]],\n",
      "\n",
      "        [[-0.0904,  0.0251, -0.0139,  ...,  0.0491,  0.0037, -0.0087],\n",
      "         [ 0.1843,  0.6990,  0.7758,  ..., -0.6553, -0.0877,  0.3425],\n",
      "         [-0.5727,  0.0692, -0.1292,  ...,  0.0863, -0.4177,  0.5597],\n",
      "         ...,\n",
      "         [ 0.2900, -0.0227,  0.1068,  ...,  0.3541,  0.8747, -0.0519],\n",
      "         [ 0.2005, -0.0129,  0.0731,  ...,  0.4245,  0.5673,  0.1132],\n",
      "         [ 0.4638,  0.0070,  0.0433,  ...,  0.4872,  0.5876,  0.1580]],\n",
      "\n",
      "        [[-0.0863,  0.0252, -0.0106,  ...,  0.0487,  0.0066, -0.0076],\n",
      "         [ 0.2882, -0.5435,  0.7525,  ...,  0.0454,  0.0916,  0.2129],\n",
      "         [ 1.4195,  0.1769,  0.6829,  ..., -0.2085,  0.0270,  0.1239],\n",
      "         ...,\n",
      "         [ 0.2120, -0.1361,  0.2257,  ...,  0.4173,  0.7199,  0.0957],\n",
      "         [ 0.1131, -0.1661,  0.1408,  ...,  0.5682,  0.7732,  0.0853],\n",
      "         [ 0.2123, -0.1674, -0.0362,  ...,  0.6554,  0.9601,  0.1511]]]), tensor([[[-6.6341e-02,  1.6240e-02, -7.2818e-03,  ...,  1.7087e-02,\n",
      "           3.6388e-03, -2.0001e-02],\n",
      "         [ 1.4502e-01,  9.3928e-01,  9.4366e-01,  ..., -7.8219e-01,\n",
      "          -6.9228e-02,  2.5615e-01],\n",
      "         [-8.1725e-01, -4.1909e-02, -1.0723e-01,  ..., -3.2527e-01,\n",
      "          -2.4686e-01,  4.5717e-01],\n",
      "         ...,\n",
      "         [ 4.0105e-01,  7.3518e-02,  1.4965e-01,  ...,  4.4216e-01,\n",
      "           1.1602e+00,  3.1183e-02],\n",
      "         [ 2.8444e-01,  2.6052e-01,  1.8804e-02,  ...,  3.7846e-01,\n",
      "           1.1118e+00,  7.2841e-02],\n",
      "         [ 2.3268e-01,  4.5087e-01, -1.6304e-01,  ...,  2.3745e-01,\n",
      "           8.9034e-01,  6.0651e-02]],\n",
      "\n",
      "        [[-7.1571e-02,  2.1247e-02, -7.5044e-03,  ...,  2.2326e-02,\n",
      "          -5.4533e-04, -1.6752e-02],\n",
      "         [ 1.3045e-01,  7.2878e-01,  9.4166e-01,  ..., -7.8142e-01,\n",
      "           3.1546e-02,  2.5678e-01],\n",
      "         [-6.5149e-01, -2.0255e-02, -5.6923e-02,  ..., -7.4768e-02,\n",
      "          -1.3443e-01,  3.5223e-01],\n",
      "         ...,\n",
      "         [ 1.9156e-01,  5.8950e-01,  3.4610e-03,  ..., -4.0152e-02,\n",
      "           5.4524e-01,  2.9992e-01],\n",
      "         [ 1.7884e-01,  4.5094e-01,  3.0430e-02,  ...,  1.1021e-02,\n",
      "           5.4571e-01,  2.0784e-01],\n",
      "         [ 1.5956e-01,  4.0418e-01, -8.9115e-04,  ...,  1.2714e-02,\n",
      "           4.8269e-01,  1.2689e-01]],\n",
      "\n",
      "        [[-6.7734e-02,  1.5635e-02, -1.0190e-02,  ...,  1.6602e-02,\n",
      "           5.8129e-03, -2.4795e-02],\n",
      "         [-5.4446e-01,  7.9990e-01,  5.1229e-01,  ..., -5.0576e-01,\n",
      "          -3.0760e-02,  8.7581e-01],\n",
      "         [-6.8157e-02,  1.6841e-01,  4.2796e-02,  ..., -8.3665e-02,\n",
      "          -6.6479e-02,  3.1894e-01],\n",
      "         ...,\n",
      "         [ 2.3476e-01,  5.8551e-01, -2.1472e-01,  ...,  2.1743e-02,\n",
      "           3.7404e-01,  1.5295e-01],\n",
      "         [ 1.7786e-01,  4.9413e-01, -2.5027e-01,  ..., -7.7359e-02,\n",
      "           5.0060e-01,  1.2819e-01],\n",
      "         [ 1.2710e-01,  3.6153e-01, -2.9108e-01,  ...,  1.1736e-01,\n",
      "           8.6760e-01,  2.0225e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.8194e-02,  1.8685e-02, -6.3849e-03,  ...,  1.8587e-02,\n",
      "          -1.5894e-03, -2.3096e-02],\n",
      "         [ 4.0843e-01, -9.9762e-02,  4.7772e-01,  ..., -4.2605e-01,\n",
      "          -9.3810e-01, -3.0272e-01],\n",
      "         [-4.5803e-02,  7.8679e-02, -9.2860e-03,  ..., -3.2312e-01,\n",
      "          -4.7519e-01, -5.5717e-01],\n",
      "         ...,\n",
      "         [ 1.2292e-01,  5.5366e-01, -6.5068e-02,  ...,  6.1057e-02,\n",
      "           4.4984e-01,  9.9773e-02],\n",
      "         [ 3.3959e-01,  4.2484e-01, -1.7969e-01,  ...,  3.4204e-01,\n",
      "           6.7848e-01,  1.2732e-01],\n",
      "         [ 4.0416e-01,  4.2979e-01, -2.0206e-01,  ...,  2.7626e-01,\n",
      "           8.4995e-01,  2.2467e-01]],\n",
      "\n",
      "        [[-6.8018e-02,  1.8723e-02, -9.3476e-03,  ...,  1.8250e-02,\n",
      "          -1.1890e-03, -2.1104e-02],\n",
      "         [ 1.7742e-01,  9.4009e-01,  8.8017e-01,  ..., -8.9846e-01,\n",
      "          -7.0351e-02,  1.9794e-01],\n",
      "         [-5.1616e-01,  1.5365e-02, -7.0922e-02,  ..., -1.9456e-01,\n",
      "          -3.8299e-01,  3.5554e-01],\n",
      "         ...,\n",
      "         [ 3.5196e-01,  2.8696e-01, -2.2710e-02,  ...,  2.3815e-01,\n",
      "           8.9313e-01, -1.6805e-02],\n",
      "         [ 1.4833e-01,  4.1957e-01, -1.4269e-03,  ..., -4.7377e-02,\n",
      "           3.6988e-01,  1.1017e-01],\n",
      "         [ 5.4290e-01,  2.9437e-01, -1.4906e-02,  ...,  1.7021e-01,\n",
      "           6.5918e-01,  1.0150e-01]],\n",
      "\n",
      "        [[-6.4501e-02,  1.6451e-02, -7.0990e-03,  ...,  2.2326e-02,\n",
      "           2.3547e-03, -1.3551e-02],\n",
      "         [ 1.5821e-01, -4.6311e-01,  5.9393e-01,  ..., -3.3923e-01,\n",
      "           2.3208e-01,  1.3243e-01],\n",
      "         [ 1.2599e+00, -1.7629e-01,  7.0554e-01,  ..., -2.9290e-01,\n",
      "           4.7924e-02,  1.2412e-01],\n",
      "         ...,\n",
      "         [ 2.7474e-01,  5.1933e-02,  1.0037e-01,  ...,  2.9329e-01,\n",
      "           7.3755e-01,  2.0279e-01],\n",
      "         [ 1.4951e-01,  1.4276e-01, -2.9945e-02,  ...,  2.6402e-01,\n",
      "           8.0934e-01,  1.1320e-01],\n",
      "         [ 2.8028e-01,  3.4107e-02, -2.0424e-01,  ...,  4.1350e-01,\n",
      "           1.0484e+00,  1.0290e-01]]]), tensor([[[-3.7235e-02,  8.1542e-03, -1.3527e-03,  ...,  1.1891e-02,\n",
      "          -1.6380e-03, -1.4861e-02],\n",
      "         [ 2.4835e-02,  3.4918e-01,  4.5128e-01,  ..., -4.6674e-01,\n",
      "          -1.5290e-01,  2.5953e-02],\n",
      "         [-3.7211e-01, -4.0502e-02,  8.1073e-02,  ..., -1.9474e-01,\n",
      "          -1.6444e-01,  7.6535e-02],\n",
      "         ...,\n",
      "         [ 1.9765e-01,  1.1269e-01,  5.8597e-02,  ...,  2.0695e-01,\n",
      "           4.8123e-01,  3.7356e-02],\n",
      "         [ 1.0558e-01,  1.5402e-01, -1.7335e-02,  ...,  1.1963e-01,\n",
      "           3.7779e-01, -5.0927e-02],\n",
      "         [ 5.1015e-02,  2.4712e-01, -4.0377e-02,  ...,  6.8139e-02,\n",
      "           2.6082e-01, -8.5279e-02]],\n",
      "\n",
      "        [[-3.6576e-02,  1.0526e-02, -1.4600e-03,  ...,  1.2379e-02,\n",
      "          -2.1449e-03, -1.2331e-02],\n",
      "         [ 6.2180e-02,  3.6709e-01,  4.1201e-01,  ..., -4.2919e-01,\n",
      "          -5.6278e-02,  1.0628e-01],\n",
      "         [-3.2559e-01,  4.4229e-02,  4.9966e-02,  ..., -1.5652e-01,\n",
      "          -8.8720e-02,  7.3068e-02],\n",
      "         ...,\n",
      "         [ 7.8774e-02,  1.5810e-01,  4.6244e-02,  ..., -2.3329e-02,\n",
      "           2.0875e-01, -7.0495e-03],\n",
      "         [ 6.2422e-02,  1.2203e-01,  3.7049e-02,  ..., -3.3195e-03,\n",
      "           1.4107e-01, -3.9257e-02],\n",
      "         [ 5.3137e-02,  1.1233e-01,  2.6811e-02,  ..., -1.7359e-02,\n",
      "           1.3386e-01, -7.4425e-02]],\n",
      "\n",
      "        [[-3.6490e-02,  7.9414e-03, -9.3970e-04,  ...,  1.1303e-02,\n",
      "          -3.2149e-04, -1.5862e-02],\n",
      "         [-1.9260e-01,  3.1482e-01,  2.9044e-01,  ..., -2.8045e-01,\n",
      "          -1.1530e-01,  3.5499e-01],\n",
      "         [ 4.8746e-02,  1.6123e-01,  6.7186e-02,  ..., -1.9046e-01,\n",
      "          -4.9584e-02,  1.8775e-01],\n",
      "         ...,\n",
      "         [ 7.0582e-02,  1.4136e-01, -3.3076e-02,  ...,  1.5669e-02,\n",
      "           9.8290e-02, -4.9653e-03],\n",
      "         [ 5.3133e-02,  1.4068e-01, -3.3051e-02,  ...,  3.4082e-03,\n",
      "           1.1081e-01, -3.4460e-02],\n",
      "         [ 9.2120e-02,  1.1603e-01, -1.2473e-01,  ...,  9.7656e-03,\n",
      "           2.9256e-01, -7.4455e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.6752e-02,  9.9508e-03, -6.8104e-04,  ...,  1.1369e-02,\n",
      "          -1.7645e-03, -1.3769e-02],\n",
      "         [ 1.6554e-01, -1.6670e-01,  3.3819e-01,  ..., -5.5318e-01,\n",
      "          -4.9793e-01,  1.1653e-01],\n",
      "         [-3.1584e-02,  7.3456e-02,  9.2152e-02,  ..., -3.1608e-01,\n",
      "          -2.8408e-01, -1.1483e-01],\n",
      "         ...,\n",
      "         [ 2.3135e-02,  1.9391e-01,  6.2510e-03,  ...,  2.2865e-03,\n",
      "           1.1600e-01, -5.8778e-02],\n",
      "         [ 6.2397e-02,  2.4464e-01, -4.5243e-02,  ...,  4.9608e-04,\n",
      "           2.2251e-01,  2.6583e-02],\n",
      "         [ 1.2893e-01,  2.3392e-01, -3.7631e-02,  ..., -1.2027e-02,\n",
      "           2.9862e-01,  7.4518e-02]],\n",
      "\n",
      "        [[-3.7299e-02,  8.5531e-03, -2.0997e-03,  ...,  1.1007e-02,\n",
      "          -1.0913e-03, -1.5051e-02],\n",
      "         [ 4.6963e-02,  4.2387e-01,  4.1335e-01,  ..., -5.2368e-01,\n",
      "          -1.4853e-01, -8.1937e-03],\n",
      "         [-2.8226e-01,  4.9414e-02,  8.3116e-02,  ..., -1.4922e-01,\n",
      "          -2.1526e-01, -8.2774e-02],\n",
      "         ...,\n",
      "         [ 1.8378e-01,  2.1419e-01, -7.2218e-02,  ...,  6.9944e-02,\n",
      "           2.8072e-01, -9.8603e-03],\n",
      "         [ 4.9650e-02,  1.7745e-01, -7.5505e-03,  ...,  2.3934e-02,\n",
      "           6.3067e-02, -4.9322e-02],\n",
      "         [ 2.5826e-01,  2.6106e-01,  6.3293e-03,  ..., -7.9971e-04,\n",
      "           2.3242e-01,  9.5698e-02]],\n",
      "\n",
      "        [[-3.6137e-02,  9.8568e-03, -2.3142e-03,  ...,  1.2413e-02,\n",
      "          -1.9899e-03, -1.2170e-02],\n",
      "         [-2.0230e-02, -3.8355e-01,  4.0208e-01,  ..., -3.4390e-01,\n",
      "           4.9255e-02, -1.8466e-02],\n",
      "         [ 6.6516e-01, -5.9350e-02,  4.2499e-01,  ..., -2.4551e-01,\n",
      "           4.4081e-02,  1.3745e-01],\n",
      "         ...,\n",
      "         [ 1.1658e-01,  1.0918e-01,  6.3575e-02,  ...,  1.1055e-01,\n",
      "           2.5185e-01,  1.8746e-01],\n",
      "         [ 1.5055e-03,  1.2658e-01, -2.8923e-03,  ...,  6.5025e-02,\n",
      "           3.0038e-01,  4.2531e-02],\n",
      "         [ 9.1361e-02,  6.3858e-02, -8.6595e-02,  ...,  1.5292e-01,\n",
      "           4.1763e-01, -6.8470e-03]]])), encoder_attentions=None)\n",
      "seg_num: 1\n",
      "batch_size: 32\n",
      "non_empty_mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "batch_size: 32\n",
      "decoder_input_ids: None\n",
      "prefix_tokens: torch.Size([20])\n",
      "out: Seq2SeqLMOutput(loss=tensor(19.1744), logits=tensor([[[33.8975,  6.0508, 16.5061,  ...,  6.2743,  5.9747,  1.7470],\n",
      "         [ 0.2329, -4.1573,  3.9979,  ..., -3.4809, -3.6597, -3.1114],\n",
      "         [-6.4283, -4.4940,  6.0055,  ..., -4.6446, -5.1042, -3.1582],\n",
      "         ...,\n",
      "         [-1.3712, -2.5256, 13.6830,  ..., -3.0890, -2.9414, -2.1269],\n",
      "         [-1.7426, -2.5363, 13.6912,  ..., -2.8569, -2.8174, -2.1129],\n",
      "         [-1.5875, -2.4519, 14.5711,  ..., -2.8181, -2.6828, -2.1615]],\n",
      "\n",
      "        [[34.5060,  6.2399, 16.0757,  ...,  6.3925,  6.3073,  1.7804],\n",
      "         [ 0.8336, -4.4636,  4.9257,  ..., -4.6354, -4.4370, -2.5021],\n",
      "         [-4.3216, -3.8728,  8.2859,  ..., -4.2965, -4.5059, -1.6224],\n",
      "         ...,\n",
      "         [ 0.6155, -2.5850, 14.0283,  ..., -3.2990, -3.3696, -3.6014],\n",
      "         [-4.8823, -3.4377, 12.1547,  ..., -3.9900, -4.1673, -3.2209],\n",
      "         [-1.4748, -3.1559, 15.8231,  ..., -3.3638, -3.2637, -2.7534]],\n",
      "\n",
      "        [[34.3668,  6.2153, 16.1518,  ...,  6.3093,  6.2422,  1.8201],\n",
      "         [ 0.2347, -2.9059,  3.3591,  ..., -3.0450, -2.5798, -1.3369],\n",
      "         [27.7651,  5.2536, 16.3962,  ...,  5.5196,  5.3568,  1.9101],\n",
      "         ...,\n",
      "         [-2.6960, -4.0808,  3.1182,  ..., -3.8139, -3.7752, -1.4723],\n",
      "         [-3.0523, -3.9453,  2.8871,  ..., -3.7923, -3.7854, -2.0434],\n",
      "         [-3.6067, -4.2675,  2.7414,  ..., -4.1139, -4.0550, -1.7219]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[33.4642,  5.9370, 15.8549,  ...,  5.9233,  5.7265,  1.9827],\n",
      "         [ 0.1447, -3.8009,  2.3029,  ..., -3.4619, -3.6705, -2.0834],\n",
      "         [-4.2897, -4.1257,  5.3102,  ..., -4.0715, -4.2434, -2.3301],\n",
      "         ...,\n",
      "         [ 0.3393, -1.2428, 17.2483,  ..., -1.4096, -1.6840, -2.8053],\n",
      "         [ 0.3159, -1.2687, 17.3406,  ..., -1.2375, -1.5768, -2.5833],\n",
      "         [ 0.1261, -1.3758, 18.7372,  ..., -1.3172, -1.5452, -2.2143]],\n",
      "\n",
      "        [[33.0887,  5.8527, 16.8920,  ...,  5.5603,  5.5634,  1.5339],\n",
      "         [-0.4571, -4.4460,  4.5612,  ..., -4.3040, -4.4445, -5.2235],\n",
      "         [-4.4090, -3.3866,  5.7685,  ..., -3.4276, -3.6133, -1.5309],\n",
      "         ...,\n",
      "         [-1.7051, -2.5831,  4.1425,  ..., -2.3290, -2.2514, -2.4410],\n",
      "         [-2.1599, -2.6535,  4.0204,  ..., -2.4120, -2.3863, -2.6403],\n",
      "         [-1.9738, -2.7702,  4.1383,  ..., -2.5873, -2.4989, -2.4941]],\n",
      "\n",
      "        [[33.4920,  5.7561, 16.3579,  ...,  5.9215,  5.8217,  1.8905],\n",
      "         [-0.3532, -4.7788,  4.9321,  ..., -4.3084, -3.8618, -3.0763],\n",
      "         [-3.2321, -3.6596, 10.2099,  ..., -3.4967, -3.8569, -0.1199],\n",
      "         ...,\n",
      "         [ 1.0454, -1.6035, 15.3860,  ..., -1.3425, -1.4573, -1.6421],\n",
      "         [ 0.9018, -1.5198, 15.5772,  ..., -1.1454, -1.3423, -1.5684],\n",
      "         [ 0.7952, -1.5518, 16.2407,  ..., -1.1357, -1.3031, -1.0929]]]), past_key_values=None, decoder_hidden_states=(tensor([[[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.6400e-01,  3.1086e-02,  1.2818e-01,  ...,  1.0363e-01,\n",
      "          -6.7577e-02,  1.8733e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.6400e-01,  3.1086e-02,  1.2818e-01,  ...,  1.0363e-01,\n",
      "          -6.7577e-02,  1.8733e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.6400e-01,  3.1086e-02,  1.2818e-01,  ...,  1.0363e-01,\n",
      "          -6.7577e-02,  1.8733e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.6400e-01,  3.1086e-02,  1.2818e-01,  ...,  1.0363e-01,\n",
      "          -6.7577e-02,  1.8733e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.6400e-01,  3.1086e-02,  1.2818e-01,  ...,  1.0363e-01,\n",
      "          -6.7577e-02,  1.8733e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.6400e-01,  3.1086e-02,  1.2818e-01,  ...,  1.0363e-01,\n",
      "          -6.7577e-02,  1.8733e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]]]), tensor([[[-2.9510e-03, -3.8872e-03,  1.0391e-02,  ...,  7.3958e-03,\n",
      "           1.2833e-02, -1.2224e-02],\n",
      "         [ 8.5716e-02, -1.2987e-01,  7.9885e-02,  ..., -2.3110e-02,\n",
      "          -1.0002e-01, -2.1004e-02],\n",
      "         [ 3.0964e-01, -9.0778e-02,  1.4115e-01,  ..., -2.9774e-01,\n",
      "          -2.5325e-01,  1.0426e-01],\n",
      "         ...,\n",
      "         [ 5.4796e-02, -3.3453e-01,  3.3979e-01,  ...,  4.6379e-01,\n",
      "          -7.4710e-01, -2.6585e-01],\n",
      "         [ 1.9234e-01, -3.4500e-01,  3.0598e-01,  ...,  5.1766e-01,\n",
      "          -9.3624e-01, -1.6749e-01],\n",
      "         [ 4.5812e-01, -2.4263e-01,  2.9455e-01,  ...,  4.3726e-01,\n",
      "          -8.3075e-01, -7.6587e-02]],\n",
      "\n",
      "        [[-2.5474e-03, -4.3449e-03,  1.1006e-02,  ...,  8.0004e-03,\n",
      "           1.2846e-02, -1.2638e-02],\n",
      "         [ 8.8544e-02, -1.4066e-01,  9.1087e-02,  ..., -3.1754e-02,\n",
      "          -1.4821e-01,  1.0503e-02],\n",
      "         [ 3.4326e-01, -3.4338e-02,  1.0421e-01,  ..., -2.9660e-01,\n",
      "          -3.8973e-01,  3.0712e-01],\n",
      "         ...,\n",
      "         [ 1.6481e-01, -4.0861e-01,  4.4839e-01,  ...,  4.5247e-01,\n",
      "          -5.9513e-01, -1.8501e-01],\n",
      "         [ 2.6495e-01, -3.9079e-01,  3.6112e-01,  ...,  4.0574e-01,\n",
      "          -6.7716e-01, -8.0052e-02],\n",
      "         [ 5.5194e-01, -3.3341e-01,  3.8698e-01,  ...,  3.8435e-01,\n",
      "          -6.6876e-01, -1.9436e-02]],\n",
      "\n",
      "        [[-2.1560e-03, -3.9623e-03,  1.0582e-02,  ...,  7.3908e-03,\n",
      "           1.3018e-02, -1.2332e-02],\n",
      "         [ 8.9548e-02, -1.0945e-01,  8.4062e-02,  ..., -4.4619e-03,\n",
      "          -1.0991e-01,  2.7308e-03],\n",
      "         [ 2.2072e-01,  7.7241e-03,  1.6232e-01,  ..., -1.6661e-01,\n",
      "          -1.2918e-01,  2.6816e-02],\n",
      "         ...,\n",
      "         [-1.2492e-01, -3.1017e-01,  2.4898e-01,  ...,  6.9952e-01,\n",
      "          -8.7145e-01, -2.8493e-01],\n",
      "         [ 3.2605e-02, -3.3160e-01,  2.2580e-01,  ...,  7.4705e-01,\n",
      "          -1.0536e+00, -1.5970e-01],\n",
      "         [ 2.9398e-01, -2.3898e-01,  2.4093e-01,  ...,  6.3323e-01,\n",
      "          -9.4678e-01, -9.6539e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.1527e-03, -3.9316e-03,  1.0172e-02,  ...,  7.0046e-03,\n",
      "           1.1811e-02, -1.2687e-02],\n",
      "         [ 1.1532e-01, -1.5567e-01,  8.2611e-02,  ..., -4.2489e-02,\n",
      "          -1.8517e-01, -1.9739e-02],\n",
      "         [ 3.2602e-01, -1.6491e-02,  6.3109e-02,  ..., -3.1101e-01,\n",
      "          -6.0289e-01,  1.5636e-01],\n",
      "         ...,\n",
      "         [ 1.2651e-01, -4.8338e-01,  3.4906e-01,  ...,  3.6631e-01,\n",
      "          -6.0775e-01, -2.8316e-01],\n",
      "         [ 2.7308e-01, -4.9260e-01,  2.6879e-01,  ...,  4.0289e-01,\n",
      "          -7.6278e-01, -1.5834e-01],\n",
      "         [ 4.9796e-01, -4.0271e-01,  2.8273e-01,  ...,  3.4961e-01,\n",
      "          -6.4417e-01, -7.0080e-02]],\n",
      "\n",
      "        [[-3.5062e-03, -3.9198e-03,  1.0501e-02,  ...,  8.3376e-03,\n",
      "           1.3404e-02, -1.1254e-02],\n",
      "         [ 1.2671e-01, -1.4811e-01,  6.7166e-02,  ..., -1.6117e-02,\n",
      "          -1.7601e-01,  1.8610e-02],\n",
      "         [ 4.4977e-01,  1.2314e-01,  8.4495e-02,  ..., -3.0487e-01,\n",
      "          -4.5446e-01,  2.6244e-01],\n",
      "         ...,\n",
      "         [ 7.9195e-02, -3.7930e-01,  3.1427e-01,  ...,  6.6114e-01,\n",
      "          -9.2700e-01, -2.2232e-01],\n",
      "         [ 2.3823e-01, -3.9203e-01,  2.7660e-01,  ...,  6.6150e-01,\n",
      "          -1.0730e+00, -6.8583e-02],\n",
      "         [ 4.7042e-01, -3.0387e-01,  2.5249e-01,  ...,  5.9743e-01,\n",
      "          -9.8457e-01, -1.2997e-03]],\n",
      "\n",
      "        [[-2.9366e-03, -3.9620e-03,  1.0476e-02,  ...,  8.0351e-03,\n",
      "           1.2540e-02, -1.1726e-02],\n",
      "         [ 8.9812e-02, -1.5012e-01,  8.7332e-02,  ..., -3.1593e-02,\n",
      "          -1.3024e-01, -1.1166e-04],\n",
      "         [ 5.8569e-01, -9.1278e-02,  1.4168e-01,  ..., -3.0604e-01,\n",
      "          -3.4176e-01,  1.6025e-01],\n",
      "         ...,\n",
      "         [ 1.2505e-01, -3.3102e-01,  3.4773e-01,  ...,  4.7274e-01,\n",
      "          -6.3607e-01, -2.0902e-01],\n",
      "         [ 2.4861e-01, -3.6837e-01,  2.8777e-01,  ...,  4.9098e-01,\n",
      "          -8.1562e-01, -9.6641e-02],\n",
      "         [ 5.1417e-01, -2.4776e-01,  2.8339e-01,  ...,  4.4385e-01,\n",
      "          -7.0151e-01, -2.3470e-02]]]), tensor([[[ 1.3235e-02, -4.4628e-03, -9.1091e-03,  ...,  2.3055e-02,\n",
      "           6.9791e-03, -4.0398e-02],\n",
      "         [ 8.5519e-03, -5.3865e-03, -8.4093e-05,  ...,  2.3010e-02,\n",
      "           1.2662e-02, -2.7722e-02],\n",
      "         [ 7.3226e-02,  1.3535e-01, -1.8704e-01,  ..., -2.6936e-01,\n",
      "          -5.6687e-02,  4.0788e-01],\n",
      "         ...,\n",
      "         [-4.5725e-01, -8.4536e-02, -3.9209e-01,  ..., -1.2930e-01,\n",
      "          -3.0264e-01,  6.0747e-02],\n",
      "         [-3.8640e-01, -1.1822e-01, -3.9335e-01,  ..., -1.1062e-01,\n",
      "          -3.6081e-01,  8.5646e-02],\n",
      "         [-3.0649e-01, -9.5515e-02, -4.6639e-01,  ..., -1.9481e-01,\n",
      "          -3.2454e-01,  2.5486e-02]],\n",
      "\n",
      "        [[ 1.3537e-02, -4.5003e-03, -8.8941e-03,  ...,  2.2967e-02,\n",
      "           7.3140e-03, -4.0318e-02],\n",
      "         [ 1.8498e-02, -7.3991e-03, -3.1102e-03,  ...,  2.6109e-02,\n",
      "           5.5962e-03, -3.8902e-02],\n",
      "         [-1.1446e-01, -6.3195e-03, -2.6238e-01,  ..., -4.0189e-01,\n",
      "          -3.9865e-01,  3.7519e-01],\n",
      "         ...,\n",
      "         [-3.1230e-01, -2.5315e-01, -2.4801e-01,  ...,  2.4543e-01,\n",
      "          -2.8641e-01,  1.7837e-01],\n",
      "         [-2.2201e-01, -2.6034e-01, -2.4065e-01,  ...,  4.8190e-02,\n",
      "          -1.8321e-01,  3.7429e-01],\n",
      "         [-8.8018e-02, -3.7497e-01, -3.0942e-01,  ...,  1.2402e-01,\n",
      "          -4.9475e-01,  2.4209e-02]],\n",
      "\n",
      "        [[ 1.3200e-02, -4.5059e-03, -8.9094e-03,  ...,  2.3410e-02,\n",
      "           6.5393e-03, -4.0168e-02],\n",
      "         [ 1.2676e-02, -1.0473e-03,  3.1832e-04,  ...,  2.1464e-02,\n",
      "           1.4685e-02, -2.9929e-02],\n",
      "         [-1.4300e-01,  2.3320e-01, -1.3387e-03,  ..., -3.0816e-01,\n",
      "           3.7480e-01,  2.7730e-01],\n",
      "         ...,\n",
      "         [-4.1772e-01, -1.2549e-01,  2.4037e-01,  ...,  4.0002e-01,\n",
      "          -4.9057e-01, -6.9380e-02],\n",
      "         [-4.4292e-01, -1.7306e-01,  2.4687e-01,  ...,  3.2873e-01,\n",
      "          -6.1781e-01,  1.0179e-02],\n",
      "         [-3.5652e-01, -1.2127e-01,  2.1453e-01,  ...,  2.4602e-01,\n",
      "          -5.4708e-01, -1.0836e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3254e-02, -4.3837e-03, -8.7744e-03,  ...,  2.3020e-02,\n",
      "           6.9285e-03, -4.0044e-02],\n",
      "         [ 2.0290e-02, -7.0099e-03, -1.8055e-03,  ...,  2.6990e-02,\n",
      "           6.0801e-03, -4.1262e-02],\n",
      "         [ 4.1511e-02, -1.5375e-01, -3.0883e-01,  ..., -3.5231e-01,\n",
      "          -5.0395e-01,  1.3488e-01],\n",
      "         ...,\n",
      "         [-3.9649e-01, -3.1222e-01, -2.9605e-01,  ...,  7.5049e-02,\n",
      "          -2.4481e-01,  1.2633e-01],\n",
      "         [-2.9528e-01, -3.1191e-01, -2.8456e-01,  ...,  6.3265e-02,\n",
      "          -2.6250e-01,  1.2191e-01],\n",
      "         [-2.0152e-01, -3.0770e-01, -3.0377e-01,  ...,  3.1687e-02,\n",
      "          -2.1144e-01,  8.1669e-02]],\n",
      "\n",
      "        [[ 1.3003e-02, -4.1940e-03, -8.8160e-03,  ...,  2.3257e-02,\n",
      "           6.4766e-03, -4.0085e-02],\n",
      "         [ 1.9480e-02, -6.6748e-03, -2.2903e-03,  ...,  2.7529e-02,\n",
      "           3.8022e-03, -3.9647e-02],\n",
      "         [ 4.3643e-01, -1.5090e-01, -9.1596e-02,  ..., -2.3354e-02,\n",
      "          -4.0909e-01,  1.7111e-01],\n",
      "         ...,\n",
      "         [-8.6899e-02, -2.7269e-01,  2.3846e-01,  ...,  5.1588e-01,\n",
      "          -5.9797e-01,  2.8846e-02],\n",
      "         [-9.7428e-02, -2.8144e-01,  2.1930e-01,  ...,  4.0953e-01,\n",
      "          -6.3018e-01,  1.0920e-01],\n",
      "         [-1.5395e-03, -2.2785e-01,  1.4682e-01,  ...,  3.6501e-01,\n",
      "          -5.9100e-01,  3.1979e-02]],\n",
      "\n",
      "        [[ 1.3234e-02, -4.6391e-03, -8.8841e-03,  ...,  2.3076e-02,\n",
      "           6.8956e-03, -4.0476e-02],\n",
      "         [ 1.5645e-02, -9.3731e-03, -2.2208e-03,  ...,  2.6142e-02,\n",
      "           5.6920e-03, -3.6300e-02],\n",
      "         [ 2.7157e-01, -1.7982e-01, -2.1406e-01,  ..., -1.4892e-01,\n",
      "          -2.1523e-01,  3.5314e-01],\n",
      "         ...,\n",
      "         [-3.0116e-01, -1.8449e-01, -3.3162e-01,  ...,  1.3535e-01,\n",
      "          -2.6536e-01,  2.9576e-02],\n",
      "         [-2.4327e-01, -2.1832e-01, -3.0908e-01,  ...,  1.3072e-01,\n",
      "          -3.0956e-01,  3.1473e-02],\n",
      "         [-1.7995e-01, -1.9011e-01, -3.6995e-01,  ...,  8.1350e-02,\n",
      "          -2.6970e-01, -2.5094e-02]]]), tensor([[[ 0.0049, -0.0116, -0.0167,  ...,  0.0082, -0.0365, -0.0094],\n",
      "         [-0.1208,  0.0995, -0.0564,  ...,  0.0779,  0.1233, -0.0736],\n",
      "         [ 0.2571,  0.2561, -0.1527,  ..., -0.5227,  0.2843,  0.3615],\n",
      "         ...,\n",
      "         [-0.6011, -0.0587, -0.5973,  ..., -0.2066, -0.7560, -0.0218],\n",
      "         [-0.5303, -0.0423, -0.6174,  ..., -0.1788, -0.8237,  0.0773],\n",
      "         [-0.5195, -0.0360, -0.6583,  ..., -0.2760, -0.8586,  0.0212]],\n",
      "\n",
      "        [[ 0.0050, -0.0118, -0.0167,  ...,  0.0082, -0.0365, -0.0093],\n",
      "         [-0.1250,  0.0522, -0.0245,  ...,  0.0450,  0.2168, -0.0298],\n",
      "         [ 0.0172, -0.0682, -0.0720,  ..., -0.4613,  0.3076,  0.1969],\n",
      "         ...,\n",
      "         [-0.8608, -0.1809, -0.6783,  ..., -0.2383, -0.5134, -0.0447],\n",
      "         [-0.8194, -0.1794, -0.7247,  ..., -0.3266, -0.5439,  0.1506],\n",
      "         [-0.7570, -0.2258, -0.7246,  ..., -0.2142, -0.7472,  0.0641]],\n",
      "\n",
      "        [[ 0.0049, -0.0118, -0.0167,  ...,  0.0080, -0.0366, -0.0093],\n",
      "         [-0.0346, -0.0149,  0.0210,  ...,  0.1036,  0.1412,  0.0147],\n",
      "         [ 0.0137,  0.0351,  0.0068,  ..., -0.0252,  0.1203,  0.0041],\n",
      "         ...,\n",
      "         [-0.6478, -0.1515, -0.1872,  ...,  0.0684, -0.4716, -0.4545],\n",
      "         [-0.6302, -0.1384, -0.1671,  ...,  0.0167, -0.5572, -0.3602],\n",
      "         [-0.6199, -0.1180, -0.1843,  ..., -0.0316, -0.4804, -0.4681]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0050, -0.0119, -0.0166,  ...,  0.0080, -0.0366, -0.0091],\n",
      "         [-0.0602,  0.0347,  0.0438,  ...,  0.0637,  0.1861, -0.0120],\n",
      "         [ 0.3048, -0.1244, -0.0031,  ..., -0.5073,  0.1015,  0.1028],\n",
      "         ...,\n",
      "         [-0.5397, -0.2974, -0.5640,  ..., -0.2553, -0.8030,  0.2432],\n",
      "         [-0.4179, -0.2612, -0.5677,  ..., -0.2459, -0.8516,  0.2811],\n",
      "         [-0.3619, -0.2633, -0.5431,  ..., -0.2621, -0.9160,  0.3157]],\n",
      "\n",
      "        [[ 0.0048, -0.0114, -0.0167,  ...,  0.0079, -0.0366, -0.0091],\n",
      "         [-0.0563,  0.0332, -0.0175,  ...,  0.1304,  0.1199,  0.0707],\n",
      "         [ 0.4092, -0.0843, -0.1196,  ..., -0.1566,  0.2163,  0.1276],\n",
      "         ...,\n",
      "         [-0.3215, -0.2827, -0.1342,  ...,  0.1351, -0.5944, -0.3392],\n",
      "         [-0.3089, -0.2613, -0.1266,  ...,  0.0638, -0.6655, -0.2528],\n",
      "         [-0.3221, -0.2246, -0.1843,  ...,  0.0371, -0.6066, -0.3484]],\n",
      "\n",
      "        [[ 0.0049, -0.0118, -0.0167,  ...,  0.0081, -0.0367, -0.0093],\n",
      "         [-0.0702,  0.0639,  0.0132,  ..., -0.0158,  0.0943, -0.0103],\n",
      "         [ 0.4824,  0.0206, -0.0327,  ..., -0.5330,  0.2147,  0.2660],\n",
      "         ...,\n",
      "         [-0.3303, -0.2187, -0.4910,  ...,  0.0382, -0.8486,  0.1488],\n",
      "         [-0.2838, -0.1868, -0.4841,  ...,  0.0134, -0.9467,  0.2115],\n",
      "         [-0.2914, -0.1920, -0.5064,  ..., -0.0545, -1.0019,  0.2160]]]), tensor([[[ 1.0675e-02, -1.3562e-03, -4.3052e-03,  ...,  9.5097e-03,\n",
      "          -4.1566e-01, -5.6887e-03],\n",
      "         [-1.5673e-01,  2.8214e-02, -2.6928e-01,  ..., -1.6924e-01,\n",
      "          -5.2826e-01,  2.0141e-01],\n",
      "         [-3.2378e-02,  2.2960e-01, -3.5595e-01,  ..., -5.8715e-01,\n",
      "          -3.1663e-01,  2.4717e-02],\n",
      "         ...,\n",
      "         [-3.7950e-01, -1.0571e-01, -1.1056e+00,  ..., -3.1892e-01,\n",
      "          -4.7488e-01, -9.8101e-03],\n",
      "         [-4.0501e-01, -1.1785e-01, -1.0207e+00,  ..., -3.2445e-01,\n",
      "          -4.9569e-01,  9.0375e-02],\n",
      "         [-4.1183e-01, -5.8475e-02, -9.5046e-01,  ..., -3.0849e-01,\n",
      "          -5.1773e-01,  1.2495e-01]],\n",
      "\n",
      "        [[ 1.0866e-02, -1.1281e-03, -4.2195e-03,  ...,  9.3776e-03,\n",
      "          -4.1560e-01, -5.7821e-03],\n",
      "         [ 8.7759e-02,  6.2265e-02, -1.6830e-01,  ...,  1.2038e-01,\n",
      "          -6.0576e-01, -3.6012e-02],\n",
      "         [-1.1852e-01,  1.6288e-01, -2.6923e-01,  ..., -3.2758e-01,\n",
      "          -3.3046e-01, -3.3395e-02],\n",
      "         ...,\n",
      "         [-8.2038e-01, -1.9876e-01, -6.2656e-01,  ..., -3.4261e-01,\n",
      "          -3.4737e-01,  2.5931e-01],\n",
      "         [-9.3643e-01, -2.7506e-01, -8.1513e-01,  ..., -5.7677e-01,\n",
      "          -2.9392e-01,  4.7478e-01],\n",
      "         [-9.3742e-01, -2.2024e-01, -7.6895e-01,  ..., -3.7961e-01,\n",
      "          -3.8345e-01,  5.8099e-01]],\n",
      "\n",
      "        [[ 1.0481e-02, -1.2211e-03, -4.6991e-03,  ...,  9.3947e-03,\n",
      "          -4.1565e-01, -5.5826e-03],\n",
      "         [ 2.1304e-02, -2.3705e-01, -6.2193e-02,  ...,  2.4492e-01,\n",
      "          -6.6244e-01, -2.4849e-02],\n",
      "         [ 7.9624e-03,  7.6089e-03,  1.3082e-03,  ...,  1.4780e-02,\n",
      "          -4.0764e-01,  1.9372e-03],\n",
      "         ...,\n",
      "         [-4.6975e-01, -3.9439e-01, -3.8484e-01,  ..., -8.4118e-03,\n",
      "          -3.6500e-01, -3.6272e-01],\n",
      "         [-4.7099e-01, -3.6268e-01, -3.7296e-01,  ..., -4.1706e-02,\n",
      "          -3.8542e-01, -2.4949e-01],\n",
      "         [-4.6216e-01, -3.6662e-01, -4.0122e-01,  ..., -9.2954e-02,\n",
      "          -3.5731e-01, -4.0366e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0821e-02, -1.2105e-03, -4.4240e-03,  ...,  9.2316e-03,\n",
      "          -4.1561e-01, -5.8788e-03],\n",
      "         [-6.6608e-02, -9.1966e-02,  7.7251e-02,  ..., -1.3829e-02,\n",
      "          -6.4250e-01, -9.0430e-03],\n",
      "         [-1.0307e-02, -2.1643e-02, -2.1010e-01,  ..., -4.4978e-01,\n",
      "          -4.0523e-01, -8.6259e-02],\n",
      "         ...,\n",
      "         [-4.5332e-01, -2.4778e-01, -5.5866e-01,  ..., -4.7334e-01,\n",
      "          -4.3356e-01,  5.4994e-01],\n",
      "         [-3.9813e-01, -2.4026e-01, -5.6649e-01,  ..., -4.6443e-01,\n",
      "          -4.5957e-01,  5.7190e-01],\n",
      "         [-4.1556e-01, -2.7510e-01, -6.0694e-01,  ..., -4.8009e-01,\n",
      "          -4.7846e-01,  6.2867e-01]],\n",
      "\n",
      "        [[ 1.0621e-02, -1.0154e-03, -4.4659e-03,  ...,  9.1785e-03,\n",
      "          -4.1570e-01, -5.7141e-03],\n",
      "         [ 4.3153e-02,  3.1763e-02, -1.8826e-01,  ...,  1.2489e-01,\n",
      "          -6.2217e-01,  1.2633e-01],\n",
      "         [ 2.0655e-01,  7.1248e-02, -2.2216e-01,  ...,  1.5713e-01,\n",
      "          -3.4215e-01,  3.5075e-03],\n",
      "         ...,\n",
      "         [-4.1360e-01, -4.7461e-01, -3.8889e-01,  ...,  2.2691e-01,\n",
      "          -4.4909e-01, -1.9086e-01],\n",
      "         [-3.9172e-01, -4.6182e-01, -3.9483e-01,  ...,  1.1725e-01,\n",
      "          -4.5535e-01, -1.6176e-01],\n",
      "         [-4.0071e-01, -4.3369e-01, -4.5057e-01,  ...,  7.8982e-02,\n",
      "          -4.4264e-01, -2.5769e-01]],\n",
      "\n",
      "        [[ 1.0720e-02, -1.3928e-03, -4.4636e-03,  ...,  9.0629e-03,\n",
      "          -4.1564e-01, -5.6598e-03],\n",
      "         [-3.8263e-02,  6.5022e-02, -2.9802e-01,  ..., -1.2324e-01,\n",
      "          -6.3171e-01, -3.3616e-02],\n",
      "         [ 1.5482e-01,  1.5983e-01, -1.0699e-01,  ..., -3.5949e-01,\n",
      "          -4.3709e-01,  1.3279e-01],\n",
      "         ...,\n",
      "         [-2.6755e-01, -2.6010e-01, -6.5280e-01,  ...,  3.2423e-02,\n",
      "          -5.7776e-01,  3.0696e-01],\n",
      "         [-2.6203e-01, -2.1188e-01, -5.4585e-01,  ...,  2.1064e-02,\n",
      "          -6.2150e-01,  3.7832e-01],\n",
      "         [-3.1215e-01, -2.4154e-01, -5.6435e-01,  ..., -3.9873e-02,\n",
      "          -6.4101e-01,  3.8694e-01]]]), tensor([[[ 1.4530e-03, -1.2955e-02, -7.4375e-03,  ..., -1.6328e-02,\n",
      "          -6.8865e-02, -2.4691e-02],\n",
      "         [ 4.8786e-02,  1.0998e-02, -1.9034e-01,  ..., -3.1881e-01,\n",
      "          -3.8027e-01,  2.8114e-03],\n",
      "         [-2.2560e-02,  1.2030e-01, -2.8454e-01,  ..., -5.0435e-01,\n",
      "          -1.3565e-01,  1.1151e-01],\n",
      "         ...,\n",
      "         [-2.8223e-01,  2.0361e-01, -1.0472e+00,  ..., -1.1039e-01,\n",
      "          -1.0578e-01,  4.0515e-01],\n",
      "         [-2.6625e-01,  1.6411e-01, -9.8259e-01,  ..., -9.8760e-02,\n",
      "          -1.2140e-01,  5.3774e-01],\n",
      "         [-2.1879e-01,  1.6141e-01, -9.5779e-01,  ..., -9.3413e-02,\n",
      "          -1.3847e-01,  5.9104e-01]],\n",
      "\n",
      "        [[ 1.9193e-03, -1.3587e-02, -8.0490e-03,  ..., -1.5611e-02,\n",
      "          -6.8959e-02, -2.4933e-02],\n",
      "         [ 4.5443e-01,  1.9618e-01, -2.1454e-01,  ..., -1.9960e-02,\n",
      "          -3.8129e-01,  1.8495e-01],\n",
      "         [ 1.3078e-01,  1.2450e-01, -3.0259e-01,  ..., -2.8888e-01,\n",
      "          -7.9108e-02,  1.5169e-01],\n",
      "         ...,\n",
      "         [-7.0966e-01, -3.5067e-02, -1.9494e-01,  ..., -2.4399e-01,\n",
      "          -7.0771e-03,  9.1819e-01],\n",
      "         [-7.1336e-01, -1.6451e-01, -4.0282e-01,  ..., -4.3731e-01,\n",
      "           5.9941e-02,  1.0156e+00],\n",
      "         [-6.9855e-01, -7.2364e-02, -3.8903e-01,  ..., -2.3521e-01,\n",
      "          -7.0953e-02,  1.0691e+00]],\n",
      "\n",
      "        [[ 1.4494e-03, -1.3180e-02, -8.8327e-03,  ..., -1.5759e-02,\n",
      "          -6.9031e-02, -2.3632e-02],\n",
      "         [ 4.5957e-01,  7.5044e-02, -2.2134e-01,  ...,  3.0633e-02,\n",
      "          -3.0472e-01, -2.3209e-01],\n",
      "         [ 3.7553e-03, -1.0429e-02, -6.9376e-03,  ..., -1.5115e-02,\n",
      "          -6.8863e-02, -2.6882e-02],\n",
      "         ...,\n",
      "         [-2.2543e-01,  1.2199e-01, -3.0033e-01,  ...,  1.6976e-01,\n",
      "          -7.1844e-03, -3.8223e-02],\n",
      "         [-2.1108e-01,  1.8697e-01, -2.4368e-01,  ...,  1.3644e-01,\n",
      "           1.0117e-02,  6.4688e-02],\n",
      "         [-2.2745e-01,  1.5281e-01, -2.6572e-01,  ...,  7.9747e-02,\n",
      "           2.0462e-02, -6.7330e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.7420e-04, -1.3313e-02, -7.9277e-03,  ..., -1.6112e-02,\n",
      "          -6.8913e-02, -2.4867e-02],\n",
      "         [ 2.0775e-01, -3.1621e-02,  2.2440e-01,  ..., -1.5160e-01,\n",
      "          -3.4918e-01, -2.8770e-01],\n",
      "         [ 1.0420e-01,  1.7570e-02, -1.3621e-01,  ..., -3.6910e-01,\n",
      "          -1.8828e-01, -1.1474e-01],\n",
      "         ...,\n",
      "         [-1.9451e-01, -4.4623e-02, -3.7394e-01,  ..., -3.2185e-01,\n",
      "          -7.7808e-02,  1.0207e+00],\n",
      "         [-1.4614e-01, -3.4400e-02, -3.6625e-01,  ..., -3.1940e-01,\n",
      "          -1.0052e-01,  1.0884e+00],\n",
      "         [-1.6659e-01, -9.0810e-02, -4.3534e-01,  ..., -3.0765e-01,\n",
      "          -9.2257e-02,  1.0656e+00]],\n",
      "\n",
      "        [[ 5.7523e-04, -1.3262e-02, -8.0865e-03,  ..., -1.6914e-02,\n",
      "          -6.9066e-02, -2.5084e-02],\n",
      "         [ 1.4422e-01,  3.9584e-02, -1.3826e-02,  ..., -3.3137e-02,\n",
      "          -4.8659e-01,  1.2179e-01],\n",
      "         [ 1.2584e-01,  5.8865e-02, -1.4075e-01,  ...,  1.2150e-01,\n",
      "          -1.2380e-01,  5.3900e-02],\n",
      "         ...,\n",
      "         [-4.5332e-01, -1.4210e-01, -3.3685e-01,  ...,  2.0998e-01,\n",
      "          -9.6518e-02,  9.8557e-02],\n",
      "         [-4.6094e-01, -1.1769e-01, -3.4034e-01,  ...,  1.1604e-01,\n",
      "          -8.1785e-02,  1.5974e-01],\n",
      "         [-4.2776e-01, -9.9517e-02, -3.7789e-01,  ...,  9.1803e-02,\n",
      "          -7.1915e-02,  1.0251e-01]],\n",
      "\n",
      "        [[ 1.4184e-03, -1.3410e-02, -8.3097e-03,  ..., -1.6921e-02,\n",
      "          -6.9138e-02, -2.4732e-02],\n",
      "         [ 1.7365e-01,  7.0479e-02, -3.9979e-02,  ..., -3.9869e-01,\n",
      "          -3.9681e-01,  1.2379e-01],\n",
      "         [ 6.9602e-02,  1.2470e-01, -1.2860e-01,  ..., -5.2871e-02,\n",
      "          -1.9160e-01,  2.4155e-01],\n",
      "         ...,\n",
      "         [-5.5187e-02, -9.8790e-03, -6.2375e-01,  ...,  2.8322e-01,\n",
      "          -2.5715e-01,  6.3985e-01],\n",
      "         [-2.6436e-02,  8.5159e-03, -5.5260e-01,  ...,  2.5040e-01,\n",
      "          -2.8429e-01,  7.6895e-01],\n",
      "         [-5.3955e-02, -4.6305e-02, -5.9037e-01,  ...,  2.1508e-01,\n",
      "          -2.9341e-01,  7.8892e-01]]]), tensor([[[ 2.6837,  2.9695,  0.8969,  ...,  1.7202, -0.2717, -0.7455],\n",
      "         [-0.0071, -0.9084,  0.5381,  ..., -0.9120, -0.6716,  1.3906],\n",
      "         [-0.5369, -0.2518,  0.9767,  ..., -1.9545,  0.8887,  0.7203],\n",
      "         ...,\n",
      "         [ 0.3724,  0.7484, -1.2030,  ...,  0.6042,  2.1771,  0.1849],\n",
      "         [ 0.3853,  0.7129, -1.0359,  ...,  0.7167,  2.0977,  0.2459],\n",
      "         [ 0.5141,  0.6767, -0.9507,  ...,  0.7219,  1.9052,  0.3406]],\n",
      "\n",
      "        [[ 2.8937,  2.8159,  1.5305,  ...,  1.6797,  0.0060, -0.5757],\n",
      "         [ 1.1647,  0.1950,  0.0895,  ..., -0.2672,  0.1605,  0.7566],\n",
      "         [ 0.4006,  0.4844, -0.1920,  ..., -0.8372,  1.1212,  0.5445],\n",
      "         ...,\n",
      "         [-0.6605, -1.0961,  0.5975,  ..., -0.2340,  3.4569,  1.6936],\n",
      "         [-0.9929, -1.5113, -0.1437,  ..., -0.7352,  4.4660,  2.0448],\n",
      "         [-0.2323, -1.0247,  0.4597,  ..., -0.6488,  3.6079,  2.3805]],\n",
      "\n",
      "        [[ 3.1126,  2.2533,  1.3099,  ...,  1.5216,  0.1160, -0.1589],\n",
      "         [ 1.5152,  1.1322, -0.9895,  ..., -0.3688,  1.3004,  0.0073],\n",
      "         [ 3.0579,  2.2504,  0.9374,  ...,  0.9610,  0.4308,  0.1705],\n",
      "         ...,\n",
      "         [ 0.1633,  1.0793,  0.8765,  ..., -0.3663,  3.1380,  0.0598],\n",
      "         [ 0.1569,  1.2123,  0.9606,  ..., -0.2203,  3.1027,  0.0791],\n",
      "         [ 0.2127,  1.1981,  0.9972,  ..., -0.4697,  3.0477, -0.0974]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.9539,  2.1810,  1.0747,  ...,  1.5075, -0.0942, -0.8264],\n",
      "         [ 0.2842, -0.7553,  0.5875,  ..., -1.0129, -0.2533, -0.4058],\n",
      "         [ 0.3183, -0.7112, -0.1096,  ..., -1.2105,  0.5868, -0.3071],\n",
      "         ...,\n",
      "         [-0.1695, -0.7401,  0.5159,  ...,  0.1926,  2.5207,  0.9636],\n",
      "         [-0.1290, -0.7607,  0.5007,  ...,  0.2226,  2.5112,  1.1525],\n",
      "         [-0.1083, -1.1935,  0.6455,  ...,  0.3041,  2.4924,  1.4218]],\n",
      "\n",
      "        [[ 2.8360,  3.0149,  1.2280,  ...,  1.6458,  0.0575, -0.7242],\n",
      "         [ 0.9168, -0.0518,  2.0337,  ...,  0.0470, -0.4715, -0.8772],\n",
      "         [ 0.5604, -0.1518,  0.8296,  ...,  0.1360,  0.5207,  0.3893],\n",
      "         ...,\n",
      "         [-0.2946,  0.1324,  0.2810,  ...,  0.2189,  2.2096, -0.6477],\n",
      "         [-0.2416,  0.1657,  0.2843,  ...,  0.0965,  2.2745, -0.5750],\n",
      "         [-0.1639,  0.2243,  0.4338,  ...,  0.0080,  2.3303, -0.5129]],\n",
      "\n",
      "        [[ 2.5396,  2.7404,  1.2003,  ...,  1.7519,  0.1862, -0.8466],\n",
      "         [ 1.0002,  0.3090,  1.6184,  ..., -2.3428,  0.1840,  0.2893],\n",
      "         [ 0.3406,  0.3771,  0.7987,  ..., -0.9567, -0.1660,  0.6873],\n",
      "         ...,\n",
      "         [ 0.2283, -0.0447,  0.1117,  ...,  1.0812,  2.0197,  0.5255],\n",
      "         [ 0.2510, -0.0358,  0.2628,  ...,  1.0469,  1.9749,  0.6765],\n",
      "         [ 0.2508, -0.4122,  0.1762,  ...,  1.0169,  2.0191,  0.7934]]])), decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-3.6129e-02,  9.1240e-03, -1.4751e-03,  ...,  1.1482e-02,\n",
      "          -6.7449e-04, -1.4217e-02],\n",
      "         [ 6.7012e-02,  1.8187e-01,  1.9371e-01,  ...,  2.4564e-01,\n",
      "           6.2073e-03,  6.6426e-02],\n",
      "         [-1.0329e-01,  3.1610e-01, -2.1937e-01,  ..., -5.2982e-02,\n",
      "           2.6652e-01, -8.6021e-02],\n",
      "         ...,\n",
      "         [ 7.3676e-02,  1.5398e-01,  5.9229e-03,  ...,  8.2163e-02,\n",
      "           1.7777e-01,  1.7355e-03],\n",
      "         [ 5.6092e-02,  1.1218e-01,  2.5662e-02,  ...,  5.2705e-02,\n",
      "           2.3076e-01,  1.9417e-02],\n",
      "         [ 6.8653e-02,  1.8225e-01,  3.5246e-03,  ...,  5.1164e-02,\n",
      "           2.1293e-01,  6.2443e-02]],\n",
      "\n",
      "        [[-3.5228e-02,  9.2666e-03, -2.2089e-03,  ...,  1.2941e-02,\n",
      "          -1.0351e-03, -9.1841e-03],\n",
      "         [ 3.4123e-01,  2.8960e-01,  3.2430e-01,  ...,  3.0643e-01,\n",
      "          -3.8141e-02,  2.6084e-01],\n",
      "         [ 3.3619e-01,  2.0724e-01,  8.4063e-02,  ...,  1.1022e-01,\n",
      "           4.3447e-03,  4.6777e-02],\n",
      "         ...,\n",
      "         [ 2.5506e-02,  3.8516e-02,  2.0514e-03,  ...,  4.5444e-02,\n",
      "           7.6416e-02, -1.1356e-02],\n",
      "         [ 5.1186e-02,  4.5249e-02,  4.3770e-03,  ...,  3.0464e-02,\n",
      "           6.7231e-02, -9.1665e-03],\n",
      "         [ 1.9701e-01,  7.4675e-02,  3.1060e-02,  ...,  3.4965e-02,\n",
      "           1.3926e-01,  8.6132e-02]],\n",
      "\n",
      "        [[-3.6947e-02,  9.1366e-03, -1.3525e-03,  ...,  1.1634e-02,\n",
      "          -3.2088e-04, -1.4903e-02],\n",
      "         [ 6.6383e-02,  2.4398e-01,  4.0892e-02,  ..., -4.0230e-02,\n",
      "          -1.7796e-02,  3.3576e-01],\n",
      "         [-5.5470e-02,  6.1721e-03, -7.4205e-02,  ...,  3.0518e-02,\n",
      "           3.4213e-01,  2.5760e-01],\n",
      "         ...,\n",
      "         [ 1.3688e-01,  2.1415e-01,  7.7179e-03,  ..., -2.3508e-02,\n",
      "           1.5232e-01,  7.9360e-02],\n",
      "         [ 5.4047e-02,  1.1581e-01, -1.6243e-02,  ..., -8.8864e-03,\n",
      "           1.0170e-01, -5.4642e-03],\n",
      "         [ 3.1826e-01,  4.9857e-02,  4.1764e-02,  ...,  9.2379e-02,\n",
      "           3.9597e-01,  2.2416e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.6260e-02,  8.1214e-03, -1.5878e-03,  ...,  1.1164e-02,\n",
      "          -1.2986e-03, -1.2346e-02],\n",
      "         [ 2.5320e-02,  2.7399e-01,  2.9088e-01,  ...,  2.3433e-01,\n",
      "          -1.4089e-01,  9.7892e-03],\n",
      "         [-3.8576e-01,  1.2572e-01, -1.6393e-01,  ...,  1.2181e-01,\n",
      "           1.9731e-01, -1.1871e-01],\n",
      "         ...,\n",
      "         [ 9.3085e-02,  9.6632e-02,  3.9767e-02,  ...,  9.1458e-02,\n",
      "           2.7981e-02, -5.5132e-02],\n",
      "         [ 6.6780e-02,  1.4450e-01,  2.2583e-02,  ...,  9.6999e-02,\n",
      "           5.4896e-02, -2.0177e-02],\n",
      "         [ 8.9733e-02,  1.2201e-01,  3.9500e-02,  ...,  6.2466e-02,\n",
      "           2.5100e-02, -4.3362e-02]],\n",
      "\n",
      "        [[-3.7000e-02,  8.0296e-03, -1.3300e-03,  ...,  1.1774e-02,\n",
      "          -6.8020e-04, -1.3952e-02],\n",
      "         [ 1.2362e-01,  9.4678e-02,  3.9525e-01,  ...,  3.2237e-02,\n",
      "          -5.5194e-02,  2.8022e-01],\n",
      "         [-1.0121e-02,  2.4671e-01,  1.2983e-01,  ..., -1.2061e-01,\n",
      "           3.5894e-01, -2.6015e-01],\n",
      "         ...,\n",
      "         [ 1.5629e-01,  1.4300e-01,  2.1537e-02,  ...,  6.7436e-03,\n",
      "           1.4630e-01,  7.5624e-02],\n",
      "         [ 4.8153e-02,  9.4897e-02,  1.5052e-02,  ..., -2.9418e-03,\n",
      "           5.1530e-02, -3.6436e-02],\n",
      "         [ 5.9341e-02,  1.2286e-01, -1.0554e-02,  ..., -2.2111e-02,\n",
      "           6.1589e-02, -5.5112e-02]],\n",
      "\n",
      "        [[-3.6560e-02,  8.1692e-03, -1.8117e-03,  ...,  1.1835e-02,\n",
      "          -2.1563e-03, -1.1573e-02],\n",
      "         [ 1.0846e-02,  2.1092e-01,  6.9563e-01,  ...,  9.8351e-02,\n",
      "          -2.6919e-01,  2.3842e-01],\n",
      "         [-4.7626e-03,  2.2165e-01,  2.4216e-01,  ...,  3.4942e-02,\n",
      "          -1.5979e-01,  1.0929e-01],\n",
      "         ...,\n",
      "         [ 7.8274e-02,  1.6699e-01, -4.8045e-03,  ...,  7.1776e-02,\n",
      "           1.2471e-01, -6.7089e-02],\n",
      "         [ 5.7450e-02,  2.0277e-01,  4.2214e-02,  ...,  1.1132e-01,\n",
      "           2.4535e-01,  6.9357e-02],\n",
      "         [ 1.1782e-01,  1.8735e-01,  3.4115e-02,  ...,  6.2140e-02,\n",
      "           3.3094e-01,  1.3443e-01]]]), encoder_hidden_states=(tensor([[[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [-0.3673,  0.0091,  0.1048,  ..., -0.5179, -0.0295, -0.2487],\n",
      "         [-0.1537,  0.2673, -0.5857,  ..., -0.0851,  0.1377,  0.1154],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.3475, -0.0152,  0.4136,  ...,  0.1141, -0.0854,  0.0133],\n",
      "         [-0.4189, -0.1118, -0.0572,  ..., -0.3104,  0.1661,  0.6862],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.2938,  0.8176, -0.2142,  ..., -0.2330,  0.3738, -0.3281],\n",
      "         [-0.2213, -0.5148,  0.0299,  ...,  0.1134,  0.0574,  0.2151],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.4379,  0.0074,  0.4272,  ..., -0.1031, -0.3134, -0.1137],\n",
      "         [-0.3545,  0.3377, -0.1916,  ..., -0.2353, -0.0399, -0.1613],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.5401, -0.3418,  0.3916,  ...,  0.2086,  0.0869, -0.2052],\n",
      "         [-0.1843, -0.5743,  0.6169,  ..., -0.6394, -0.1904, -0.1164],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.5054, -0.4804,  0.1864,  ...,  0.0910,  0.1165,  0.2355],\n",
      "         [-0.0372, -0.2468,  0.0466,  ...,  0.0590, -0.2413,  0.1013],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]]]), tensor([[[-0.0309, -0.0383,  0.0471,  ...,  0.0195, -0.0387,  0.0115],\n",
      "         [-0.4643, -0.0635,  0.1779,  ...,  0.2870, -0.1126,  0.0926],\n",
      "         [ 0.0310,  0.1947, -0.6891,  ...,  0.2247,  0.2251, -0.0269],\n",
      "         ...,\n",
      "         [ 0.3129,  0.4475,  0.0960,  ...,  0.3475,  0.5457, -0.2325],\n",
      "         [ 0.3922,  0.4581,  0.0072,  ...,  0.6767,  0.4158, -0.1693],\n",
      "         [ 0.4923,  0.3262, -0.1513,  ...,  0.7056,  0.3551,  0.0604]],\n",
      "\n",
      "        [[-0.0423, -0.0341,  0.0687,  ...,  0.0255, -0.0404,  0.0292],\n",
      "         [ 0.4717, -0.0795,  0.8536,  ...,  0.3661,  0.2025,  0.2670],\n",
      "         [-0.0562,  0.2691,  0.1756,  ..., -0.3620, -0.3383,  0.4561],\n",
      "         ...,\n",
      "         [ 0.0283,  0.5138,  0.1699,  ...,  0.6155,  0.3721, -0.3302],\n",
      "         [ 0.2622,  0.5426,  0.1347,  ...,  0.7233,  0.4019, -0.1342],\n",
      "         [ 0.5439,  0.3913, -0.1474,  ...,  0.9094,  0.3715,  0.0419]],\n",
      "\n",
      "        [[-0.0418, -0.0257,  0.0501,  ...,  0.0188, -0.0230,  0.0222],\n",
      "         [ 0.4317,  0.6118, -0.1231,  ...,  0.4960,  0.5437, -0.2010],\n",
      "         [-0.1128, -0.2233,  0.1163,  ...,  0.1227,  0.3432,  0.2962],\n",
      "         ...,\n",
      "         [ 0.4140,  0.6154,  0.0459,  ...,  0.1854,  0.5056, -0.2354],\n",
      "         [ 0.3610,  0.5982, -0.0594,  ...,  0.5081,  0.5082,  0.0330],\n",
      "         [ 0.6050,  0.2712, -0.1676,  ...,  0.6521,  0.3760,  0.1610]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0563, -0.0258,  0.0579,  ...,  0.0164, -0.0283,  0.0190],\n",
      "         [ 0.2119, -0.2038,  0.5611,  ...,  0.4033, -0.1646,  0.1357],\n",
      "         [-0.6640,  0.3153, -0.4410,  ...,  0.0211,  0.3483,  0.1179],\n",
      "         ...,\n",
      "         [ 0.4251,  0.3239,  0.1159,  ...,  0.3915,  0.4728, -0.0531],\n",
      "         [ 0.3884,  0.4383, -0.0109,  ...,  0.7894,  0.6176,  0.3498],\n",
      "         [ 0.6801,  0.1906, -0.1738,  ...,  0.7608,  0.4776,  0.0385]],\n",
      "\n",
      "        [[-0.0333, -0.0286,  0.0466,  ...,  0.0294, -0.0300,  0.0173],\n",
      "         [ 0.4288, -0.1014,  0.5091,  ...,  0.4382,  0.1610,  0.2251],\n",
      "         [ 0.1792, -0.5386,  0.4233,  ..., -0.3308, -0.0019, -0.5227],\n",
      "         ...,\n",
      "         [ 0.4947,  0.6514,  0.0236,  ...,  0.2276,  0.4996, -0.0554],\n",
      "         [ 0.5171,  0.5840,  0.1002,  ...,  0.5466,  0.4716,  0.0976],\n",
      "         [ 0.5716,  0.4465, -0.1614,  ...,  0.7550,  0.3885,  0.2272]],\n",
      "\n",
      "        [[-0.0492, -0.0258,  0.0546,  ...,  0.0209, -0.0272,  0.0234],\n",
      "         [ 0.4941, -0.4361,  0.5559,  ...,  0.3994, -0.0105,  0.4206],\n",
      "         [ 0.3602, -0.0771,  0.1426,  ...,  0.1810, -0.5211, -0.0607],\n",
      "         ...,\n",
      "         [ 0.2073,  0.6500,  0.1276,  ...,  0.6516,  0.5980, -0.2178],\n",
      "         [ 0.3862,  0.6315,  0.1329,  ...,  0.6608,  0.4295,  0.0465],\n",
      "         [ 0.5207,  0.3661, -0.0715,  ...,  0.8261,  0.4292,  0.1263]]]), tensor([[[-5.8961e-02, -1.5729e-03,  3.3526e-02,  ..., -3.8219e-02,\n",
      "          -6.5115e-02, -7.8551e-03],\n",
      "         [-4.9127e-01, -1.1180e-01,  2.9562e-01,  ...,  3.4740e-01,\n",
      "           3.4371e-02,  5.8198e-01],\n",
      "         [ 2.1119e-02,  3.2091e-02, -4.8446e-01,  ...,  2.2715e-01,\n",
      "           2.7935e-01,  3.4283e-02],\n",
      "         ...,\n",
      "         [ 2.8697e-01,  4.3041e-01,  1.9718e-01,  ...,  2.0218e-01,\n",
      "           7.2957e-01, -2.4279e-01],\n",
      "         [ 3.0419e-01,  4.9565e-01,  7.1430e-02,  ...,  3.6704e-01,\n",
      "           6.2168e-01, -3.0876e-01],\n",
      "         [ 3.9001e-01,  5.3621e-01, -4.9558e-02,  ...,  4.5337e-01,\n",
      "           6.2435e-01, -1.1976e-01]],\n",
      "\n",
      "        [[-6.4737e-02,  4.5216e-03,  4.8211e-02,  ..., -3.4380e-02,\n",
      "          -4.6683e-02,  9.6878e-03],\n",
      "         [ 5.1011e-01,  4.1003e-01,  9.3508e-01,  ...,  3.4308e-01,\n",
      "           3.8980e-01,  8.0685e-01],\n",
      "         [ 2.1097e-01,  3.3622e-01,  5.6555e-02,  ..., -8.9389e-03,\n",
      "          -1.7058e-01,  2.2065e-01],\n",
      "         ...,\n",
      "         [-1.9071e-02,  5.9770e-01,  2.3831e-01,  ...,  3.2239e-01,\n",
      "           5.8771e-01, -2.8323e-01],\n",
      "         [ 2.4532e-01,  5.7178e-01,  1.6449e-01,  ...,  3.3965e-01,\n",
      "           6.3979e-01, -2.2286e-01],\n",
      "         [ 5.8804e-01,  4.9786e-01, -5.0581e-03,  ...,  5.1000e-01,\n",
      "           5.1991e-01,  1.1003e-02]],\n",
      "\n",
      "        [[-6.9274e-02,  1.8631e-03,  3.7275e-02,  ..., -3.6394e-02,\n",
      "          -5.5981e-02,  8.0463e-04],\n",
      "         [ 2.0498e-01,  4.8330e-01, -3.4757e-03,  ...,  5.2576e-01,\n",
      "           7.1555e-01,  2.0089e-01],\n",
      "         [-1.8080e-01, -5.9261e-03,  1.8165e-01,  ...,  1.8794e-02,\n",
      "           5.5182e-01,  2.2495e-01],\n",
      "         ...,\n",
      "         [ 4.6536e-01,  2.8468e-01,  1.6300e-01,  ...,  6.4636e-02,\n",
      "           6.9445e-01, -7.8836e-03],\n",
      "         [ 3.3162e-01,  3.6029e-01,  3.1357e-02,  ...,  2.1970e-01,\n",
      "           7.7218e-01,  6.7409e-02],\n",
      "         [ 6.8420e-01,  3.7768e-01,  2.0329e-02,  ...,  4.2642e-01,\n",
      "           6.3249e-01,  1.4649e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.5585e-02,  1.0081e-02,  3.5922e-02,  ..., -2.7217e-02,\n",
      "          -5.1606e-02,  1.3479e-03],\n",
      "         [ 3.9045e-02, -5.7584e-02,  7.1432e-01,  ...,  3.5684e-01,\n",
      "           6.5695e-02,  7.7563e-01],\n",
      "         [-9.2108e-01,  2.6399e-01, -5.1743e-01,  ...,  2.6115e-01,\n",
      "           4.4089e-01,  1.8460e-01],\n",
      "         ...,\n",
      "         [ 3.4300e-01,  3.5672e-01,  2.8657e-01,  ...,  2.0552e-01,\n",
      "           6.3537e-01, -1.2704e-01],\n",
      "         [ 3.4375e-01,  4.3733e-01,  1.1183e-01,  ...,  6.7018e-01,\n",
      "           8.0188e-01,  9.2689e-02],\n",
      "         [ 6.0161e-01,  3.7217e-01, -9.3733e-04,  ...,  4.9257e-01,\n",
      "           7.1225e-01, -8.5821e-02]],\n",
      "\n",
      "        [[-6.2324e-02,  8.1191e-03,  3.1067e-02,  ..., -3.6112e-02,\n",
      "          -6.0862e-02,  4.8813e-03],\n",
      "         [ 4.1829e-01,  4.9199e-02,  6.3120e-01,  ...,  4.7920e-01,\n",
      "           2.6717e-01,  8.3445e-01],\n",
      "         [ 1.0490e-02, -3.0690e-01,  4.2782e-01,  ..., -1.9130e-01,\n",
      "           3.4787e-01, -2.3438e-01],\n",
      "         ...,\n",
      "         [ 5.3836e-01,  4.3426e-01,  2.4666e-01,  ...,  8.5329e-02,\n",
      "           7.3982e-01, -1.2800e-01],\n",
      "         [ 5.0663e-01,  5.0572e-01,  1.3380e-01,  ...,  2.1852e-01,\n",
      "           7.4419e-01, -1.4611e-01],\n",
      "         [ 5.8741e-01,  5.1373e-01, -1.3873e-02,  ...,  4.4503e-01,\n",
      "           6.2979e-01, -1.5810e-01]],\n",
      "\n",
      "        [[-6.1430e-02,  7.1429e-03,  3.2753e-02,  ..., -3.6010e-02,\n",
      "          -5.6583e-02, -6.8704e-03],\n",
      "         [ 4.8485e-01,  4.8736e-03,  8.0019e-01,  ...,  5.1380e-01,\n",
      "          -3.8261e-03,  1.0032e+00],\n",
      "         [ 3.8019e-01,  1.7947e-01,  8.4474e-02,  ...,  3.7499e-01,\n",
      "          -4.5186e-01,  1.3448e-01],\n",
      "         ...,\n",
      "         [ 2.1339e-01,  6.7282e-01,  1.9463e-01,  ...,  4.7133e-01,\n",
      "           7.5223e-01, -3.2049e-01],\n",
      "         [ 3.2879e-01,  6.9830e-01,  1.3647e-01,  ...,  4.2393e-01,\n",
      "           5.9969e-01, -2.1760e-01],\n",
      "         [ 4.8170e-01,  6.9216e-01,  1.3091e-03,  ...,  5.7772e-01,\n",
      "           5.9725e-01, -9.9924e-02]]]), tensor([[[-6.5146e-02,  1.8294e-02,  6.9177e-03,  ..., -1.1348e-02,\n",
      "          -8.6925e-03,  2.5167e-03],\n",
      "         [-4.5656e-01,  7.3260e-02,  3.7021e-01,  ...,  2.2242e-01,\n",
      "          -1.0372e-02,  8.4612e-01],\n",
      "         [-2.6265e-01,  2.0003e-01, -3.0698e-01,  ...,  5.0448e-02,\n",
      "           1.7433e-01,  8.4348e-02],\n",
      "         ...,\n",
      "         [ 7.2466e-02, -1.3768e-02,  2.7320e-01,  ...,  2.2088e-01,\n",
      "           5.9156e-01,  1.9304e-01],\n",
      "         [ 1.4079e-01, -3.0093e-02,  2.0655e-01,  ...,  4.4096e-01,\n",
      "           5.6474e-01,  1.5493e-01],\n",
      "         [ 2.3030e-01,  5.6001e-02,  7.5624e-02,  ...,  4.6123e-01,\n",
      "           4.9995e-01,  3.2853e-01]],\n",
      "\n",
      "        [[-6.5752e-02,  2.4087e-02,  1.0010e-02,  ..., -9.6115e-03,\n",
      "          -2.3942e-03,  3.0213e-04],\n",
      "         [ 6.0407e-01,  5.4321e-01,  8.7666e-01,  ...,  4.6989e-01,\n",
      "           2.2692e-01,  5.8153e-01],\n",
      "         [ 1.6149e-01,  4.7356e-01,  1.1571e-01,  ...,  8.4469e-02,\n",
      "          -1.9119e-01, -2.2313e-01],\n",
      "         ...,\n",
      "         [-6.6127e-02, -5.0029e-02,  3.2158e-01,  ...,  4.0449e-01,\n",
      "           4.9121e-01,  6.2359e-02],\n",
      "         [ 1.9989e-01, -6.4328e-02,  2.7862e-01,  ...,  4.0487e-01,\n",
      "           5.2002e-01,  1.0924e-01],\n",
      "         [ 4.9315e-01, -1.0633e-01,  1.1094e-01,  ...,  4.8415e-01,\n",
      "           4.4137e-01,  2.9102e-01]],\n",
      "\n",
      "        [[-6.5930e-02,  2.0475e-02,  1.1413e-02,  ..., -2.4061e-02,\n",
      "          -9.2169e-03, -1.3998e-04],\n",
      "         [ 6.6251e-02,  3.7439e-01,  3.0199e-02,  ...,  5.7632e-01,\n",
      "           4.8120e-01,  5.7002e-01],\n",
      "         [-2.0346e-01,  1.1237e-01, -6.0347e-02,  ...,  1.4560e-01,\n",
      "           4.8862e-01,  4.3376e-01],\n",
      "         ...,\n",
      "         [ 1.3042e-01, -1.5200e-01,  1.9554e-01,  ..., -9.1254e-04,\n",
      "           5.4875e-01,  1.4623e-01],\n",
      "         [ 5.5666e-02, -1.2230e-01,  7.4328e-02,  ...,  3.1098e-01,\n",
      "           6.3254e-01,  2.7820e-01],\n",
      "         [ 4.2175e-01, -2.4500e-01,  3.3979e-02,  ...,  3.8110e-01,\n",
      "           5.9715e-01,  3.4404e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.9938e-02,  2.2973e-02,  1.2767e-02,  ..., -1.8590e-02,\n",
      "          -4.2296e-03,  4.3405e-03],\n",
      "         [ 1.2056e-01,  3.3153e-01,  7.3740e-01,  ...,  5.4264e-01,\n",
      "          -7.0931e-02,  8.0321e-01],\n",
      "         [-1.0560e+00,  8.2887e-02, -4.9074e-01,  ...,  1.7117e-01,\n",
      "           3.7928e-01, -1.5779e-01],\n",
      "         ...,\n",
      "         [ 1.3691e-01, -4.7388e-02,  3.9724e-01,  ...,  3.4110e-01,\n",
      "           3.9126e-01,  1.8059e-01],\n",
      "         [ 1.2608e-01, -3.5642e-02,  2.6250e-01,  ...,  7.2603e-01,\n",
      "           6.6093e-01,  4.1434e-01],\n",
      "         [ 2.8894e-01, -6.2457e-02,  2.0410e-01,  ...,  6.1628e-01,\n",
      "           4.3863e-01,  3.1270e-01]],\n",
      "\n",
      "        [[-6.5476e-02,  2.2253e-02,  7.1623e-03,  ..., -1.8777e-02,\n",
      "          -1.1818e-02,  4.1542e-03],\n",
      "         [ 1.1582e-01,  2.9058e-01,  7.7717e-01,  ...,  1.2192e-01,\n",
      "           9.9078e-03,  1.0697e+00],\n",
      "         [-9.0909e-02, -1.9507e-01,  3.6666e-01,  ..., -2.8136e-01,\n",
      "           4.0228e-01, -1.2009e-01],\n",
      "         ...,\n",
      "         [ 1.7436e-01, -1.9710e-01,  1.4435e-01,  ...,  3.9025e-02,\n",
      "           5.7223e-01,  2.5511e-01],\n",
      "         [ 1.8341e-01, -1.0324e-01,  1.1516e-01,  ...,  2.0040e-01,\n",
      "           5.8806e-01,  2.4123e-01],\n",
      "         [ 2.7031e-01, -1.1994e-01, -1.2559e-02,  ...,  2.6447e-01,\n",
      "           4.7744e-01,  3.0726e-01]],\n",
      "\n",
      "        [[-6.7022e-02,  2.2163e-02,  6.0307e-03,  ..., -1.3327e-02,\n",
      "          -4.8663e-03, -1.7756e-03],\n",
      "         [ 4.2021e-01,  2.4606e-01,  9.0176e-01,  ...,  3.7249e-01,\n",
      "          -1.3508e-01,  9.6389e-01],\n",
      "         [ 2.6983e-01,  1.4249e-01,  1.3012e-01,  ...,  1.9929e-01,\n",
      "          -3.9553e-01,  2.3246e-01],\n",
      "         ...,\n",
      "         [ 1.2337e-02,  1.3480e-01,  2.0517e-01,  ...,  5.0672e-01,\n",
      "           6.2348e-01,  1.6469e-01],\n",
      "         [ 2.0402e-01,  6.5319e-02,  2.0890e-01,  ...,  6.1830e-01,\n",
      "           5.5332e-01,  1.7559e-01],\n",
      "         [ 2.6611e-01, -1.1065e-02,  9.3026e-02,  ...,  6.1626e-01,\n",
      "           5.6845e-01,  3.9220e-01]]]), tensor([[[-0.0864,  0.0262, -0.0099,  ...,  0.0473,  0.0054, -0.0067],\n",
      "         [-0.1130,  0.0642,  0.3037,  ...,  0.5893,  0.0632,  0.3031],\n",
      "         [ 0.0160,  0.4358, -0.2863,  ..., -0.0503,  0.4450,  0.0779],\n",
      "         ...,\n",
      "         [ 0.2696,  0.0418,  0.2998,  ...,  0.3184,  0.5986,  0.1284],\n",
      "         [ 0.3285, -0.0636,  0.2435,  ...,  0.4825,  0.6270,  0.0800],\n",
      "         [ 0.4127,  0.0167,  0.1655,  ...,  0.4988,  0.5314,  0.2514]],\n",
      "\n",
      "        [[-0.0910,  0.0240, -0.0080,  ...,  0.0437,  0.0050, -0.0053],\n",
      "         [ 0.8278,  0.5049,  0.8109,  ...,  0.5702,  0.0737,  0.2323],\n",
      "         [ 0.4318,  0.5103,  0.2149,  ...,  0.4038, -0.0786, -0.1598],\n",
      "         ...,\n",
      "         [ 0.2023,  0.0279,  0.2868,  ...,  0.2254,  0.4325,  0.1390],\n",
      "         [ 0.3700,  0.0258,  0.2538,  ...,  0.2306,  0.5029,  0.2046],\n",
      "         [ 0.7814,  0.0689,  0.1079,  ...,  0.3208,  0.5168,  0.1537]],\n",
      "\n",
      "        [[-0.0860,  0.0264, -0.0117,  ...,  0.0479,  0.0039, -0.0068],\n",
      "         [ 0.1191,  0.4121,  0.1202,  ...,  0.5780,  0.2627,  0.6967],\n",
      "         [ 0.1016,  0.0250, -0.0086,  ...,  0.2171,  0.7453,  0.4734],\n",
      "         ...,\n",
      "         [ 0.3901, -0.0977,  0.1767,  ...,  0.2078,  0.6145,  0.2980],\n",
      "         [ 0.1833, -0.0408,  0.0390,  ...,  0.2761,  0.6169,  0.3621],\n",
      "         [ 0.6384, -0.2300,  0.1177,  ...,  0.5355,  0.8539,  0.3086]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0891,  0.0283, -0.0115,  ...,  0.0457,  0.0051, -0.0090],\n",
      "         [ 0.2336,  0.5246,  0.7424,  ...,  0.6527, -0.1038,  0.3393],\n",
      "         [-0.7993, -0.0049, -0.3538,  ...,  0.2921,  0.4688, -0.2534],\n",
      "         ...,\n",
      "         [ 0.2981,  0.1927,  0.3613,  ...,  0.2057,  0.3600,  0.1758],\n",
      "         [ 0.3135,  0.1350,  0.2175,  ...,  0.5541,  0.6517,  0.2652],\n",
      "         [ 0.4458,  0.2025,  0.2231,  ...,  0.3557,  0.3898,  0.3099]],\n",
      "\n",
      "        [[-0.0875,  0.0275, -0.0124,  ...,  0.0499,  0.0038, -0.0085],\n",
      "         [ 0.2544,  0.1629,  0.6828,  ...,  0.0762,  0.0175,  0.6875],\n",
      "         [-0.0637,  0.0357,  0.3289,  ..., -0.2310,  0.7794, -0.0738],\n",
      "         ...,\n",
      "         [ 0.4300, -0.1338,  0.2253,  ...,  0.2529,  0.6732,  0.3379],\n",
      "         [ 0.3511, -0.0469,  0.1647,  ...,  0.3497,  0.5873,  0.2753],\n",
      "         [ 0.4419,  0.0131, -0.0104,  ...,  0.2850,  0.4921,  0.3913]],\n",
      "\n",
      "        [[-0.0872,  0.0249, -0.0102,  ...,  0.0476,  0.0059, -0.0071],\n",
      "         [ 0.5852,  0.0030,  1.0677,  ...,  0.1863, -0.3184,  0.6776],\n",
      "         [ 0.1667,  0.3128,  0.0894,  ...,  0.2971, -0.1637,  0.2967],\n",
      "         ...,\n",
      "         [ 0.1911,  0.2933,  0.2218,  ...,  0.4033,  0.6479,  0.1262],\n",
      "         [ 0.3876,  0.0613,  0.1952,  ...,  0.6790,  0.6749,  0.1480],\n",
      "         [ 0.4980,  0.0219,  0.1203,  ...,  0.6568,  0.7525,  0.2794]]]), tensor([[[-6.6651e-02,  1.5749e-02, -3.8065e-03,  ...,  2.1290e-02,\n",
      "           3.5747e-03, -1.9083e-02],\n",
      "         [-5.1126e-02,  3.7409e-01,  3.7273e-01,  ...,  4.3948e-01,\n",
      "           1.2545e-01,  1.3975e-01],\n",
      "         [-1.0663e-01,  4.8207e-01, -4.3436e-01,  ...,  4.3804e-02,\n",
      "           6.3406e-01,  4.3657e-02],\n",
      "         ...,\n",
      "         [ 2.7770e-01,  2.5998e-01,  1.6659e-01,  ...,  2.9584e-01,\n",
      "           5.9667e-01,  2.9198e-01],\n",
      "         [ 2.4562e-01,  2.1601e-01,  1.7591e-01,  ...,  3.4255e-01,\n",
      "           6.8831e-01,  2.1457e-01],\n",
      "         [ 3.0950e-01,  3.2631e-01,  8.5038e-02,  ...,  2.8425e-01,\n",
      "           5.9359e-01,  3.6428e-01]],\n",
      "\n",
      "        [[-6.9157e-02,  2.5092e-02, -6.3633e-03,  ...,  3.2070e-02,\n",
      "           9.1702e-04, -1.1907e-02],\n",
      "         [ 8.2379e-01,  8.0777e-01,  6.5286e-01,  ...,  6.4389e-01,\n",
      "           1.2057e-01,  2.8584e-01],\n",
      "         [ 5.2152e-01,  5.3068e-01,  4.6508e-03,  ...,  3.0060e-01,\n",
      "          -2.3957e-02, -1.0672e-01],\n",
      "         ...,\n",
      "         [ 1.9758e-01,  1.6988e-01,  1.3873e-01,  ...,  4.7232e-02,\n",
      "           2.8611e-01,  1.3654e-01],\n",
      "         [ 3.1073e-01,  1.3090e-01,  1.3440e-01,  ...,  4.2795e-02,\n",
      "           2.7826e-01,  1.7619e-01],\n",
      "         [ 6.9049e-01,  1.2072e-01,  3.3466e-02,  ...,  2.5996e-01,\n",
      "           4.8077e-01,  1.7402e-01]],\n",
      "\n",
      "        [[-6.6847e-02,  1.8095e-02, -9.6110e-03,  ...,  1.8222e-02,\n",
      "           4.0696e-03, -1.9103e-02],\n",
      "         [ 1.4494e-01,  6.5323e-01,  1.0518e-02,  ...,  4.6482e-03,\n",
      "           8.4173e-02,  5.5989e-01],\n",
      "         [ 1.8786e-01,  1.0503e-01, -4.0074e-02,  ...,  2.4746e-01,\n",
      "           6.6452e-01,  3.0272e-01],\n",
      "         ...,\n",
      "         [ 3.9776e-01,  1.9479e-01,  3.3944e-02,  ..., -3.0561e-02,\n",
      "           5.8761e-01,  3.1005e-01],\n",
      "         [ 2.2744e-01,  1.5487e-01, -4.3988e-02,  ..., -3.2213e-02,\n",
      "           4.1202e-01,  2.8595e-01],\n",
      "         [ 5.9352e-01, -2.0118e-01, -1.7419e-02,  ...,  3.1183e-01,\n",
      "           9.4666e-01,  1.2344e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.5971e-02,  1.7349e-02, -6.4340e-03,  ...,  2.4441e-02,\n",
      "           4.5628e-04, -1.9776e-02],\n",
      "         [ 2.0315e-01,  5.6663e-01,  6.6432e-01,  ...,  5.6831e-01,\n",
      "          -2.0078e-01, -1.0649e-01],\n",
      "         [-8.1037e-01,  1.8018e-01, -3.7440e-01,  ...,  2.8449e-01,\n",
      "           4.8644e-01, -2.1733e-01],\n",
      "         ...,\n",
      "         [ 4.6517e-01,  2.8535e-01,  2.3210e-01,  ...,  2.1522e-01,\n",
      "           1.0902e-01,  3.4032e-02],\n",
      "         [ 3.1160e-01,  4.2490e-01,  1.1849e-01,  ...,  3.0324e-01,\n",
      "           3.2703e-01,  1.6745e-01],\n",
      "         [ 4.9637e-01,  3.1393e-01,  1.6812e-01,  ...,  2.0661e-01,\n",
      "           1.3090e-01,  8.1414e-02]],\n",
      "\n",
      "        [[-6.7575e-02,  1.8305e-02, -4.5584e-03,  ...,  1.9148e-02,\n",
      "           3.7199e-03, -1.8614e-02],\n",
      "         [ 4.2615e-01,  8.0607e-02,  6.2386e-01,  ...,  1.3243e-01,\n",
      "           1.2697e-01,  4.9896e-01],\n",
      "         [ 7.5700e-02,  1.5745e-01,  2.0905e-01,  ..., -5.4214e-02,\n",
      "           8.6157e-01, -3.5593e-01],\n",
      "         ...,\n",
      "         [ 4.9023e-01, -5.2253e-02,  4.3549e-02,  ...,  1.2679e-02,\n",
      "           5.7783e-01,  2.3436e-01],\n",
      "         [ 3.4337e-01,  8.5101e-02,  7.9240e-02,  ..., -2.3439e-02,\n",
      "           3.3915e-01,  1.5551e-01],\n",
      "         [ 4.3199e-01,  3.9848e-02, -7.8078e-02,  ..., -1.0116e-01,\n",
      "           3.2986e-01,  1.3199e-01]],\n",
      "\n",
      "        [[-6.7776e-02,  1.6765e-02, -4.5118e-03,  ...,  2.5155e-02,\n",
      "          -2.0486e-04, -1.2772e-02],\n",
      "         [ 3.2318e-01,  3.5843e-01,  1.2003e+00,  ...,  3.0300e-01,\n",
      "          -3.1830e-01,  3.1374e-01],\n",
      "         [ 1.8219e-01,  4.9127e-01,  3.9012e-01,  ...,  3.5777e-01,\n",
      "          -1.6099e-01,  6.6080e-02],\n",
      "         ...,\n",
      "         [ 2.4580e-01,  4.2588e-01,  1.0841e-01,  ...,  2.1428e-01,\n",
      "           5.1898e-01,  1.6527e-01],\n",
      "         [ 2.1534e-01,  3.4473e-01,  1.0402e-01,  ...,  4.3496e-01,\n",
      "           6.9495e-01,  1.6730e-01],\n",
      "         [ 2.9772e-01,  2.5093e-01,  1.7847e-02,  ...,  3.6863e-01,\n",
      "           8.7121e-01,  2.1815e-01]]]), tensor([[[-3.6129e-02,  9.1240e-03, -1.4751e-03,  ...,  1.1482e-02,\n",
      "          -6.7449e-04, -1.4217e-02],\n",
      "         [ 6.7012e-02,  1.8187e-01,  1.9371e-01,  ...,  2.4564e-01,\n",
      "           6.2073e-03,  6.6426e-02],\n",
      "         [-1.0329e-01,  3.1610e-01, -2.1937e-01,  ..., -5.2982e-02,\n",
      "           2.6652e-01, -8.6021e-02],\n",
      "         ...,\n",
      "         [ 7.3676e-02,  1.5398e-01,  5.9229e-03,  ...,  8.2163e-02,\n",
      "           1.7777e-01,  1.7355e-03],\n",
      "         [ 5.6092e-02,  1.1218e-01,  2.5662e-02,  ...,  5.2705e-02,\n",
      "           2.3076e-01,  1.9417e-02],\n",
      "         [ 6.8653e-02,  1.8225e-01,  3.5246e-03,  ...,  5.1164e-02,\n",
      "           2.1293e-01,  6.2443e-02]],\n",
      "\n",
      "        [[-3.5228e-02,  9.2666e-03, -2.2089e-03,  ...,  1.2941e-02,\n",
      "          -1.0351e-03, -9.1841e-03],\n",
      "         [ 3.4123e-01,  2.8960e-01,  3.2430e-01,  ...,  3.0643e-01,\n",
      "          -3.8141e-02,  2.6084e-01],\n",
      "         [ 3.3619e-01,  2.0724e-01,  8.4063e-02,  ...,  1.1022e-01,\n",
      "           4.3447e-03,  4.6777e-02],\n",
      "         ...,\n",
      "         [ 2.5506e-02,  3.8516e-02,  2.0514e-03,  ...,  4.5444e-02,\n",
      "           7.6416e-02, -1.1356e-02],\n",
      "         [ 5.1186e-02,  4.5249e-02,  4.3770e-03,  ...,  3.0464e-02,\n",
      "           6.7231e-02, -9.1665e-03],\n",
      "         [ 1.9701e-01,  7.4675e-02,  3.1060e-02,  ...,  3.4965e-02,\n",
      "           1.3926e-01,  8.6132e-02]],\n",
      "\n",
      "        [[-3.6947e-02,  9.1366e-03, -1.3525e-03,  ...,  1.1634e-02,\n",
      "          -3.2088e-04, -1.4903e-02],\n",
      "         [ 6.6383e-02,  2.4398e-01,  4.0892e-02,  ..., -4.0230e-02,\n",
      "          -1.7796e-02,  3.3576e-01],\n",
      "         [-5.5470e-02,  6.1721e-03, -7.4205e-02,  ...,  3.0518e-02,\n",
      "           3.4213e-01,  2.5760e-01],\n",
      "         ...,\n",
      "         [ 1.3688e-01,  2.1415e-01,  7.7179e-03,  ..., -2.3508e-02,\n",
      "           1.5232e-01,  7.9360e-02],\n",
      "         [ 5.4047e-02,  1.1581e-01, -1.6243e-02,  ..., -8.8864e-03,\n",
      "           1.0170e-01, -5.4642e-03],\n",
      "         [ 3.1826e-01,  4.9857e-02,  4.1764e-02,  ...,  9.2379e-02,\n",
      "           3.9597e-01,  2.2416e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.6260e-02,  8.1214e-03, -1.5878e-03,  ...,  1.1164e-02,\n",
      "          -1.2986e-03, -1.2346e-02],\n",
      "         [ 2.5320e-02,  2.7399e-01,  2.9088e-01,  ...,  2.3433e-01,\n",
      "          -1.4089e-01,  9.7892e-03],\n",
      "         [-3.8576e-01,  1.2572e-01, -1.6393e-01,  ...,  1.2181e-01,\n",
      "           1.9731e-01, -1.1871e-01],\n",
      "         ...,\n",
      "         [ 9.3085e-02,  9.6632e-02,  3.9767e-02,  ...,  9.1458e-02,\n",
      "           2.7981e-02, -5.5132e-02],\n",
      "         [ 6.6780e-02,  1.4450e-01,  2.2583e-02,  ...,  9.6999e-02,\n",
      "           5.4896e-02, -2.0177e-02],\n",
      "         [ 8.9733e-02,  1.2201e-01,  3.9500e-02,  ...,  6.2466e-02,\n",
      "           2.5100e-02, -4.3362e-02]],\n",
      "\n",
      "        [[-3.7000e-02,  8.0296e-03, -1.3300e-03,  ...,  1.1774e-02,\n",
      "          -6.8020e-04, -1.3952e-02],\n",
      "         [ 1.2362e-01,  9.4678e-02,  3.9525e-01,  ...,  3.2237e-02,\n",
      "          -5.5194e-02,  2.8022e-01],\n",
      "         [-1.0121e-02,  2.4671e-01,  1.2983e-01,  ..., -1.2061e-01,\n",
      "           3.5894e-01, -2.6015e-01],\n",
      "         ...,\n",
      "         [ 1.5629e-01,  1.4300e-01,  2.1537e-02,  ...,  6.7436e-03,\n",
      "           1.4630e-01,  7.5624e-02],\n",
      "         [ 4.8153e-02,  9.4897e-02,  1.5052e-02,  ..., -2.9418e-03,\n",
      "           5.1530e-02, -3.6436e-02],\n",
      "         [ 5.9341e-02,  1.2286e-01, -1.0554e-02,  ..., -2.2111e-02,\n",
      "           6.1589e-02, -5.5112e-02]],\n",
      "\n",
      "        [[-3.6560e-02,  8.1692e-03, -1.8117e-03,  ...,  1.1835e-02,\n",
      "          -2.1563e-03, -1.1573e-02],\n",
      "         [ 1.0846e-02,  2.1092e-01,  6.9563e-01,  ...,  9.8351e-02,\n",
      "          -2.6919e-01,  2.3842e-01],\n",
      "         [-4.7626e-03,  2.2165e-01,  2.4216e-01,  ...,  3.4942e-02,\n",
      "          -1.5979e-01,  1.0929e-01],\n",
      "         ...,\n",
      "         [ 7.8274e-02,  1.6699e-01, -4.8045e-03,  ...,  7.1776e-02,\n",
      "           1.2471e-01, -6.7089e-02],\n",
      "         [ 5.7450e-02,  2.0277e-01,  4.2214e-02,  ...,  1.1132e-01,\n",
      "           2.4535e-01,  6.9357e-02],\n",
      "         [ 1.1782e-01,  1.8735e-01,  3.4115e-02,  ...,  6.2140e-02,\n",
      "           3.3094e-01,  1.3443e-01]]])), encoder_attentions=None)\n",
      "seg_num: 2\n",
      "batch_size: 32\n",
      "non_empty_mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "batch_size: 32\n",
      "decoder_input_ids: None\n",
      "prefix_tokens: torch.Size([20])\n",
      "out: Seq2SeqLMOutput(loss=tensor(19.6703), logits=tensor([[[33.5862,  6.6471, 15.4413,  ...,  6.4784,  6.6552,  1.2370],\n",
      "         [ 4.5902, -4.9075,  4.6287,  ..., -3.1258, -2.9030, -2.9051],\n",
      "         [-4.0512, -4.3522,  2.6462,  ..., -3.3446, -3.0276, -2.7244],\n",
      "         ...,\n",
      "         [-1.7733, -3.9566,  7.9215,  ..., -2.7292, -2.3879,  0.3498],\n",
      "         [-1.7747, -3.9626,  7.9369,  ..., -2.7286, -2.3822,  0.2993],\n",
      "         [-1.7644, -3.9854,  8.0693,  ..., -2.7272, -2.3824,  0.5001]],\n",
      "\n",
      "        [[33.5862,  6.6471, 15.4413,  ...,  6.4784,  6.6552,  1.2370],\n",
      "         [ 4.5902, -4.9075,  4.6287,  ..., -3.1258, -2.9030, -2.9051],\n",
      "         [-4.0512, -4.3522,  2.6462,  ..., -3.3446, -3.0276, -2.7244],\n",
      "         ...,\n",
      "         [-1.7733, -3.9566,  7.9215,  ..., -2.7292, -2.3879,  0.3498],\n",
      "         [-1.7747, -3.9626,  7.9369,  ..., -2.7286, -2.3822,  0.2993],\n",
      "         [-1.7644, -3.9854,  8.0693,  ..., -2.7272, -2.3824,  0.5001]],\n",
      "\n",
      "        [[34.1559,  6.4241, 16.1884,  ...,  6.2604,  6.2520,  1.3308],\n",
      "         [ 1.7854, -4.9016,  4.2700,  ..., -4.0438, -4.1039, -3.9733],\n",
      "         [-6.6897, -4.2120,  8.9266,  ..., -4.6460, -4.6121, -3.4573],\n",
      "         ...,\n",
      "         [-1.0317, -2.3399, 11.7088,  ..., -2.9823, -3.1076, -3.7670],\n",
      "         [-0.1300, -1.9468, 12.9197,  ..., -2.4602, -2.7198, -3.9638],\n",
      "         [-4.2172, -2.9114, 12.5790,  ..., -3.7572, -3.7091, -4.7852]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[33.5862,  6.6471, 15.4413,  ...,  6.4784,  6.6552,  1.2370],\n",
      "         [ 4.5902, -4.9075,  4.6287,  ..., -3.1258, -2.9030, -2.9051],\n",
      "         [-4.0512, -4.3522,  2.6462,  ..., -3.3446, -3.0276, -2.7244],\n",
      "         ...,\n",
      "         [-1.7733, -3.9566,  7.9215,  ..., -2.7292, -2.3879,  0.3498],\n",
      "         [-1.7747, -3.9626,  7.9369,  ..., -2.7286, -2.3822,  0.2993],\n",
      "         [-1.7644, -3.9854,  8.0693,  ..., -2.7272, -2.3824,  0.5001]],\n",
      "\n",
      "        [[33.8313,  6.5871, 16.6916,  ...,  6.6048,  6.6004,  1.6232],\n",
      "         [ 1.3059, -3.3055,  6.9021,  ..., -2.4977, -2.5811, -1.7587],\n",
      "         [-4.5516, -3.5183, 14.8754,  ..., -4.0050, -3.9259, -1.9192],\n",
      "         ...,\n",
      "         [ 1.5274, -0.1220, 23.6254,  ...,  0.5372,  0.2622, -2.0099],\n",
      "         [ 2.1009, -0.1889, 25.4912,  ...,  0.6741,  0.3686, -1.8638],\n",
      "         [ 3.2547, -0.0970, 29.2630,  ...,  1.1124,  0.9106, -1.0222]],\n",
      "\n",
      "        [[33.5862,  6.6471, 15.4413,  ...,  6.4784,  6.6552,  1.2370],\n",
      "         [ 4.5902, -4.9075,  4.6287,  ..., -3.1258, -2.9030, -2.9051],\n",
      "         [-4.0512, -4.3522,  2.6462,  ..., -3.3446, -3.0276, -2.7244],\n",
      "         ...,\n",
      "         [-1.7733, -3.9566,  7.9215,  ..., -2.7292, -2.3879,  0.3498],\n",
      "         [-1.7747, -3.9626,  7.9369,  ..., -2.7286, -2.3822,  0.2993],\n",
      "         [-1.7644, -3.9854,  8.0693,  ..., -2.7272, -2.3824,  0.5001]]]), past_key_values=None, decoder_hidden_states=(tensor([[[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [-7.2251e-02, -5.6212e-02, -4.8033e-02,  ...,  1.6368e-02,\n",
      "          -2.5698e-01, -3.0881e-02],\n",
      "         [-1.2963e-01,  5.1395e-01,  8.5932e-02,  ..., -3.2633e-01,\n",
      "           7.9166e-02,  9.8082e-02],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [-7.2251e-02, -5.6212e-02, -4.8033e-02,  ...,  1.6368e-02,\n",
      "          -2.5698e-01, -3.0881e-02],\n",
      "         [-1.2963e-01,  5.1395e-01,  8.5932e-02,  ..., -3.2633e-01,\n",
      "           7.9166e-02,  9.8082e-02],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.6400e-01,  3.1086e-02,  1.2818e-01,  ...,  1.0363e-01,\n",
      "          -6.7577e-02,  1.8733e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [-7.2251e-02, -5.6212e-02, -4.8033e-02,  ...,  1.6368e-02,\n",
      "          -2.5698e-01, -3.0881e-02],\n",
      "         [-1.2963e-01,  5.1395e-01,  8.5932e-02,  ..., -3.2633e-01,\n",
      "           7.9166e-02,  9.8082e-02],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [ 1.3897e-01, -1.5990e-01, -1.6540e-02,  ...,  1.3367e-01,\n",
      "          -2.6807e-01,  2.0773e-02],\n",
      "         [ 4.6400e-01,  3.1086e-02,  1.2818e-01,  ...,  1.0363e-01,\n",
      "          -6.7577e-02,  1.8733e-01],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]],\n",
      "\n",
      "        [[ 6.0430e-04, -8.9219e-03, -7.5089e-03,  ...,  1.6100e-03,\n",
      "          -2.1178e-02,  1.0431e-02],\n",
      "         [-7.2251e-02, -5.6212e-02, -4.8033e-02,  ...,  1.6368e-02,\n",
      "          -2.5698e-01, -3.0881e-02],\n",
      "         [-1.2963e-01,  5.1395e-01,  8.5932e-02,  ..., -3.2633e-01,\n",
      "           7.9166e-02,  9.8082e-02],\n",
      "         ...,\n",
      "         [ 1.4349e-01, -3.6913e-02,  7.6800e-02,  ...,  1.8344e-01,\n",
      "          -3.9791e-01, -2.3475e-01],\n",
      "         [ 3.3587e-01, -1.2969e-01,  3.6851e-02,  ...,  1.6006e-01,\n",
      "          -6.9880e-01, -2.8297e-02],\n",
      "         [ 5.4898e-01, -1.4833e-02,  1.1643e-01,  ...,  2.3468e-01,\n",
      "          -6.2131e-01,  1.6673e-02]]]), tensor([[[-3.7615e-03,  1.4599e-03,  6.0765e-03,  ..., -1.5947e-04,\n",
      "           2.7627e-02, -1.7028e-02],\n",
      "         [-6.8561e-02,  3.3890e-02, -1.7589e-02,  ..., -9.4119e-02,\n",
      "           3.1324e-02,  9.3372e-03],\n",
      "         [-7.6557e-02,  5.0167e-01, -1.1316e-01,  ..., -3.6202e-01,\n",
      "           1.3912e-01,  1.7625e-01],\n",
      "         ...,\n",
      "         [-3.6823e-03, -1.4306e-01,  1.4060e-01,  ...,  4.5591e-01,\n",
      "          -5.1079e-01,  1.1983e-01],\n",
      "         [ 1.7639e-01, -1.2025e-01,  1.1496e-01,  ...,  4.3321e-01,\n",
      "          -7.0596e-01,  3.0930e-01],\n",
      "         [ 4.0572e-01, -4.8029e-02,  1.4050e-01,  ...,  3.7240e-01,\n",
      "          -5.8099e-01,  3.3344e-01]],\n",
      "\n",
      "        [[-3.7615e-03,  1.4599e-03,  6.0765e-03,  ..., -1.5947e-04,\n",
      "           2.7627e-02, -1.7028e-02],\n",
      "         [-6.8561e-02,  3.3890e-02, -1.7589e-02,  ..., -9.4119e-02,\n",
      "           3.1324e-02,  9.3372e-03],\n",
      "         [-7.6557e-02,  5.0167e-01, -1.1316e-01,  ..., -3.6202e-01,\n",
      "           1.3912e-01,  1.7625e-01],\n",
      "         ...,\n",
      "         [-3.6823e-03, -1.4306e-01,  1.4060e-01,  ...,  4.5591e-01,\n",
      "          -5.1079e-01,  1.1983e-01],\n",
      "         [ 1.7639e-01, -1.2025e-01,  1.1496e-01,  ...,  4.3321e-01,\n",
      "          -7.0596e-01,  3.0930e-01],\n",
      "         [ 4.0572e-01, -4.8029e-02,  1.4050e-01,  ...,  3.7240e-01,\n",
      "          -5.8099e-01,  3.3344e-01]],\n",
      "\n",
      "        [[-2.3629e-03, -4.9511e-03,  1.3141e-02,  ...,  6.3858e-03,\n",
      "           1.8559e-02, -1.0930e-02],\n",
      "         [ 9.2565e-02, -1.5585e-01,  1.1538e-01,  ..., -3.4866e-02,\n",
      "          -1.3704e-01,  6.7449e-03],\n",
      "         [ 3.1982e-01, -2.5661e-01,  4.2074e-02,  ..., -3.7143e-01,\n",
      "          -4.1774e-01,  2.3851e-01],\n",
      "         ...,\n",
      "         [ 1.8437e-01, -4.4359e-01,  4.2439e-01,  ...,  5.3453e-01,\n",
      "          -6.0020e-01, -4.2392e-02],\n",
      "         [ 2.7142e-01, -4.1972e-01,  3.5624e-01,  ...,  4.7137e-01,\n",
      "          -6.8720e-01,  4.0083e-02],\n",
      "         [ 5.7267e-01, -3.6946e-01,  3.8087e-01,  ...,  4.5208e-01,\n",
      "          -6.7498e-01,  1.0676e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.7615e-03,  1.4599e-03,  6.0765e-03,  ..., -1.5947e-04,\n",
      "           2.7627e-02, -1.7028e-02],\n",
      "         [-6.8561e-02,  3.3890e-02, -1.7589e-02,  ..., -9.4119e-02,\n",
      "           3.1324e-02,  9.3372e-03],\n",
      "         [-7.6557e-02,  5.0167e-01, -1.1316e-01,  ..., -3.6202e-01,\n",
      "           1.3912e-01,  1.7625e-01],\n",
      "         ...,\n",
      "         [-3.6823e-03, -1.4306e-01,  1.4060e-01,  ...,  4.5591e-01,\n",
      "          -5.1079e-01,  1.1983e-01],\n",
      "         [ 1.7639e-01, -1.2025e-01,  1.1496e-01,  ...,  4.3321e-01,\n",
      "          -7.0596e-01,  3.0930e-01],\n",
      "         [ 4.0572e-01, -4.8029e-02,  1.4050e-01,  ...,  3.7240e-01,\n",
      "          -5.8099e-01,  3.3344e-01]],\n",
      "\n",
      "        [[-2.2101e-03, -5.1527e-03,  1.2115e-02,  ...,  6.1928e-03,\n",
      "           1.5943e-02, -1.1396e-02],\n",
      "         [ 1.1751e-01, -1.5773e-01,  1.0661e-01,  ..., -4.0474e-02,\n",
      "          -1.2760e-01, -2.0861e-02],\n",
      "         [ 5.1610e-01, -2.3743e-01,  8.4137e-02,  ..., -3.9488e-01,\n",
      "          -2.5004e-01,  8.3809e-02],\n",
      "         ...,\n",
      "         [ 2.3071e-01, -5.0427e-01,  4.0976e-01,  ...,  4.3894e-01,\n",
      "          -5.9725e-01, -9.1046e-02],\n",
      "         [ 3.5014e-01, -5.0882e-01,  3.7405e-01,  ...,  4.4846e-01,\n",
      "          -7.6441e-01,  1.2813e-02],\n",
      "         [ 6.3288e-01, -4.1711e-01,  3.7338e-01,  ...,  3.8113e-01,\n",
      "          -6.6416e-01,  7.9495e-02]],\n",
      "\n",
      "        [[-3.7615e-03,  1.4599e-03,  6.0765e-03,  ..., -1.5947e-04,\n",
      "           2.7627e-02, -1.7028e-02],\n",
      "         [-6.8561e-02,  3.3890e-02, -1.7589e-02,  ..., -9.4119e-02,\n",
      "           3.1324e-02,  9.3372e-03],\n",
      "         [-7.6557e-02,  5.0167e-01, -1.1316e-01,  ..., -3.6202e-01,\n",
      "           1.3912e-01,  1.7625e-01],\n",
      "         ...,\n",
      "         [-3.6823e-03, -1.4306e-01,  1.4060e-01,  ...,  4.5591e-01,\n",
      "          -5.1079e-01,  1.1983e-01],\n",
      "         [ 1.7639e-01, -1.2025e-01,  1.1496e-01,  ...,  4.3321e-01,\n",
      "          -7.0596e-01,  3.0930e-01],\n",
      "         [ 4.0572e-01, -4.8029e-02,  1.4050e-01,  ...,  3.7240e-01,\n",
      "          -5.8099e-01,  3.3344e-01]]]), tensor([[[ 1.3293e-02, -9.2552e-04, -8.4646e-03,  ...,  2.0379e-02,\n",
      "           8.7264e-03, -3.8537e-02],\n",
      "         [ 6.6050e-03,  1.8102e-02, -1.3166e-02,  ...,  1.4899e-02,\n",
      "           1.2719e-02, -2.0215e-02],\n",
      "         [-2.3745e-01,  4.8128e-01, -1.1780e-01,  ..., -5.6934e-01,\n",
      "           1.8675e-01,  4.4015e-01],\n",
      "         ...,\n",
      "         [ 1.1202e-02, -2.7293e-02, -6.6852e-02,  ..., -6.1636e-02,\n",
      "          -3.8200e-01,  3.8265e-01],\n",
      "         [ 5.3324e-02, -5.4188e-02, -4.8659e-02,  ..., -1.0910e-01,\n",
      "          -4.3269e-01,  4.0922e-01],\n",
      "         [ 1.4283e-01, -6.8570e-02, -4.7251e-02,  ..., -1.9838e-01,\n",
      "          -3.6855e-01,  3.8030e-01]],\n",
      "\n",
      "        [[ 1.3293e-02, -9.2552e-04, -8.4646e-03,  ...,  2.0379e-02,\n",
      "           8.7264e-03, -3.8537e-02],\n",
      "         [ 6.6050e-03,  1.8102e-02, -1.3166e-02,  ...,  1.4899e-02,\n",
      "           1.2719e-02, -2.0215e-02],\n",
      "         [-2.3745e-01,  4.8128e-01, -1.1780e-01,  ..., -5.6934e-01,\n",
      "           1.8675e-01,  4.4015e-01],\n",
      "         ...,\n",
      "         [ 1.1202e-02, -2.7293e-02, -6.6852e-02,  ..., -6.1636e-02,\n",
      "          -3.8200e-01,  3.8265e-01],\n",
      "         [ 5.3324e-02, -5.4188e-02, -4.8659e-02,  ..., -1.0910e-01,\n",
      "          -4.3269e-01,  4.0922e-01],\n",
      "         [ 1.4283e-01, -6.8570e-02, -4.7251e-02,  ..., -1.9838e-01,\n",
      "          -3.6855e-01,  3.8030e-01]],\n",
      "\n",
      "        [[ 1.2983e-02, -4.4354e-03, -9.0893e-03,  ...,  2.2704e-02,\n",
      "           7.6843e-03, -4.0507e-02],\n",
      "         [ 1.6768e-02, -8.8612e-03, -2.0433e-03,  ...,  2.4984e-02,\n",
      "           3.7507e-03, -3.9599e-02],\n",
      "         [ 5.0409e-01, -3.0108e-02, -6.3514e-02,  ..., -2.1734e-01,\n",
      "          -5.2560e-01,  3.7645e-01],\n",
      "         ...,\n",
      "         [-3.5145e-01, -2.9520e-01, -1.2126e-01,  ...,  9.3057e-02,\n",
      "          -1.8166e-01,  2.8610e-01],\n",
      "         [-2.4143e-01, -3.5742e-01, -1.4004e-01,  ..., -9.2219e-02,\n",
      "          -1.6576e-01,  4.6183e-01],\n",
      "         [-4.8958e-02, -3.6751e-01, -1.7403e-01,  ...,  1.7350e-01,\n",
      "          -4.2374e-01,  3.9611e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3293e-02, -9.2552e-04, -8.4646e-03,  ...,  2.0379e-02,\n",
      "           8.7264e-03, -3.8537e-02],\n",
      "         [ 6.6050e-03,  1.8102e-02, -1.3166e-02,  ...,  1.4899e-02,\n",
      "           1.2719e-02, -2.0215e-02],\n",
      "         [-2.3745e-01,  4.8128e-01, -1.1780e-01,  ..., -5.6934e-01,\n",
      "           1.8675e-01,  4.4015e-01],\n",
      "         ...,\n",
      "         [ 1.1202e-02, -2.7293e-02, -6.6852e-02,  ..., -6.1636e-02,\n",
      "          -3.8200e-01,  3.8265e-01],\n",
      "         [ 5.3324e-02, -5.4188e-02, -4.8659e-02,  ..., -1.0910e-01,\n",
      "          -4.3269e-01,  4.0922e-01],\n",
      "         [ 1.4283e-01, -6.8570e-02, -4.7251e-02,  ..., -1.9838e-01,\n",
      "          -3.6855e-01,  3.8030e-01]],\n",
      "\n",
      "        [[ 1.3313e-02, -4.7138e-03, -9.0050e-03,  ...,  2.2751e-02,\n",
      "           7.6170e-03, -4.0372e-02],\n",
      "         [ 2.2312e-02, -1.0607e-02,  5.6135e-04,  ...,  2.4832e-02,\n",
      "           3.6961e-03, -3.7375e-02],\n",
      "         [ 4.4704e-01, -8.2180e-02, -1.0374e-01,  ..., -4.1729e-01,\n",
      "          -1.9813e-01,  5.3291e-01],\n",
      "         ...,\n",
      "         [-2.9056e-01, -4.6502e-01, -1.3281e-01,  ...,  2.9277e-01,\n",
      "          -4.0475e-01,  1.1967e-01],\n",
      "         [-2.3984e-01, -4.2625e-01, -1.2303e-01,  ...,  2.5460e-01,\n",
      "          -4.1355e-01,  1.8835e-01],\n",
      "         [-8.2159e-02, -4.1218e-01, -1.7869e-01,  ...,  2.0133e-01,\n",
      "          -3.6919e-01,  5.8928e-02]],\n",
      "\n",
      "        [[ 1.3293e-02, -9.2552e-04, -8.4646e-03,  ...,  2.0379e-02,\n",
      "           8.7264e-03, -3.8537e-02],\n",
      "         [ 6.6050e-03,  1.8102e-02, -1.3166e-02,  ...,  1.4899e-02,\n",
      "           1.2719e-02, -2.0215e-02],\n",
      "         [-2.3745e-01,  4.8128e-01, -1.1780e-01,  ..., -5.6934e-01,\n",
      "           1.8675e-01,  4.4015e-01],\n",
      "         ...,\n",
      "         [ 1.1202e-02, -2.7293e-02, -6.6852e-02,  ..., -6.1636e-02,\n",
      "          -3.8200e-01,  3.8265e-01],\n",
      "         [ 5.3324e-02, -5.4188e-02, -4.8659e-02,  ..., -1.0910e-01,\n",
      "          -4.3269e-01,  4.0922e-01],\n",
      "         [ 1.4283e-01, -6.8570e-02, -4.7251e-02,  ..., -1.9838e-01,\n",
      "          -3.6855e-01,  3.8030e-01]]]), tensor([[[ 1.4605e-02, -3.7089e-03,  7.3343e-04,  ...,  1.6103e-02,\n",
      "          -2.5636e-02, -1.1605e-02],\n",
      "         [ 4.6764e-03,  9.5583e-02,  1.1853e-01,  ...,  1.3217e-01,\n",
      "           1.8383e-01, -1.5613e-02],\n",
      "         [ 1.7618e-01,  4.4866e-01,  3.0223e-01,  ..., -2.3242e-01,\n",
      "           6.1662e-01, -7.3218e-02],\n",
      "         ...,\n",
      "         [ 4.2438e-02,  3.9304e-02,  2.6606e-01,  ...,  1.7567e-01,\n",
      "          -2.5405e-01, -1.8233e-01],\n",
      "         [ 5.6320e-02,  2.5569e-02,  2.8161e-01,  ...,  1.5522e-01,\n",
      "          -2.4899e-01, -1.5835e-01],\n",
      "         [ 4.0613e-02,  1.4543e-02,  2.7892e-01,  ...,  1.2033e-01,\n",
      "          -2.7046e-01, -1.6260e-01]],\n",
      "\n",
      "        [[ 1.4605e-02, -3.7089e-03,  7.3343e-04,  ...,  1.6103e-02,\n",
      "          -2.5636e-02, -1.1605e-02],\n",
      "         [ 4.6764e-03,  9.5583e-02,  1.1853e-01,  ...,  1.3217e-01,\n",
      "           1.8383e-01, -1.5613e-02],\n",
      "         [ 1.7618e-01,  4.4866e-01,  3.0223e-01,  ..., -2.3242e-01,\n",
      "           6.1662e-01, -7.3218e-02],\n",
      "         ...,\n",
      "         [ 4.2438e-02,  3.9304e-02,  2.6606e-01,  ...,  1.7567e-01,\n",
      "          -2.5405e-01, -1.8233e-01],\n",
      "         [ 5.6320e-02,  2.5569e-02,  2.8161e-01,  ...,  1.5522e-01,\n",
      "          -2.4899e-01, -1.5835e-01],\n",
      "         [ 4.0613e-02,  1.4543e-02,  2.7892e-01,  ...,  1.2033e-01,\n",
      "          -2.7046e-01, -1.6260e-01]],\n",
      "\n",
      "        [[ 5.0649e-03, -1.1853e-02, -1.6967e-02,  ...,  8.3065e-03,\n",
      "          -3.5972e-02, -9.7215e-03],\n",
      "         [-1.1679e-01, -4.9706e-04, -8.7571e-02,  ...,  6.4463e-02,\n",
      "           1.2428e-01, -1.1058e-01],\n",
      "         [ 4.4775e-01, -4.0967e-02, -1.1275e-01,  ..., -4.9848e-01,\n",
      "           1.8013e-02,  2.5737e-01],\n",
      "         ...,\n",
      "         [-9.4744e-01, -1.6606e-01, -5.5360e-01,  ..., -2.5244e-01,\n",
      "          -3.8247e-01,  1.1720e-01],\n",
      "         [-8.6661e-01, -1.7198e-01, -5.4150e-01,  ..., -3.4342e-01,\n",
      "          -3.8691e-01,  2.9269e-01],\n",
      "         [-7.5363e-01, -1.7779e-01, -7.1015e-01,  ..., -1.8310e-01,\n",
      "          -6.8027e-01,  1.9346e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.4605e-02, -3.7089e-03,  7.3343e-04,  ...,  1.6103e-02,\n",
      "          -2.5636e-02, -1.1605e-02],\n",
      "         [ 4.6764e-03,  9.5583e-02,  1.1853e-01,  ...,  1.3217e-01,\n",
      "           1.8383e-01, -1.5613e-02],\n",
      "         [ 1.7618e-01,  4.4866e-01,  3.0223e-01,  ..., -2.3242e-01,\n",
      "           6.1662e-01, -7.3218e-02],\n",
      "         ...,\n",
      "         [ 4.2438e-02,  3.9304e-02,  2.6606e-01,  ...,  1.7567e-01,\n",
      "          -2.5405e-01, -1.8233e-01],\n",
      "         [ 5.6320e-02,  2.5569e-02,  2.8161e-01,  ...,  1.5522e-01,\n",
      "          -2.4899e-01, -1.5835e-01],\n",
      "         [ 4.0613e-02,  1.4543e-02,  2.7892e-01,  ...,  1.2033e-01,\n",
      "          -2.7046e-01, -1.6260e-01]],\n",
      "\n",
      "        [[ 5.0395e-03, -1.1856e-02, -1.6897e-02,  ...,  8.2598e-03,\n",
      "          -3.5949e-02, -9.7744e-03],\n",
      "         [-8.9479e-02,  8.0336e-04,  2.2295e-02,  ...,  6.6820e-02,\n",
      "           1.2065e-01,  3.3669e-02],\n",
      "         [ 3.1664e-01,  5.4371e-02, -1.2953e-01,  ..., -8.5057e-01,\n",
      "           1.5594e-01,  3.0255e-01],\n",
      "         ...,\n",
      "         [-8.3960e-01, -3.4664e-01, -6.2518e-01,  ..., -3.4418e-02,\n",
      "          -4.6880e-01,  7.6367e-02],\n",
      "         [-8.5088e-01, -2.5633e-01, -6.4792e-01,  ..., -1.0778e-01,\n",
      "          -5.1638e-01,  1.5347e-01],\n",
      "         [-7.7511e-01, -2.6891e-01, -6.8382e-01,  ..., -1.5754e-01,\n",
      "          -5.9916e-01,  1.8446e-01]],\n",
      "\n",
      "        [[ 1.4605e-02, -3.7089e-03,  7.3343e-04,  ...,  1.6103e-02,\n",
      "          -2.5636e-02, -1.1605e-02],\n",
      "         [ 4.6764e-03,  9.5583e-02,  1.1853e-01,  ...,  1.3217e-01,\n",
      "           1.8383e-01, -1.5613e-02],\n",
      "         [ 1.7618e-01,  4.4866e-01,  3.0223e-01,  ..., -2.3242e-01,\n",
      "           6.1662e-01, -7.3218e-02],\n",
      "         ...,\n",
      "         [ 4.2438e-02,  3.9304e-02,  2.6606e-01,  ...,  1.7567e-01,\n",
      "          -2.5405e-01, -1.8233e-01],\n",
      "         [ 5.6320e-02,  2.5569e-02,  2.8161e-01,  ...,  1.5522e-01,\n",
      "          -2.4899e-01, -1.5835e-01],\n",
      "         [ 4.0613e-02,  1.4543e-02,  2.7892e-01,  ...,  1.2033e-01,\n",
      "          -2.7046e-01, -1.6260e-01]]]), tensor([[[ 1.4606e-03,  6.8439e-03, -2.3660e-03,  ...,  5.7688e-04,\n",
      "          -4.1612e-01, -1.7834e-02],\n",
      "         [ 1.4642e-01,  4.9988e-01,  1.6046e-01,  ..., -5.9150e-02,\n",
      "          -4.6517e-01, -3.9264e-01],\n",
      "         [ 1.9347e-01,  8.2394e-01,  2.8647e-01,  ..., -4.8421e-01,\n",
      "          -1.7563e-01, -4.8420e-01],\n",
      "         ...,\n",
      "         [ 5.9656e-02,  4.4320e-01,  2.0134e-01,  ..., -1.9264e-01,\n",
      "          -2.8873e-01, -6.4657e-01],\n",
      "         [ 6.6754e-02,  4.3339e-01,  2.1940e-01,  ..., -2.0981e-01,\n",
      "          -2.9157e-01, -6.3022e-01],\n",
      "         [ 7.0857e-02,  4.0462e-01,  2.1777e-01,  ..., -2.4008e-01,\n",
      "          -3.0098e-01, -6.3659e-01]],\n",
      "\n",
      "        [[ 1.4606e-03,  6.8439e-03, -2.3660e-03,  ...,  5.7688e-04,\n",
      "          -4.1612e-01, -1.7834e-02],\n",
      "         [ 1.4642e-01,  4.9988e-01,  1.6046e-01,  ..., -5.9150e-02,\n",
      "          -4.6517e-01, -3.9264e-01],\n",
      "         [ 1.9347e-01,  8.2394e-01,  2.8647e-01,  ..., -4.8421e-01,\n",
      "          -1.7563e-01, -4.8420e-01],\n",
      "         ...,\n",
      "         [ 5.9656e-02,  4.4320e-01,  2.0134e-01,  ..., -1.9264e-01,\n",
      "          -2.8873e-01, -6.4657e-01],\n",
      "         [ 6.6754e-02,  4.3339e-01,  2.1940e-01,  ..., -2.0981e-01,\n",
      "          -2.9157e-01, -6.3022e-01],\n",
      "         [ 7.0857e-02,  4.0462e-01,  2.1777e-01,  ..., -2.4008e-01,\n",
      "          -3.0098e-01, -6.3659e-01]],\n",
      "\n",
      "        [[ 1.1076e-02, -1.0744e-03, -4.1693e-03,  ...,  9.0709e-03,\n",
      "          -4.1563e-01, -5.6747e-03],\n",
      "         [-5.5338e-02, -1.8870e-01, -4.0093e-01,  ..., -1.2423e-01,\n",
      "          -6.3175e-01, -9.5956e-02],\n",
      "         [ 1.6403e-01, -9.9519e-02, -1.9249e-01,  ..., -5.4679e-01,\n",
      "          -4.2615e-01,  2.3945e-02],\n",
      "         ...,\n",
      "         [-9.2852e-01, -1.4366e-01, -5.0473e-01,  ..., -4.2309e-01,\n",
      "          -3.9561e-01,  4.6811e-01],\n",
      "         [-9.3319e-01, -1.3659e-01, -5.3880e-01,  ..., -6.1411e-01,\n",
      "          -3.6176e-01,  5.8823e-01],\n",
      "         [-8.8800e-01, -1.8189e-01, -5.4031e-01,  ..., -3.0049e-01,\n",
      "          -4.4964e-01,  6.2452e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.4606e-03,  6.8439e-03, -2.3660e-03,  ...,  5.7688e-04,\n",
      "          -4.1612e-01, -1.7834e-02],\n",
      "         [ 1.4642e-01,  4.9988e-01,  1.6046e-01,  ..., -5.9150e-02,\n",
      "          -4.6517e-01, -3.9264e-01],\n",
      "         [ 1.9347e-01,  8.2394e-01,  2.8647e-01,  ..., -4.8421e-01,\n",
      "          -1.7563e-01, -4.8420e-01],\n",
      "         ...,\n",
      "         [ 5.9656e-02,  4.4320e-01,  2.0134e-01,  ..., -1.9264e-01,\n",
      "          -2.8873e-01, -6.4657e-01],\n",
      "         [ 6.6754e-02,  4.3339e-01,  2.1940e-01,  ..., -2.0981e-01,\n",
      "          -2.9157e-01, -6.3022e-01],\n",
      "         [ 7.0857e-02,  4.0462e-01,  2.1777e-01,  ..., -2.4008e-01,\n",
      "          -3.0098e-01, -6.3659e-01]],\n",
      "\n",
      "        [[ 1.1065e-02, -1.0877e-03, -4.1842e-03,  ...,  9.0338e-03,\n",
      "          -4.1562e-01, -5.7335e-03],\n",
      "         [ 4.9176e-02, -1.9512e-01, -7.1137e-02,  ...,  8.6839e-02,\n",
      "          -6.3684e-01,  1.9508e-01],\n",
      "         [ 2.3179e-02, -4.9379e-02, -1.7772e-01,  ..., -5.4645e-01,\n",
      "          -4.5892e-01,  2.1399e-01],\n",
      "         ...,\n",
      "         [-7.9420e-01, -3.1401e-01, -4.4940e-01,  ..., -1.6643e-01,\n",
      "          -4.3772e-01,  6.8680e-01],\n",
      "         [-8.4738e-01, -2.5416e-01, -4.8902e-01,  ..., -2.3285e-01,\n",
      "          -4.2405e-01,  7.4705e-01],\n",
      "         [-8.7702e-01, -2.3122e-01, -5.9145e-01,  ..., -3.0014e-01,\n",
      "          -4.4195e-01,  8.3408e-01]],\n",
      "\n",
      "        [[ 1.4606e-03,  6.8439e-03, -2.3660e-03,  ...,  5.7688e-04,\n",
      "          -4.1612e-01, -1.7834e-02],\n",
      "         [ 1.4642e-01,  4.9988e-01,  1.6046e-01,  ..., -5.9150e-02,\n",
      "          -4.6517e-01, -3.9264e-01],\n",
      "         [ 1.9347e-01,  8.2394e-01,  2.8647e-01,  ..., -4.8421e-01,\n",
      "          -1.7563e-01, -4.8420e-01],\n",
      "         ...,\n",
      "         [ 5.9656e-02,  4.4320e-01,  2.0134e-01,  ..., -1.9264e-01,\n",
      "          -2.8873e-01, -6.4657e-01],\n",
      "         [ 6.6754e-02,  4.3339e-01,  2.1940e-01,  ..., -2.0981e-01,\n",
      "          -2.9157e-01, -6.3022e-01],\n",
      "         [ 7.0857e-02,  4.0462e-01,  2.1777e-01,  ..., -2.4008e-01,\n",
      "          -3.0098e-01, -6.3659e-01]]]), tensor([[[ 7.5275e-04, -1.0821e-03, -1.0715e-02,  ..., -1.4857e-02,\n",
      "          -6.3957e-02, -4.1406e-02],\n",
      "         [ 3.6448e-01,  6.8850e-01,  1.6299e-01,  ...,  2.5668e-01,\n",
      "          -6.8223e-02, -6.3472e-01],\n",
      "         [ 3.5481e-01,  1.0168e+00,  3.0775e-01,  ..., -1.3573e-01,\n",
      "           2.5065e-01, -6.9467e-01],\n",
      "         ...,\n",
      "         [ 1.5086e-01,  7.3509e-01,  2.7764e-01,  ...,  9.1282e-02,\n",
      "           1.7666e-01, -5.9322e-01],\n",
      "         [ 1.4872e-01,  7.3142e-01,  2.8463e-01,  ...,  7.5415e-02,\n",
      "           1.7496e-01, -5.9272e-01],\n",
      "         [ 1.5291e-01,  6.9459e-01,  2.7399e-01,  ...,  6.6386e-02,\n",
      "           1.6635e-01, -5.9108e-01]],\n",
      "\n",
      "        [[ 7.5275e-04, -1.0821e-03, -1.0715e-02,  ..., -1.4857e-02,\n",
      "          -6.3957e-02, -4.1406e-02],\n",
      "         [ 3.6448e-01,  6.8850e-01,  1.6299e-01,  ...,  2.5668e-01,\n",
      "          -6.8223e-02, -6.3472e-01],\n",
      "         [ 3.5481e-01,  1.0168e+00,  3.0775e-01,  ..., -1.3573e-01,\n",
      "           2.5065e-01, -6.9467e-01],\n",
      "         ...,\n",
      "         [ 1.5086e-01,  7.3509e-01,  2.7764e-01,  ...,  9.1282e-02,\n",
      "           1.7666e-01, -5.9322e-01],\n",
      "         [ 1.4872e-01,  7.3142e-01,  2.8463e-01,  ...,  7.5415e-02,\n",
      "           1.7496e-01, -5.9272e-01],\n",
      "         [ 1.5291e-01,  6.9459e-01,  2.7399e-01,  ...,  6.6386e-02,\n",
      "           1.6635e-01, -5.9108e-01]],\n",
      "\n",
      "        [[ 2.5425e-03, -1.3612e-02, -8.5760e-03,  ..., -1.4470e-02,\n",
      "          -6.9125e-02, -2.4409e-02],\n",
      "         [ 7.6806e-02,  1.6090e-01, -1.7680e-01,  ..., -7.5638e-03,\n",
      "          -3.9395e-01,  4.6034e-02],\n",
      "         [ 2.8997e-01, -6.9694e-02, -1.1531e-01,  ..., -1.6127e-01,\n",
      "          -2.2244e-01,  2.8323e-01],\n",
      "         ...,\n",
      "         [-7.4878e-01,  1.1625e-01, -3.3286e-01,  ..., -2.8135e-01,\n",
      "          -2.9788e-02,  6.3972e-01],\n",
      "         [-6.8631e-01,  1.4270e-01, -3.2614e-01,  ..., -5.5568e-01,\n",
      "          -7.0802e-03,  7.5061e-01],\n",
      "         [-7.5611e-01,  4.6185e-02, -3.6996e-01,  ..., -2.0291e-01,\n",
      "          -5.8324e-02,  9.3078e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.5275e-04, -1.0821e-03, -1.0715e-02,  ..., -1.4857e-02,\n",
      "          -6.3957e-02, -4.1406e-02],\n",
      "         [ 3.6448e-01,  6.8850e-01,  1.6299e-01,  ...,  2.5668e-01,\n",
      "          -6.8223e-02, -6.3472e-01],\n",
      "         [ 3.5481e-01,  1.0168e+00,  3.0775e-01,  ..., -1.3573e-01,\n",
      "           2.5065e-01, -6.9467e-01],\n",
      "         ...,\n",
      "         [ 1.5086e-01,  7.3509e-01,  2.7764e-01,  ...,  9.1282e-02,\n",
      "           1.7666e-01, -5.9322e-01],\n",
      "         [ 1.4872e-01,  7.3142e-01,  2.8463e-01,  ...,  7.5415e-02,\n",
      "           1.7496e-01, -5.9272e-01],\n",
      "         [ 1.5291e-01,  6.9459e-01,  2.7399e-01,  ...,  6.6386e-02,\n",
      "           1.6635e-01, -5.9108e-01]],\n",
      "\n",
      "        [[ 2.7152e-03, -1.3944e-02, -8.4326e-03,  ..., -1.4578e-02,\n",
      "          -6.9280e-02, -2.4177e-02],\n",
      "         [ 2.7643e-02, -2.0770e-01,  6.0621e-02,  ..., -8.2396e-03,\n",
      "          -3.9219e-01,  1.5585e-01],\n",
      "         [-7.7498e-02, -1.8502e-03, -3.6665e-01,  ..., -4.1293e-01,\n",
      "          -2.7724e-01,  4.0727e-01],\n",
      "         ...,\n",
      "         [-6.2499e-01, -1.7951e-01, -2.6241e-01,  ..., -1.6404e-01,\n",
      "          -1.2318e-01,  1.2353e+00],\n",
      "         [-6.2479e-01, -1.0317e-01, -2.7482e-01,  ..., -2.1342e-01,\n",
      "          -1.3581e-01,  1.3097e+00],\n",
      "         [-6.7737e-01, -7.5217e-02, -3.9366e-01,  ..., -2.5382e-01,\n",
      "          -1.5676e-01,  1.3347e+00]],\n",
      "\n",
      "        [[ 7.5275e-04, -1.0821e-03, -1.0715e-02,  ..., -1.4857e-02,\n",
      "          -6.3957e-02, -4.1406e-02],\n",
      "         [ 3.6448e-01,  6.8850e-01,  1.6299e-01,  ...,  2.5668e-01,\n",
      "          -6.8223e-02, -6.3472e-01],\n",
      "         [ 3.5481e-01,  1.0168e+00,  3.0775e-01,  ..., -1.3573e-01,\n",
      "           2.5065e-01, -6.9467e-01],\n",
      "         ...,\n",
      "         [ 1.5086e-01,  7.3509e-01,  2.7764e-01,  ...,  9.1282e-02,\n",
      "           1.7666e-01, -5.9322e-01],\n",
      "         [ 1.4872e-01,  7.3142e-01,  2.8463e-01,  ...,  7.5415e-02,\n",
      "           1.7496e-01, -5.9272e-01],\n",
      "         [ 1.5291e-01,  6.9459e-01,  2.7399e-01,  ...,  6.6386e-02,\n",
      "           1.6635e-01, -5.9108e-01]]]), tensor([[[ 2.1374,  2.4173,  1.2108,  ...,  1.8234,  0.5280, -1.0932],\n",
      "         [-0.4225,  0.7847,  1.7089,  ...,  1.5256,  1.7501, -1.8947],\n",
      "         [-0.0721,  2.7445,  2.8553,  ...,  0.4311,  4.2966, -1.9362],\n",
      "         ...,\n",
      "         [-0.8817,  1.4684,  2.5217,  ...,  0.6373,  4.9406, -2.4920],\n",
      "         [-0.8737,  1.4605,  2.5447,  ...,  0.6073,  4.9316, -2.5010],\n",
      "         [-0.8982,  1.3546,  2.4702,  ...,  0.5356,  4.8857, -2.4614]],\n",
      "\n",
      "        [[ 2.1374,  2.4173,  1.2108,  ...,  1.8234,  0.5280, -1.0932],\n",
      "         [-0.4225,  0.7847,  1.7089,  ...,  1.5256,  1.7501, -1.8947],\n",
      "         [-0.0721,  2.7445,  2.8553,  ...,  0.4311,  4.2966, -1.9362],\n",
      "         ...,\n",
      "         [-0.8817,  1.4684,  2.5217,  ...,  0.6373,  4.9406, -2.4920],\n",
      "         [-0.8737,  1.4605,  2.5447,  ...,  0.6073,  4.9316, -2.5010],\n",
      "         [-0.8982,  1.3546,  2.4702,  ...,  0.5356,  4.8857, -2.4614]],\n",
      "\n",
      "        [[ 2.9433,  2.3861,  1.5769,  ...,  1.5068,  0.0591, -0.8428],\n",
      "         [ 0.5858,  0.4592,  0.0394,  ...,  0.5381,  0.5739, -0.2123],\n",
      "         [ 0.7913,  0.2984,  0.0901,  ...,  0.2345, -0.4932,  0.5503],\n",
      "         ...,\n",
      "         [-0.2438, -0.2380, -0.5508,  ..., -1.0173,  2.4126,  0.7344],\n",
      "         [-0.4828, -0.1842, -0.4230,  ..., -1.5417,  2.9623,  1.0404],\n",
      "         [-0.3759, -0.7564, -0.5316,  ..., -0.5724,  1.9851,  1.6977]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.1374,  2.4173,  1.2108,  ...,  1.8234,  0.5280, -1.0932],\n",
      "         [-0.4225,  0.7847,  1.7089,  ...,  1.5256,  1.7501, -1.8947],\n",
      "         [-0.0721,  2.7445,  2.8553,  ...,  0.4311,  4.2966, -1.9362],\n",
      "         ...,\n",
      "         [-0.8817,  1.4684,  2.5217,  ...,  0.6373,  4.9406, -2.4920],\n",
      "         [-0.8737,  1.4605,  2.5447,  ...,  0.6073,  4.9316, -2.5010],\n",
      "         [-0.8982,  1.3546,  2.4702,  ...,  0.5356,  4.8857, -2.4614]],\n",
      "\n",
      "        [[ 2.9607,  2.4239,  1.7111,  ...,  1.5569, -0.1149, -0.6218],\n",
      "         [ 0.2267, -1.3219,  1.1865,  ...,  0.6543, -2.0410, -0.4588],\n",
      "         [-0.6115, -0.4989, -0.5395,  ..., -0.8330, -1.4933,  1.0154],\n",
      "         ...,\n",
      "         [-0.4360, -1.8840,  0.5891,  ...,  0.0206,  1.5076,  1.9591],\n",
      "         [-0.4623, -1.8445,  0.6862,  ..., -0.0638,  1.4382,  2.3008],\n",
      "         [-0.4140, -2.0942,  0.6422,  ..., -0.1820,  1.4760,  2.6586]],\n",
      "\n",
      "        [[ 2.1374,  2.4173,  1.2108,  ...,  1.8234,  0.5280, -1.0932],\n",
      "         [-0.4225,  0.7847,  1.7089,  ...,  1.5256,  1.7501, -1.8947],\n",
      "         [-0.0721,  2.7445,  2.8553,  ...,  0.4311,  4.2966, -1.9362],\n",
      "         ...,\n",
      "         [-0.8817,  1.4684,  2.5217,  ...,  0.6373,  4.9406, -2.4920],\n",
      "         [-0.8737,  1.4605,  2.5447,  ...,  0.6073,  4.9316, -2.5010],\n",
      "         [-0.8982,  1.3546,  2.4702,  ...,  0.5356,  4.8857, -2.4614]]])), decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[-0.0336,  0.0117, -0.0035,  ...,  0.0122, -0.0020, -0.0031],\n",
      "         [ 0.2768,  0.4012,  0.1966,  ...,  0.1041, -0.1464,  0.3489],\n",
      "         [ 0.1674, -0.0675, -0.0248,  ...,  0.1758, -0.1385,  0.2728],\n",
      "         ...,\n",
      "         [ 0.0661,  0.0589,  0.0386,  ...,  0.0439, -0.0228,  0.0150],\n",
      "         [ 0.0458,  0.0894,  0.0865,  ...,  0.0121, -0.0164, -0.0098],\n",
      "         [-0.0006,  0.0685,  0.1142,  ...,  0.0345,  0.0645,  0.0569]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[-0.0338,  0.0093, -0.0031,  ...,  0.0114, -0.0023, -0.0038],\n",
      "         [-0.0833,  0.2156,  0.1540,  ...,  0.2003, -0.0836,  0.0276],\n",
      "         [ 0.1793,  0.2425,  0.1441,  ...,  0.0927, -0.2056,  0.0699],\n",
      "         ...,\n",
      "         [ 0.1145,  0.0907,  0.0724,  ...,  0.0642,  0.0113,  0.0287],\n",
      "         [ 0.0896,  0.0933,  0.0714,  ...,  0.0251, -0.0067,  0.0008],\n",
      "         [ 0.1038,  0.0903,  0.0585,  ...,  0.0445, -0.0199,  0.0296]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]]]), encoder_hidden_states=(tensor([[[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.4281, -0.1174,  0.0323,  ...,  0.6988,  0.1744,  0.5320],\n",
      "         [-0.1649,  0.3387,  0.0755,  ...,  0.1147, -0.3394, -0.1809],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.4548, -0.3528,  0.4371,  ..., -0.4600, -0.5799,  0.1508],\n",
      "         [-0.0372, -0.2468,  0.0466,  ...,  0.0590, -0.2413,  0.1013],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]]]), tensor([[[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]],\n",
      "\n",
      "        [[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]],\n",
      "\n",
      "        [[-6.1717e-02, -4.2524e-02,  7.6055e-02,  ...,  1.9359e-02,\n",
      "          -5.5939e-02,  2.8754e-02],\n",
      "         [ 2.3682e-01, -1.6177e-01,  1.7567e-01,  ...,  9.4418e-01,\n",
      "          -1.1729e-02,  5.5003e-01],\n",
      "         [-2.0299e-01,  3.5929e-01,  5.3140e-01,  ...,  2.8624e-01,\n",
      "          -8.2498e-01, -4.8208e-02],\n",
      "         ...,\n",
      "         [ 3.6461e-01,  4.8995e-01,  1.1852e-02,  ...,  3.5000e-01,\n",
      "           3.7499e-01, -2.6280e-01],\n",
      "         [ 3.5215e-01,  1.7557e-01,  1.4737e-01,  ...,  4.5129e-01,\n",
      "           3.1404e-01, -8.0274e-02],\n",
      "         [ 3.2108e-01,  8.0538e-02, -2.9880e-02,  ...,  6.3441e-01,\n",
      "           1.0800e-01, -6.0268e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]],\n",
      "\n",
      "        [[-4.3795e-02, -6.3818e-02,  1.0007e-01,  ...,  1.9040e-02,\n",
      "          -1.1842e-01,  7.0602e-02],\n",
      "         [-1.7110e-02, -1.3006e-01,  2.6985e-02,  ..., -1.1934e-01,\n",
      "          -2.6391e-01,  2.4954e-01],\n",
      "         [ 3.3353e-01, -1.7296e-01,  3.4357e-01,  ...,  1.1651e-01,\n",
      "          -5.6767e-01,  7.5876e-02],\n",
      "         ...,\n",
      "         [ 3.5886e-01,  6.2751e-01,  1.2573e-01,  ...,  3.6067e-01,\n",
      "           3.5714e-01, -4.0761e-01],\n",
      "         [ 4.3859e-01,  5.5870e-01,  7.1691e-02,  ...,  4.3952e-01,\n",
      "           3.8011e-01, -2.7304e-01],\n",
      "         [ 5.3833e-01,  4.0162e-01, -1.2835e-01,  ...,  7.6645e-01,\n",
      "           2.5464e-01, -1.7718e-01]],\n",
      "\n",
      "        [[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]]]), tensor([[[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]],\n",
      "\n",
      "        [[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]],\n",
      "\n",
      "        [[-0.0769,  0.0050,  0.0506,  ..., -0.0249, -0.0564, -0.0050],\n",
      "         [ 0.3860, -0.0809,  0.4648,  ...,  0.2956,  0.1068,  0.7542],\n",
      "         [-0.3198,  0.3157,  0.2466,  ...,  0.3532, -0.4391,  0.3950],\n",
      "         ...,\n",
      "         [ 0.3612,  0.4124,  0.2207,  ...,  0.0942,  0.5220, -0.1118],\n",
      "         [ 0.2268,  0.2617,  0.2831,  ...,  0.1073,  0.4973, -0.1063],\n",
      "         [ 0.2146,  0.3861,  0.1055,  ...,  0.3441,  0.2149, -0.2237]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]],\n",
      "\n",
      "        [[-0.0757,  0.0054,  0.0855,  ..., -0.0211, -0.0686,  0.0238],\n",
      "         [-0.3566,  0.1954,  0.2372,  ...,  0.1940, -0.0231,  0.5388],\n",
      "         [ 0.4478, -0.0520,  0.5280,  ...,  0.0774, -0.4152,  0.3092],\n",
      "         ...,\n",
      "         [ 0.4296,  0.5824,  0.3031,  ...,  0.1094,  0.5167, -0.2204],\n",
      "         [ 0.5155,  0.4919,  0.1865,  ...,  0.1437,  0.5566, -0.2015],\n",
      "         [ 0.6023,  0.4555,  0.0721,  ...,  0.3597,  0.4392, -0.1250]],\n",
      "\n",
      "        [[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]]]), tensor([[[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]],\n",
      "\n",
      "        [[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]],\n",
      "\n",
      "        [[-6.8759e-02,  2.6430e-02,  1.0901e-02,  ..., -3.5379e-03,\n",
      "          -1.2332e-03, -7.4572e-03],\n",
      "         [ 4.3310e-01,  1.9028e-01,  3.0225e-01,  ...,  5.7623e-01,\n",
      "           6.1169e-02,  7.7887e-01],\n",
      "         [ 4.5549e-02,  3.0375e-01,  3.2946e-01,  ...,  7.3628e-01,\n",
      "          -4.0321e-01,  6.3376e-01],\n",
      "         ...,\n",
      "         [ 1.9360e-01,  6.0749e-02,  3.7029e-01,  ...,  3.8067e-01,\n",
      "           3.6700e-01,  2.5802e-01],\n",
      "         [ 9.8493e-02,  1.4034e-03,  4.7523e-01,  ...,  4.9572e-01,\n",
      "           3.1781e-01,  1.0321e-01],\n",
      "         [ 1.9767e-01, -1.6218e-01,  3.4040e-01,  ...,  7.1429e-01,\n",
      "           1.2679e-01,  1.6186e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]],\n",
      "\n",
      "        [[-7.0447e-02,  3.6495e-02,  1.4445e-02,  ...,  2.2460e-02,\n",
      "          -8.4794e-03, -1.6912e-02],\n",
      "         [-4.3142e-01,  3.9871e-01,  3.6756e-01,  ...,  4.2858e-01,\n",
      "          -6.4041e-02,  5.1471e-01],\n",
      "         [ 3.9501e-01, -9.8675e-03,  5.8382e-01,  ...,  2.6260e-01,\n",
      "          -4.9510e-01,  4.8299e-01],\n",
      "         ...,\n",
      "         [ 2.5783e-01,  1.6938e-01,  4.6586e-01,  ...,  4.6780e-01,\n",
      "           3.6133e-01,  2.1204e-01],\n",
      "         [ 3.0614e-01,  1.1999e-01,  4.0946e-01,  ...,  4.9324e-01,\n",
      "           4.2999e-01,  3.0587e-01],\n",
      "         [ 3.9830e-01,  1.0866e-01,  2.9185e-01,  ...,  6.7092e-01,\n",
      "           3.4049e-01,  3.5630e-01]],\n",
      "\n",
      "        [[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]]]), tensor([[[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]],\n",
      "\n",
      "        [[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]],\n",
      "\n",
      "        [[-0.0949,  0.0276, -0.0028,  ...,  0.0417,  0.0056, -0.0050],\n",
      "         [ 0.4562,  0.3582,  0.2873,  ...,  0.3661, -0.1768,  0.5894],\n",
      "         [ 0.1313,  0.1431,  0.2115,  ...,  0.3603, -0.1456,  0.3289],\n",
      "         ...,\n",
      "         [ 0.3643,  0.2735,  0.3083,  ...,  0.2247,  0.2563,  0.2718],\n",
      "         [ 0.1815,  0.2399,  0.4444,  ...,  0.2413,  0.1842,  0.2475],\n",
      "         [ 0.3533,  0.0057,  0.3984,  ...,  0.3084,  0.1863,  0.4102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]],\n",
      "\n",
      "        [[-0.0980,  0.0298,  0.0010,  ...,  0.0472,  0.0020, -0.0054],\n",
      "         [-0.3930,  0.4051,  0.3843,  ...,  0.3565,  0.0291,  0.2107],\n",
      "         [ 0.3793,  0.1329,  0.3120,  ...,  0.1775, -0.5218,  0.2055],\n",
      "         ...,\n",
      "         [ 0.3739,  0.3796,  0.3862,  ...,  0.2219,  0.2397,  0.3630],\n",
      "         [ 0.3174,  0.3572,  0.2890,  ...,  0.2413,  0.3200,  0.3494],\n",
      "         [ 0.4471,  0.3954,  0.2137,  ...,  0.3875,  0.2554,  0.3915]],\n",
      "\n",
      "        [[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]]]), tensor([[[ 0.2250,  0.2268, -0.0974,  ...,  0.3116,  0.0548,  0.3275],\n",
      "         [ 0.3554,  0.1478,  0.4579,  ...,  0.3436,  0.0381,  0.9085],\n",
      "         [ 0.2821,  0.1734,  0.3648,  ...,  0.2544,  0.1815,  0.7424],\n",
      "         ...,\n",
      "         [ 0.4294,  0.1700,  0.4806,  ...,  0.2450,  0.5267,  0.8716],\n",
      "         [ 0.4257,  0.1805,  0.3245,  ...,  0.2773,  0.5707,  0.8922],\n",
      "         [ 0.3838,  0.1531,  0.2401,  ...,  0.3156,  0.5754,  0.9349]],\n",
      "\n",
      "        [[ 0.2250,  0.2268, -0.0974,  ...,  0.3116,  0.0548,  0.3275],\n",
      "         [ 0.3554,  0.1478,  0.4579,  ...,  0.3436,  0.0381,  0.9085],\n",
      "         [ 0.2821,  0.1734,  0.3648,  ...,  0.2544,  0.1815,  0.7424],\n",
      "         ...,\n",
      "         [ 0.4294,  0.1700,  0.4806,  ...,  0.2450,  0.5267,  0.8716],\n",
      "         [ 0.4257,  0.1805,  0.3245,  ...,  0.2773,  0.5707,  0.8922],\n",
      "         [ 0.3838,  0.1531,  0.2401,  ...,  0.3156,  0.5754,  0.9349]],\n",
      "\n",
      "        [[-0.0768,  0.0361, -0.0108,  ...,  0.0263, -0.0062, -0.0137],\n",
      "         [ 0.6555,  0.7922,  0.4208,  ...,  0.1255,  0.0385,  0.9469],\n",
      "         [ 0.2578,  0.0620,  0.0338,  ...,  0.3210, -0.1292,  0.5267],\n",
      "         ...,\n",
      "         [ 0.4072,  0.1545,  0.2641,  ...,  0.1191, -0.0401,  0.1657],\n",
      "         [ 0.2717,  0.3023,  0.3799,  ...,  0.0469, -0.0402,  0.1503],\n",
      "         [ 0.0899,  0.1895,  0.2694,  ...,  0.1513,  0.1860,  0.3022]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2250,  0.2268, -0.0974,  ...,  0.3116,  0.0548,  0.3275],\n",
      "         [ 0.3554,  0.1478,  0.4579,  ...,  0.3436,  0.0381,  0.9085],\n",
      "         [ 0.2821,  0.1734,  0.3648,  ...,  0.2544,  0.1815,  0.7424],\n",
      "         ...,\n",
      "         [ 0.4294,  0.1700,  0.4806,  ...,  0.2450,  0.5267,  0.8716],\n",
      "         [ 0.4257,  0.1805,  0.3245,  ...,  0.2773,  0.5707,  0.8922],\n",
      "         [ 0.3838,  0.1531,  0.2401,  ...,  0.3156,  0.5754,  0.9349]],\n",
      "\n",
      "        [[-0.0754,  0.0336, -0.0110,  ...,  0.0272, -0.0049, -0.0144],\n",
      "         [-0.2471,  0.4329,  0.2592,  ...,  0.3951, -0.0792,  0.1977],\n",
      "         [ 0.5177,  0.2566,  0.3078,  ...,  0.1464, -0.5230,  0.0188],\n",
      "         ...,\n",
      "         [ 0.4570,  0.2935,  0.2256,  ...,  0.1860,  0.0280,  0.2872],\n",
      "         [ 0.3515,  0.3043,  0.2142,  ...,  0.1125,  0.0097,  0.2139],\n",
      "         [ 0.4239,  0.3367,  0.1311,  ...,  0.2356, -0.0365,  0.2538]],\n",
      "\n",
      "        [[ 0.2250,  0.2268, -0.0974,  ...,  0.3116,  0.0548,  0.3275],\n",
      "         [ 0.3554,  0.1478,  0.4579,  ...,  0.3436,  0.0381,  0.9085],\n",
      "         [ 0.2821,  0.1734,  0.3648,  ...,  0.2544,  0.1815,  0.7424],\n",
      "         ...,\n",
      "         [ 0.4294,  0.1700,  0.4806,  ...,  0.2450,  0.5267,  0.8716],\n",
      "         [ 0.4257,  0.1805,  0.3245,  ...,  0.2773,  0.5707,  0.8922],\n",
      "         [ 0.3838,  0.1531,  0.2401,  ...,  0.3156,  0.5754,  0.9349]]]), tensor([[[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[-0.0336,  0.0117, -0.0035,  ...,  0.0122, -0.0020, -0.0031],\n",
      "         [ 0.2768,  0.4012,  0.1966,  ...,  0.1041, -0.1464,  0.3489],\n",
      "         [ 0.1674, -0.0675, -0.0248,  ...,  0.1758, -0.1385,  0.2728],\n",
      "         ...,\n",
      "         [ 0.0661,  0.0589,  0.0386,  ...,  0.0439, -0.0228,  0.0150],\n",
      "         [ 0.0458,  0.0894,  0.0865,  ...,  0.0121, -0.0164, -0.0098],\n",
      "         [-0.0006,  0.0685,  0.1142,  ...,  0.0345,  0.0645,  0.0569]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[-0.0338,  0.0093, -0.0031,  ...,  0.0114, -0.0023, -0.0038],\n",
      "         [-0.0833,  0.2156,  0.1540,  ...,  0.2003, -0.0836,  0.0276],\n",
      "         [ 0.1793,  0.2425,  0.1441,  ...,  0.0927, -0.2056,  0.0699],\n",
      "         ...,\n",
      "         [ 0.1145,  0.0907,  0.0724,  ...,  0.0642,  0.0113,  0.0287],\n",
      "         [ 0.0896,  0.0933,  0.0714,  ...,  0.0251, -0.0067,  0.0008],\n",
      "         [ 0.1038,  0.0903,  0.0585,  ...,  0.0445, -0.0199,  0.0296]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]]])), encoder_attentions=None)\n",
      "model is finished\n",
      "non_empty_mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "batch_size: 32\n",
      "out: tensor([[    2,     0,  2765,  ...,  9260,     5,     2],\n",
      "        [    2,     0,  2765,  ...,  3650,    19,     2],\n",
      "        [    2,     0,  1640,  ...,     4,    22,     2],\n",
      "        ...,\n",
      "        [    2,     0, 30504,  ...,    49, 19518,     2],\n",
      "        [    2,     0,  2765,  ...,    11,    10,     2],\n",
      "        [    2,     0,   133,  ...,    18,     4,     2]])\n",
      "non_empty_mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "batch_size: 32\n",
      "out: tensor([[   2,    0,  894,  ..., 1142,   81,    2],\n",
      "        [   2,    0,  133,  ...,  774, 3092,    2],\n",
      "        [   2,    0, 5110,  ...,    5, 7780,    2],\n",
      "        ...,\n",
      "        [   2,    0, 1213,  ..., 2357,    6,    2],\n",
      "        [   2,    0, 1748,  ...,  834,  854,    2],\n",
      "        [   2,    0,  157,  ..., 1178,  271,    2]])\n",
      "non_empty_mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "batch_size: 32\n",
      "out: tensor([[    2,     0,    17,  ...,    17,    36,     2],\n",
      "        [    2,     0,    17,  ...,    17,    36,     2],\n",
      "        [    2,     0,   117,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    2,     0,    17,  ...,    17,    36,     2],\n",
      "        [    2,     0, 27444,  ...,     1,     1,     1],\n",
      "        [    2,     0,    17,  ...,    17,    36,     2]])\n",
      "model_outputs:  ”�’�” —��� El�� ”’s�›�� $” $�� —” �� ��im�� 0��″�� 1��1��73�� Osama�� on” El� ’� � �’ �� � $’73� �73” 0’ —� � El’ $� $ $� �”″� � — �� — ” � � � —� $ �� $ —� — $� — —’ (�� 24�� ��� (\n"
     ]
    }
   ],
   "source": [
    "for _, batch in enumerate(train_dataloader):\n",
    "    input_ids = batch[\"input_ids\"].to(model.device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "    labels = batch[\"labels\"].to(model.device)\n",
    "    \n",
    "    print(\"input_ids.shape:\", input_ids.shape)\n",
    "    print(\"attention_mask.shape:\", attention_mask.shape)\n",
    "    print(\"labels.shape:\", labels.shape)\n",
    "\n",
    "    model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "    model.generate(\n",
    "        input_ids=input_ids,\n",
    "        # attention_mask=attention_mask,\n",
    "        min_length=0,\n",
    "        max_length=142,\n",
    "        num_beams=4\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_tokens = torch.arange(20).long()\n",
    "prefix_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_tokens = prefix_tokens.unsqueeze(0)\n",
    "prefix_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_tokens = prefix_tokens.expand(32, -1)\n",
    "prefix_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token_id: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[12312414],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)\n",
    "segment_size = 20\n",
    "def get_full_padding_segment():\n",
    "    padding_segment = [tokenizer.pad_token_id for _ in range(segment_size)]\n",
    "    return padding_segment\n",
    "\n",
    "test = get_full_padding_segment()\n",
    "test\n",
    "[test]\n",
    "[[12312414]] + [test] * 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
