{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!wandb login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:vw970or3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e259c5475ee34e1fa7a9bdecc7283256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.227164…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▄▅▁▂▅▄▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.99713</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-wind-1</strong> at: <a href='https://wandb.ai/kaifan-li/my_project/runs/vw970or3' target=\"_blank\">https://wandb.ai/kaifan-li/my_project/runs/vw970or3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230804_225122-vw970or3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:vw970or3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07bc6da2c3d4e70a35c6eab7030ed93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668189813693366, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/is/kaifan-l/private_room/proj-repos/prompt-for-long-text-summarization/wandb/run-20230804_225935-7shln82z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kaifan-li/my_project/runs/7shln82z' target=\"_blank\">swept-dawn-2</a></strong> to <a href='https://wandb.ai/kaifan-li/my_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kaifan-li/my_project' target=\"_blank\">https://wandb.ai/kaifan-li/my_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kaifan-li/my_project/runs/7shln82z' target=\"_blank\">https://wandb.ai/kaifan-li/my_project/runs/7shln82z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "os.environ['WANDB_DIR'] = os.getcwd() + '/wandb/'\n",
    "os.environ['WANDB_CACHE_DIR'] = os.getcwd() + '/wandb/.cache/'\n",
    "os.environ['WANDB_CONFIG_DIR'] = os.getcwd() + '/wandb/.config/'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 初始化wandb\n",
    "wandb.init(\n",
    "    entity='kaifan-li',\n",
    "    project=\"my_project\"\n",
    ")\n",
    "\n",
    "# 构建模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i in range(100):\n",
    "        inputs = torch.randn(32, 10)  # 随机生成输入数据\n",
    "        labels = torch.randn(32, 1)   # 随机生成标签\n",
    "        \n",
    "        # 正向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # 记录训练过程和指标\n",
    "    avg_loss = running_loss / 100\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": avg_loss})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = \"Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.Long documents, like research papers, scientific articles, or books, often contain a wealth of information and insights. These documents can cover complex topics, present detailed arguments, and provide extensive evidence to support their claims. However, handling such long texts can be challenging, especially when working with models that have input length limitations.n natural language processing tasks, like text classification or language generation, it is common to use pretrained transformer models like BERT, GPT-3, or T5. These models typically have a maximum input length of 512 tokens, which means they cannot directly handle documents that exceed this limit.To process long documents with pretrained models, a common approach is to split the text into smaller segments or chunks, process each segment independently with the model, and then combine the results. By dividing the document into smaller parts, each segment can fit within the model's input length constraints.However, this approach requires careful handling to ensure that the divisions do not disrupt the coherence and context of the document. Some strategies involve using sliding windows, adding special tokens to mark the beginning and end of segments, or using an overlap between segments to preserve context.Researchers and developers often implement custom solutions to tackle long document processing, depending on their specific use case and model requirements.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13014"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/is/kaifan-l/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import psutil\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, get_linear_schedule_with_warmup, set_seed\n",
    "\n",
    "from peft import PrefixTuningConfig, TaskType, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator() # device_placement=\"cuda:0\"\n",
    "model_name_or_path = \"facebook/bart-base\"\n",
    "dataset_name = \"cnn_dailymail\"\n",
    "peft_config = PrefixTuningConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    inference_mode=False,\n",
    "    num_virtual_tokens=20,\n",
    ")\n",
    "text_column = 'article'\n",
    "label_column = 'highlights'\n",
    "lr = 3e-3\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "do_test = True\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dataset = load_dataset(dataset_name, \"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "target_max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples[text_column]\n",
    "    targets = examples[label_column]\n",
    "    model_inputs = tokenizer(inputs, truncation=True) # 这里暂时不padding\n",
    "    targets = tokenizer(\n",
    "        targets,\n",
    "        max_length=target_max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    targets = targets['input_ids']\n",
    "    targets[targets == tokenizer.pad_token_id] = -100\n",
    "    model_inputs['labels'] = targets\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 13368/13368 [00:12<00:00, 1042.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "with accelerator.main_process_first():\n",
    "    cnn_dataset = cnn_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        num_proc=1,\n",
    "        remove_columns=cnn_dataset[\"train\"].column_names,\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(cnn_dataset[\"train\"]) * 0.1)\n",
    "eval_size = int(len(cnn_dataset[\"validation\"]) * 0.01)\n",
    "test_size = int(len(cnn_dataset[\"test\"]) * 0.01)\n",
    "\n",
    "# 从打乱后的数据集中随机抽取指定数量的数据\n",
    "train_dataset = cnn_dataset[\"train\"].shuffle(seed=42).select(range(train_size))\n",
    "eval_dataset = cnn_dataset[\"validation\"].shuffle(seed=42).select(range(eval_size))\n",
    "test_dataset = cnn_dataset[\"test\"].shuffle(seed=42).select(range(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    return tokenizer.pad(examples, padding='longest', return_tensors='pt')\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True, # 将数据加载到固定的内存中，可以加速数据加载\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024])\n"
     ]
    }
   ],
   "source": [
    "for num, batch in enumerate(train_dataloader):\n",
    "    print(batch[\"input_ids\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:549: FutureWarning: The class `PretrainedBartModel` has been depreciated, please use `BartPreTrainedModel` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import logging\n",
    "import copy\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "from transformers import (\n",
    "    BartForConditionalGeneration, \n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "from transformers import BartConfig\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "from model.prefix_encoder import PrefixEncoder\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "class CustomBartConfig(BartConfig):\n",
    "    def __init__(self,\n",
    "                 pre_seq_len=20,\n",
    "                 input_size=512,\n",
    "                 max_n_segments=3,\n",
    "                 bptt_depth=-1,\n",
    "                 prefix_projection=False, \n",
    "                 hidden_dropout_prob=0.1,\n",
    "                 segment_alignment='left',\n",
    "                 sum_token_size=0,\n",
    "                 label_max_size=142,\n",
    "                 sum_loss=True,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pre_seq_len = pre_seq_len\n",
    "        self.input_size = input_size\n",
    "        self.max_n_segments = max_n_segments\n",
    "        self.bptt_depth = bptt_depth\n",
    "        self.prefix_projection = prefix_projection # whether to use reparametrization trick\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob # dropout for prefix encoder\n",
    "        self.segment_alignment = segment_alignment\n",
    "        self.sum_token_size = sum_token_size\n",
    "        self.label_max_size = label_max_size # the max size of labels\n",
    "        self.sum_loss = sum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_config = BartConfig.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBartConfig {\n",
       "  \"_name_or_path\": \"bart-base\",\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"BartModel\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"bptt_depth\": -1,\n",
       "  \"classif_dropout\": 0.1,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_attention_heads\": 12,\n",
       "  \"decoder_ffn_dim\": 3072,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"dropout\": 0.1,\n",
       "  \"early_stopping\": true,\n",
       "  \"encoder_attention_heads\": 12,\n",
       "  \"encoder_ffn_dim\": 3072,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 6,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"forced_bos_token_id\": 0,\n",
       "  \"forced_eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"input_size\": 512,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"label_max_size\": 142,\n",
       "  \"max_n_segments\": 3,\n",
       "  \"max_position_embeddings\": 1024,\n",
       "  \"model_type\": \"bart\",\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"normalize_before\": false,\n",
       "  \"normalize_embedding\": true,\n",
       "  \"num_beams\": 4,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"pre_seq_len\": 20,\n",
       "  \"prefix_projection\": false,\n",
       "  \"scale_embedding\": false,\n",
       "  \"segment_alignment\": \"left\",\n",
       "  \"sum_loss\": true,\n",
       "  \"sum_token_size\": 0,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 128,\n",
       "      \"min_length\": 12,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_cnn\": {\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 142,\n",
       "      \"min_length\": 56,\n",
       "      \"num_beams\": 4\n",
       "    },\n",
       "    \"summarization_xsum\": {\n",
       "      \"length_penalty\": 1.0,\n",
       "      \"max_length\": 62,\n",
       "      \"min_length\": 11,\n",
       "      \"num_beams\": 6\n",
       "    }\n",
       "  },\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.32.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_config = CustomBartConfig(**bart_config.to_dict())\n",
    "custom_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import logging\n",
    "import copy\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "from transformers import (\n",
    "    BartPretrainedModel,\n",
    "    BartForConditionalGeneration, \n",
    "    T5ForConditionalGeneration,\n",
    ")\n",
    "from transformers import BartConfig, T5Config\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "\n",
    "from model.prefix_encoder import PrefixEncoder\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from transformers.modeling_bart.py\n",
    "def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
    "    \"\"\"\n",
    "    Shift input ids one token to the right.\n",
    "    \"\"\"\n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
    "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
    "\n",
    "    if pad_token_id is None:\n",
    "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
    "    # replace possible -100 values in labels by `pad_token_id`\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "\n",
    "    return shifted_input_ids\n",
    "# prefix-tuning/p-tuning v2 version\n",
    "class BartPrefixForConditionalGeneration(BartPretrainedModel):\n",
    "    def __init__(self, config, checkpoint):\n",
    "        super().__init__(config)\n",
    "        # copied from BartForConditionalGeneration.__init__()\n",
    "        # self.model = BartModel(config)\n",
    "        # self.register_buffer(\"final_logits_bias\", torch.zeros((1, self.model.shared.num_embeddings)))\n",
    "        # self.lm_head = nn.Linear(config.d_model, self.model.shared.num_embeddings, bias=False)\n",
    "        # self.post_init() will not overwrite the pretrained parameters when using from_pretrained()\n",
    "        \n",
    "        self.model = BartForConditionalGeneration.from_pretrained(checkpoint)\n",
    "        self.tokenizer = BartTokenizer.from_pretrained(checkpoint)\n",
    "        self.config = config\n",
    "\n",
    "        self.segment_alignment = config.segment_alignment\n",
    "        self.extract_special_tokens(tokenizer)\n",
    "        self.pre_seq_len = config.pre_seq_len\n",
    "        self.n_layer = config.num_hidden_layers\n",
    "        self.n_head = config.num_attention_heads\n",
    "        self.n_embd = config.hidden_size // config.num_attention_heads\n",
    "        # self.extend_word_embeddings(config.pre_seq_len, tokenizer)\n",
    "        \n",
    "        # tokenizer.num_special_tokens_to_add()cal the number of special tokens needed to add except [SEP]\n",
    "        # bart-base: 489\n",
    "        self.segment_size = config.input_size - self.pre_seq_len - tokenizer.num_special_tokens_to_add()\n",
    "        if 'sep_token' in tokenizer.special_tokens_map:\n",
    "            self.segment_size -= 1\n",
    "        \n",
    "        # TODO: forget some part of long range memory and add new memory\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.prefix_tokens = torch.arange(self.pre_seq_len).long()\n",
    "        self.prefix_encoder = PrefixEncoder(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "        bart_param = 0\n",
    "        all_param = 0\n",
    "        \n",
    "        # count the number of trainable parameters in bart\n",
    "        for name, param in self.model.named_parameters():\n",
    "            bart_param += param.numel() # numel() returns the total number of elements in the input tensor\n",
    "            \n",
    "        for name, param in self.named_parameters():\n",
    "            all_param += param.numel()\n",
    "            \n",
    "        trainable_param = all_param - bart_param\n",
    "        \n",
    "        print(\"Total parameters: {:,}\".format(all_param))\n",
    "        print(\"Trainable parameters: {:,} {:,%}\".format((trainable_param), trainable_param/all_param))\n",
    "\n",
    "    def get_prompt(self, batch_size):\n",
    "        prefix_tokens = self.prefix_tokens.unsqueeze(0).expand(batch_size, -1).to(self.model.device)\n",
    "        past_key_values = self.prefix_encoder(prefix_tokens)\n",
    "        bsz, seqlen, _ = past_key_values.shape\n",
    "        past_key_values = past_key_values.view(\n",
    "            bsz,\n",
    "            seqlen,\n",
    "            self.n_layer * 2,\n",
    "            self.n_head,\n",
    "            self.n_embd\n",
    "        )        \n",
    "        past_key_values = self.dropout(past_key_values)\n",
    "        # (2,batch_size,n_head,seq_len,head_dim)\n",
    "        past_key_values = past_key_values.permute([2, 0, 3, 1, 4]).split(2)\n",
    "        return past_key_values\n",
    "    \n",
    "    # TODO：split labels other warys\n",
    "    # TODO: 25% -> 50% -> 75% -> 100% -> 100% -> 100% -> 100% -> 100% -> 100% -> 100%\n",
    "    def pad_and_segment(self, input_ids, attention_mask=None, labels=None):\n",
    "        \"\"\"\n",
    "        segment input_ids into segments\n",
    "        \n",
    "        input sample:\n",
    "        segmented_batch = [\n",
    "            [sample1_seg1, sample1_seg2, sample1_seg3],\n",
    "            [sample2_seg1, sample2_seg2],\n",
    "            [sample3_seg1, sample3_seg2, sample3_seg3, sample3_seg4]\n",
    "        ]\n",
    "                   \n",
    "        output sample:\n",
    "        segmented_batch = [\n",
    "            [sample1_seg1, sample2_seg1, sample3_seg1],\n",
    "            [sample1_seg2, sample2_seg2, sample3_seg2],\n",
    "            [sample1_seg3, None, sample3_seg3],\n",
    "            [None, None, sample3_seg4]\n",
    "        ]\n",
    "        \"\"\"\n",
    "        segmented_batch = []\n",
    "        segmented_batch_attention_masks = []\n",
    "        segmented_batch_labels = []\n",
    "        \n",
    "        if attention_mask is None:\n",
    "            attention_mask = [None] * input_ids.shape[0]\n",
    "        batch_attention_mask = attention_mask\n",
    "            \n",
    "        # inference mode\n",
    "        if labels is None:\n",
    "            labels = [None] * input_ids.shape[0]\n",
    "        batch_labels = labels\n",
    "        \n",
    "        # input_ids: [batch_size, seq_len]\n",
    "        for seq, attn_mask, label in zip(input_ids, batch_attention_mask, batch_labels):\n",
    "\n",
    "            # pytorch syntax: element-wise operation\n",
    "            drop_mask = sum([seq == t for t in self.special_token_ids])\n",
    "            drop_mask = torch.tensor([1 if t != 0 else 0 for t in drop_mask])\n",
    "\n",
    "            # bool type slice for tensor type\n",
    "            # remove special tokens\n",
    "            seq = seq[(1 - drop_mask).bool()]\n",
    "            seq = seq[:self.segment_size * self.config.max_n_segments]\n",
    "            \n",
    "            if attn_mask is not None:\n",
    "                attn_mask_drop_mask = sum([attn_mask == self.pad_token_id])\n",
    "                attn_mask = attn_mask[attn_mask_drop_mask.bool()]\n",
    "                attn_mask = attn_mask[:self.segment_size * self.config.max_n_segments]\n",
    "            if label is not None:\n",
    "                label_drop_mask = sum([label == t for t in self.special_token_ids + [-100]])\n",
    "                label_drop_mask = torch.tensor([1 if t != 0 else 0 for t in label_drop_mask])\n",
    "                label = label[(1-label_drop_mask).bool()]\n",
    "                # TODO：label = label[:self.config.sum_max_size * self.config.max_n_segments]\n",
    "                label = label[:self.segment_size * self.config.max_n_segments]\n",
    "            \n",
    "            align = self.segment_alignment\n",
    "            if align in {'right', None}:\n",
    "                split_inds = (list(range(len(seq), 0, -self.segment_size)) + [0])[::-1]\n",
    "            elif align == 'left':\n",
    "                split_inds = list(range(0, len(seq), self.segment_size)) + [len(seq)]\n",
    "            elif align == 'center':\n",
    "                n_seg = math.ceil(len(seq) / self.segment_size)\n",
    "                split_inds = list(range(0, len(seq), math.ceil(len(seq) / n_seg))) + [len(seq)]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            input_segments = [seq[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "            input_segments = [self.pad_add_special_tokens(t, self.config.input_size) for t in input_segments]\n",
    "            \n",
    "            # add empty segment markers if needed\n",
    "            n_empty_segments = self.config.max_n_segments - len(input_segments)\n",
    "            # input_segments:\n",
    "            # print(\"input_segments:\", input_segments)\n",
    "            input_segments = input_segments + [self.get_full_padding_segment()] * n_empty_segments\n",
    "            \n",
    "            # segmented_batch: \n",
    "            segmented_batch.append(input_segments)\n",
    "\n",
    "            if attn_mask is not None:\n",
    "                attn_mask_segments = [attn_mask[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "                attn_mask_segments = [self.pad_add_special_tokens(t, self.config.input_size, add_to='attention_mask') for t in attn_mask_segments]\n",
    "                attn_mask_segments = attn_mask_segments + [self.get_full_padding_segment()] * n_empty_segments\n",
    "                segmented_batch_attention_masks.append(attn_mask_segments)\n",
    "            \n",
    "            # TODO: labels need to be segmented by other rules\n",
    "            if label is not None:\n",
    "                labels_segments = [label[start:end] for (start, end) in zip(split_inds, split_inds[1:])]\n",
    "                labels_segments = [self.pad_add_special_tokens(t, self.config.input_size, add_to='labels') for t in labels_segments]\n",
    "                labels_segments = labels_segments + [self.get_full_padding_segment()] * n_empty_segments\n",
    "                segmented_batch_labels.append(labels_segments)\n",
    "                \n",
    "        segmented_batch = [[sample[seg_num] for sample in segmented_batch] \n",
    "                            for seg_num in range(self.config.max_n_segments)]\n",
    "        segmented_batch_attention_masks = [[sample[seg_num] for sample in segmented_batch_attention_masks]\n",
    "                                           for seg_num in range(self.config.max_n_segments)]\n",
    "        segmented_batch_labels = [[sample[seg_num] for sample in segmented_batch_labels]\n",
    "                                  for seg_num in range(self.config.max_n_segments)]\n",
    "\n",
    "        return segmented_batch, segmented_batch_attention_masks, segmented_batch_labels\n",
    "        \n",
    "    def extract_special_tokens(self, tokenizer):\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.special_token_ids = [tokenizer.pad_token_id]\n",
    "        for token in ['cls_token', 'sep_token', 'eos_token', 'bos_token']:\n",
    "            token_id = getattr(tokenizer, f'{token}_id')\n",
    "            if token_id is not None:\n",
    "                self.register_buffer(token, torch.tensor([token_id]))\n",
    "                self.special_token_ids.append(token_id)\n",
    "            else:\n",
    "                setattr(self, token, None)\n",
    "                \n",
    "    # def extend_word_embeddings(self, tokenizer):\n",
    "    #     vocab_size = self.model.config.vocab_size\n",
    "    #     # NOTE: Really necessary???\n",
    "    #     extended_vocab_size = vocab_size + self.config.pre_seq_len\n",
    "    #     self.pre_seq_len = self.config.pre_seq_len\n",
    "    \n",
    "    def get_full_padding_segment(self,):\n",
    "        padding_segment = torch.tensor([self.pad_token_id for _ in range(self.config.input_size)])\n",
    "        return padding_segment\n",
    "    \n",
    "    # Memory mechanism like RNN\n",
    "    def forget_and_memory(self,):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    #  prefix-tuning don't need to concat prefix and input sequence\n",
    "    def pad_add_special_tokens(self, tensor, segment_size, \n",
    "                               prompts=None, prompt_attention_mask=None, # maybe better to use pre_seq_len and generate prompts attention mask?\n",
    "                               add_to='input_ids'):\n",
    "        \"\"\"\n",
    "        bart tokenizer:\n",
    "        {'bos_token': '<s>', 0\n",
    "         'eos_token': '</s>', 2\n",
    "         'unk_token': '<unk>', 3\n",
    "         'sep_token': '</s>', 0\n",
    "         'pad_token': '<pad>', 1\n",
    "         'cls_token': '<s>', 0\n",
    "         'mask_token': '<mask>' 50264\n",
    "        }\n",
    "        \"\"\"\n",
    "        input_elements = []\n",
    "        # Add special tokens: <s> and </s> to the input sequence\n",
    "        # For prefix-prop\n",
    "        if prompts is not None:\n",
    "            if add_to == 'inputs':\n",
    "                input_elements += [self.cls_token, prompts, self.sep_token, tensor, self.sep_token]\n",
    "            # For Bart, only the pad token is 0 in attention_mask\n",
    "            elif add_to == 'attention_mask':\n",
    "                mask_value = torch.ones((1), device=tensor.device)\n",
    "                input_elements += [mask_value, prompt_attention_mask, mask_value, tensor, mask_value]\n",
    "            # As a encoder-decoder model：is not needed to add prompt to labels\n",
    "            elif add_to == 'labels':\n",
    "                input_elements += [self.eos_token, tensor, self.sep_token]\n",
    "        # For prefix-tuning/p-tuning v2\n",
    "        else:\n",
    "            if add_to == 'input_ids':\n",
    "                input_elements += [self.sep_token, tensor, self.sep_token]\n",
    "            elif add_to == 'attention_mask':\n",
    "                mask_value = torch.ones((1), device=tensor.device)\n",
    "                input_elements += [mask_value, tensor, mask_value]\n",
    "            elif add_to == 'labels':\n",
    "                input_elements += [self.eos_token, tensor, self.sep_token]\n",
    "        tensor = torch.cat(input_elements)\n",
    "\n",
    "        # Add padding tokens\n",
    "        # TODO: implement summary module\n",
    "        #       now self.config.sum_size default = 0\n",
    "        pad_size = segment_size - tensor.shape[0] - self.config.sum_token_size\n",
    "        if pad_size > 0:\n",
    "            if add_to == 'input_ids':\n",
    "                tensor = F.pad(tensor, (0, pad_size), value=self.pad_token_id)\n",
    "            # TODO: 显然有错误\n",
    "            elif add_to == 'attention_mask':\n",
    "                tensor = F.pad(tensor, (0, pad_size), value=0)\n",
    "            elif add_to == 'labels':\n",
    "                # TODO: dynamic padding labels??\n",
    "                # pad_size = min(pad_size, self.config.label_max_size)\n",
    "                # for Seq2Seq labels need to be pad by -100\n",
    "                tensor = F.pad(tensor, (0, pad_size), value=-100)\n",
    "        return tensor\n",
    "\n",
    "        # TODO: this implementation just add <s> and </s> to the input sequence\n",
    "        #       maybe need to add other special tokens\n",
    "    \n",
    "    def prepare_kwargs(self, segment, kwargs):\n",
    "        segment_input_ids, segment_attention_mask, segment_label = segment\n",
    "        seg_kwargs = dict(**kwargs)\n",
    "        \n",
    "        # [sample1_seg1, sample2_seg1, sample3_seg1,....] up to batch_size\n",
    "        # Some of the segments are None like: [sample1_seg3, None, sample3_seg3]\n",
    "        non_empty_mask = [s is not None for s in segment_input_ids]\n",
    "        print(\"non_empty_mask:\", non_empty_mask)\n",
    "        # all the segments are None, due to the max_n_segments >> the number of segments        \n",
    "        if sum(non_empty_mask) == 0:\n",
    "            return None, non_empty_mask\n",
    "        \n",
    "        # convert list to tensor\n",
    "        # print(\"segment_input_ids:\", segment_input_ids)\n",
    "        for s in segment_input_ids:\n",
    "            print(\"s:\", s.shape)\n",
    "        input_ids = torch.stack([s for s in segment_input_ids if s is not None])\n",
    "        print(\"input_ids:\", input_ids.shape)\n",
    "        # input_embeds = self.model.embeddings(input_ids)\n",
    "\n",
    "        seg_kwargs['input_ids'] = input_ids\n",
    "        print(\"input_ids:\", seg_kwargs['input_ids'].shape)\n",
    "        # seg_kwargs['inputs_embeds'] = input_embeds\n",
    "        \n",
    "        # if seg_kwargs.get('token_type_ids') is not None:\n",
    "        #     seg_kwargs['token_type_ids'] = self.get_token_type_ids(input_ids)\n",
    "\n",
    "        # seg_kwargs['decoder_input_ids'] = torch.stack([el for el, m in zip(segment_label, non_empty_mask) if m])\n",
    "        # seg_kwargs['decoder_input_ids'] = seg_kwargs['decoder_input_ids'][non_empty_mask]\n",
    "        # print(\"decoder_input_ids:\", seg_kwargs['decoder_input_ids'].shape)\n",
    "        # if seg_kwargs['labels_mask'] is not None:\n",
    "        # seg_kwargs['labels_mask'] = torch.stack([el for el, m in zip(segment_labels_mask, non_empty_mask) if m])\n",
    "        # if seg_kwargs.get('token_type_ids') is not None:\n",
    "        #     seg_kwargs['token_type_ids'] = self.get_token_type_ids(input_ids)\n",
    "        # seg_kwargs['output_hidden_states'] = True\n",
    "        \n",
    "        # generate prompts\n",
    "        batch_size = seg_kwargs['input_ids'].shape[0]\n",
    "        print('batch_size:', batch_size)\n",
    "        past_key_values = self.get_prompt(batch_size)\n",
    "        prefix_attention_mask = torch.ones(batch_size, self.pre_seq_len)\n",
    "        attention_mask = torch.stack([s for s in segment_attention_mask if s is not None])\n",
    "        \n",
    "        if seg_kwargs['labels'] is not None:\n",
    "            seg_kwargs['labels'] = torch.stack([el for el, m in zip(segment_label, non_empty_mask) if m])\n",
    "        \n",
    "        # attn_mask = torch.cat([prefix_attention_mask, attention_mask], dim=1)\n",
    "        seg_kwargs['past_key_values'] = past_key_values\n",
    "        seg_kwargs['attention_mask'] = self.get_attention_mask(input_ids)\n",
    "        \n",
    "        return seg_kwargs, non_empty_mask\n",
    "        \n",
    "    def get_attention_mask(self, tensor):\n",
    "        mask = torch.ones_like(tensor)\n",
    "        mask[tensor == self.pad_token_id] = 0\n",
    "        return mask\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
    "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = True,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, Seq2SeqLMOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
    "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
    "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
    "\n",
    "        Returns:\n",
    "        \"\"\" \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        kwargs = {\n",
    "            'attention_mask': attention_mask, \n",
    "            # 'token_type_ids': token_type_ids,\n",
    "            # 'position_ids': position_ids, \n",
    "            'inputs_embeds': inputs_embeds,\n",
    "            'labels': labels,\n",
    "            'output_attentions': output_attentions,\n",
    "            'output_hidden_states': output_hidden_states, \n",
    "            'return_dict': return_dict,\n",
    "        }\n",
    "        \n",
    "\n",
    "            \n",
    "        # MODIFIED: add prefix encoder\n",
    "        # batch_size = input_ids.shape[0]\n",
    "        # past_key_values = self.get_prompt(batch_size)\n",
    "        # prefix_attention_mask = torch.ones(batch_size, self.pre_seq_len)\n",
    "        # attention_mask = torch.cat([prefix_attention_mask, attention_mask], dim=1)\n",
    "        \n",
    "        # segmented: [max_n_segments, batch_size, segment_size]\n",
    "        # !!! Note: the batch_size is not the same as the input batch_size\n",
    "        segmented = self.pad_and_segment(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "        # NOTE: why???\n",
    "        # if self.pre_seq_len == 0:\n",
    "        #     segmented = segmented[-1:]\n",
    "        \n",
    "        model_outputs = []\n",
    "        for seg_num, segment in enumerate(zip(*segmented)):\n",
    "            print(\"seg_num:\", seg_num)\n",
    "            \n",
    "            in_ids, attn_mask, l = segment\n",
    "            print(\"batch_size:\", len(in_ids))\n",
    "            # TODO: can't control the number of gradient accumulation steps now\n",
    "            if self.config.bptt_depth != -1:\n",
    "                raise NotImplementedError\n",
    "            \n",
    "            seg_kwargs, non_empty_mask = self.prepare_kwargs(segment, kwargs)\n",
    "            # print(\"in_ids|attn_mask|l:\", seg_kwargs['input_ids'].shape, seg_kwargs['attention_mask'].shape, seg_kwargs['decoder_input_ids'].shape)\n",
    "            if sum(non_empty_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            out = self.model(**seg_kwargs)\n",
    "            print('decoder_input_ids:', decoder_input_ids)\n",
    "            # out = self.model(\n",
    "            #     input_ids=seg_kwargs['input_ids'],\n",
    "            #     attention_mask=seg_kwargs['attention_mask'],\n",
    "            #     # TODO: 只能concat attention到decoder attention mask\n",
    "            #     # past_key_values=seg_kwargs['past_key_values'],\n",
    "            #     # TODO: decoder_attention_mask: https://github.com/huggingface/transformers/issues/25271\n",
    "            #     decoder_input_ids=decoder_input_ids\n",
    "            # )\n",
    "            # self.prefix_tokens = out.encoder_last_hidden_state[-1][:, 1:self.pre_seq_len+1]\n",
    "            # self.prefix_tokens = out.last_hidden_state[:, :self.pre_seq_len]\n",
    "            print('prefix_tokens:', self.prefix_tokens.shape)\n",
    "            out['seg_kwargs'] = seg_kwargs\n",
    "            model_outputs.append(out)\n",
    "            print('out:', out)\n",
    "        out = self.process_outputs(model_outputs, output_attentions, output_hidden_states)\n",
    "        print('model is finished')\n",
    "        return out\n",
    "            \n",
    "    def generate(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
    "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        num_beams: Optional[int] = None,\n",
    "        min_length: Optional[int] = None,\n",
    "        max_length: Optional[int] = None,\n",
    "    ) -> Union[Tuple, Seq2SeqLMOutput]:\n",
    "        # Auto generate decoder_input_ids and decoder_attention_mask from labels\n",
    "        if (labels is not None) and (decoder_input_ids is None and decoder_inputs_embeds is None):\n",
    "            decoder_input_ids = shift_tokens_right(\n",
    "                labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
    "            )\n",
    "            if decoder_attention_mask is not None:\n",
    "                raise Exception # some error for passing 1/2 of decoder input_id/attn_mask?\n",
    "            decoder_attention_mask = torch.where(decoder_input_ids == self.config.pad_token_id, 0, 1)\n",
    "            \n",
    "        kwargs = {\n",
    "            'attention_mask': attention_mask, \n",
    "            # 'token_type_ids': token_type_ids,\n",
    "            # 'position_ids': position_ids, \n",
    "            'inputs_embeds': inputs_embeds,\n",
    "            'decoder_input_ids': labels, # NOTE: labels is used as decoder_input_ids\n",
    "            'output_attentions': output_attentions,\n",
    "            'output_hidden_states': output_hidden_states, \n",
    "            'return_dict': return_dict,\n",
    "            'num_beams': num_beams,\n",
    "            'min_length': min_length,\n",
    "            'max_length': max_length,\n",
    "        }\n",
    "        \n",
    "        segmented = self.pad_and_segment(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "        \n",
    "        model_outputs = []\n",
    "        for seg_num, segment in enumerate(zip(*segmented)):\n",
    "            in_ids, attn_mask, l = segment\n",
    "            \n",
    "            if self.config.bptt_depth != -1:\n",
    "                raise NotImplementedError\n",
    "            \n",
    "            seg_kwargs, non_empty_mask = self.prepare_kwargs(segment, kwargs)\n",
    "            if sum(non_empty_mask) == 0:\n",
    "                continue\n",
    "            \n",
    "            out = self.model.generate(\n",
    "                input_ids=seg_kwargs['input_ids'],\n",
    "                min_length=seg_kwargs['min_length'],\n",
    "                max_length=seg_kwargs['max_length'],\n",
    "                num_beams=seg_kwargs['num_beams'],\n",
    "            )\n",
    "            model_outputs.append(out)\n",
    "            print('out:', out)\n",
    "        print(\"model_outputs: \", self.tokenizer.decode(model_outputs[-1][0], skip_special_tokens=True))\n",
    "        \n",
    "    def process_outputs(self, model_outputs, output_attentions, output_hidden_states):\n",
    "        out = model_outputs[-1] # get the last segment output\n",
    "        \n",
    "        bs, seq_len = input_ids.shape\n",
    "        \n",
    "        losses = []\n",
    "        logits = []\n",
    "        labels_segm = []\n",
    "        \n",
    "        for out in model_outputs:\n",
    "            losses.append(out['loss'])\n",
    "            logits.append(out['logits'].detach())\n",
    "            labels_segm += [out['seg_kwargs']['labels']]\n",
    "        \n",
    "        if not output_hidden_states:\n",
    "            for key in out.keys():\n",
    "                if 'hidden_state' in key:\n",
    "                    out[key] = None\n",
    "                    \n",
    "        for i, l in enumerate(losses):\n",
    "            out[f'loss_{i}'] = l.mean()\n",
    "            \n",
    "        out['loss'] = torch.stack(losses).mean()\n",
    "        \n",
    "        for i in range(len(logits)):\n",
    "            logits[i] = F.pad(logits[i], (0, 0, 0, 0, 0, bs - logits[i].shape[0]))\n",
    "            labels_segm[i] = F.pad(labels_segm[i], (0, 0, 0, bs - labels_segm[i].shape[0]), value=-100)\n",
    "        \n",
    "        out['logits'] = torch.cat(logits, dim=1)\n",
    "        # Warning: rmt logits, labels, masks are not in the same order as in input data:\n",
    "        # the first dimension is number of segments!\n",
    "        # so, torch.cat will result in segm0, segm0,.. and only after all segm0 will come segm1, ... .\n",
    "        # not segm0, segm1, segm0, segm1 as in input data\n",
    "        out['logits_segm'] = [logits]\n",
    "        out['labels_segm'] = [labels_segm]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 139,604,736\n",
      "Trainable parameters: 184,320 0.132030%\n"
     ]
    }
   ],
   "source": [
    "# from model.summarization import BartPrefixForConditionalGeneration\n",
    "checkpoint = 'facebook/bart-base'\n",
    "model = BartPrefixForConditionalGeneration(    \n",
    "    checkpoint=checkpoint,\n",
    "    config=custom_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 2, 2, 0]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.special_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids.shape: torch.Size([32, 1024])\n",
      "attention_mask.shape: torch.Size([32, 1024])\n",
      "labels.shape: torch.Size([32, 128])\n",
      "seg_num: 0\n",
      "batch_size: 32\n",
      "non_empty_mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "batch_size: 32\n",
      "decoder_input_ids: None\n",
      "prefix_tokens: torch.Size([20])\n",
      "out: Seq2SeqLMOutput(loss=tensor(10.7538, grad_fn=<NllLossBackward0>), logits=tensor([[[ -0.7711,  -3.6456,   4.7643,  ...,  -3.1936,  -3.6050,  -0.2910],\n",
      "         [ -3.5079,  -4.0015,   4.2275,  ...,  -3.8197,  -4.2386,  -0.7017],\n",
      "         [ -8.5254,  -4.1201,  -0.6075,  ...,  -3.6225,  -3.8713,  -1.2421],\n",
      "         ...,\n",
      "         [ -8.6339,  -2.0752,  15.5890,  ...,  -1.9667,  -2.0484,  -3.6061],\n",
      "         [-10.3339,  -2.0696,  12.3024,  ...,  -1.9982,  -2.3085,  -4.3013],\n",
      "         [ 25.8074,   3.6523,  18.6839,  ...,   4.3239,   4.0059,   0.6598]],\n",
      "\n",
      "        [[ -0.4900,  -4.3565,   0.9911,  ...,  -3.7566,  -3.6996,  -0.2768],\n",
      "         [ -1.0444,  -3.7531,   1.4055,  ...,  -2.8416,  -2.7672,   0.3048],\n",
      "         [-10.5425,  -5.4111,  -0.2856,  ...,  -4.3411,  -4.6512,   0.6267],\n",
      "         ...,\n",
      "         [ -8.5442,  -3.2419,   4.6177,  ...,  -3.4212,  -2.8345,  -2.5816],\n",
      "         [ -8.5941,  -3.3175,   4.5037,  ...,  -3.5082,  -2.7994,  -2.3675],\n",
      "         [ -8.9356,  -3.4593,   3.6772,  ...,  -3.6007,  -2.8393,  -2.3709]],\n",
      "\n",
      "        [[-12.2619,  -5.5154,  -3.9527,  ...,  -3.5072,  -3.9651,  -0.7042],\n",
      "         [-11.1835,  -5.4432,  -2.5279,  ...,  -3.4645,  -3.8766,  -0.2971],\n",
      "         [-10.6961,  -4.9214,  -2.8249,  ...,  -3.3533,  -4.1500,  -1.5298],\n",
      "         ...,\n",
      "         [-13.3054,  -4.1546,   0.9466,  ...,  -1.9082,  -2.2996,  -0.4850],\n",
      "         [-13.8028,  -4.3461,   1.4250,  ...,  -1.7421,  -2.0848,  -0.0325],\n",
      "         [-13.7751,  -4.6238,   1.3866,  ...,  -1.8903,  -2.2132,  -0.6570]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -8.2056,  -4.7587,  -3.2439,  ...,  -3.2362,  -3.2173,  -2.7939],\n",
      "         [ -6.0369,  -4.4504,  -1.5013,  ...,  -2.6125,  -2.5962,  -3.1906],\n",
      "         [ -8.4653,  -5.1058,   0.1174,  ...,  -3.9769,  -4.6189,  -2.4613],\n",
      "         ...,\n",
      "         [-10.9742,  -4.4173,   3.2366,  ...,  -4.5392,  -4.9330,  -1.8694],\n",
      "         [-11.8963,  -4.4231,   3.0009,  ...,  -4.6058,  -5.0411,  -2.0754],\n",
      "         [-13.3158,  -4.4540,   3.0356,  ...,  -4.6861,  -5.2223,  -2.8809]],\n",
      "\n",
      "        [[ -8.8953,  -5.0603,   0.7321,  ...,  -4.2527,  -4.3384,  -0.6151],\n",
      "         [-11.5098,  -5.5566,  -0.4285,  ...,  -4.5346,  -4.6997,  -0.1853],\n",
      "         [ -5.4701,  -5.2335,  -0.3981,  ...,  -4.7720,  -4.6395,  -0.8768],\n",
      "         ...,\n",
      "         [ -1.9468,  -2.9727,   8.1168,  ...,  -1.6474,  -2.3481,  -1.0724],\n",
      "         [ -3.4391,  -3.2056,   7.3102,  ...,  -2.1868,  -2.9471,  -0.2469],\n",
      "         [ -5.6482,  -3.3350,   6.0362,  ...,  -2.4654,  -3.2496,  -1.1179]],\n",
      "\n",
      "        [[-15.4230,  -4.9016,  -3.7748,  ...,  -3.9725,  -4.4138,  -1.4966],\n",
      "         [-18.1302,  -5.2757,  -5.7869,  ...,  -3.9708,  -4.5705,  -1.4951],\n",
      "         [-12.0989,  -4.4536,  -4.6104,  ...,  -2.9170,  -3.7175,  -1.3178],\n",
      "         ...,\n",
      "         [ -5.9548,  -3.3638,   8.0121,  ...,  -2.1403,  -1.6205,  -0.9794],\n",
      "         [ -6.5840,  -3.4151,   7.9143,  ...,  -2.0082,  -1.4852,  -1.0295],\n",
      "         [ -7.6577,  -3.5413,   7.6006,  ...,  -2.1173,  -1.6982,  -1.6024]]],\n",
      "       grad_fn=<AddBackward0>), past_key_values=None, decoder_hidden_states=(tensor([[[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [ 0.1742,  0.1726,  0.1872,  ..., -0.4192,  0.1219, -0.3870],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [ 0.0265,  0.2606, -0.2435,  ...,  0.2487,  0.5109,  0.1550],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [-0.2754, -0.0814,  0.4363,  ..., -0.4677,  0.1007, -0.1236],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [-0.2754, -0.0814,  0.4363,  ..., -0.4677,  0.1007, -0.1236],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [-0.1470,  0.4237, -0.1054,  ..., -0.0757,  0.4690, -0.3391],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [ 0.5242,  0.6169,  0.2717,  ..., -0.7545,  0.4824,  0.1820],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]]]), tensor([[[ 0.8911, -0.1364, -0.3255,  ..., -0.0663, -0.1391,  0.1159],\n",
      "         [ 0.9094, -0.2769, -0.3577,  ..., -0.0864, -0.2645,  0.0537],\n",
      "         [ 0.0651, -0.0631,  0.1198,  ..., -0.3856, -0.2726, -0.8641],\n",
      "         ...,\n",
      "         [ 0.3806, -0.1113,  0.3029,  ...,  0.2014, -0.1576, -0.2337],\n",
      "         [ 0.3194, -0.1142,  0.3030,  ...,  0.3985, -0.3015, -0.3157],\n",
      "         [ 0.3600, -0.2306,  0.2187,  ...,  0.4644, -0.5640, -0.2059]],\n",
      "\n",
      "        [[ 0.7083,  0.2801, -0.3428,  ..., -0.2613, -0.2177,  0.4671],\n",
      "         [ 0.7206,  0.1077, -0.3151,  ..., -0.4240, -0.2036,  0.3559],\n",
      "         [-0.1556,  0.0657, -0.0796,  ..., -0.3777,  0.1482, -0.2241],\n",
      "         ...,\n",
      "         [ 0.0159, -0.0547,  0.1082,  ...,  0.4044, -0.4588, -0.2569],\n",
      "         [-0.0083, -0.0942,  0.1168,  ...,  0.5871, -0.6388, -0.3216],\n",
      "         [ 0.0518, -0.2114,  0.0925,  ...,  0.6936, -0.9450, -0.2369]],\n",
      "\n",
      "        [[ 0.8132,  0.1707, -0.3322,  ..., -0.7342, -0.0477, -0.2194],\n",
      "         [ 0.7800,  0.0999, -0.3361,  ..., -0.8281, -0.1516, -0.1581],\n",
      "         [-0.6120, -0.3929,  0.5834,  ..., -0.8743, -0.2954,  0.0950],\n",
      "         ...,\n",
      "         [ 0.1591, -0.1427,  0.1297,  ...,  0.5138, -0.4481, -0.3242],\n",
      "         [ 0.0899, -0.2156,  0.1332,  ...,  0.7154, -0.6032, -0.3841],\n",
      "         [ 0.1415, -0.3128,  0.0971,  ...,  0.8150, -0.9401, -0.2821]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9142,  0.1949, -0.2351,  ..., -0.0602,  0.0252,  0.3550],\n",
      "         [ 0.9011,  0.0376, -0.1843,  ..., -0.1466, -0.0634,  0.2568],\n",
      "         [-0.7347, -0.4067,  0.5686,  ..., -0.9865, -0.2687,  0.0097],\n",
      "         ...,\n",
      "         [ 0.0178, -0.1458,  0.2971,  ...,  0.3986, -0.3291, -0.2926],\n",
      "         [-0.0378, -0.1585,  0.2777,  ...,  0.6171, -0.4880, -0.3829],\n",
      "         [ 0.0487, -0.2867,  0.2355,  ...,  0.7056, -0.8168, -0.2530]],\n",
      "\n",
      "        [[ 0.7729, -0.0417, -0.1081,  ..., -0.3313, -0.0575,  0.3191],\n",
      "         [ 0.7373, -0.1312, -0.0998,  ..., -0.4584, -0.1482,  0.0481],\n",
      "         [-0.3645, -0.1631, -0.0386,  ..., -0.2426,  0.1913, -0.1843],\n",
      "         ...,\n",
      "         [ 0.1369, -0.1552,  0.2325,  ...,  0.2477, -0.2767, -0.2138],\n",
      "         [ 0.0853, -0.1933,  0.2495,  ...,  0.4452, -0.4135, -0.2788],\n",
      "         [ 0.1764, -0.3079,  0.1763,  ...,  0.5719, -0.7515, -0.1828]],\n",
      "\n",
      "        [[ 0.9101,  0.0997, -0.2686,  ..., -0.0804, -0.0693,  0.1517],\n",
      "         [ 0.8496, -0.0098, -0.2153,  ..., -0.2908, -0.2420,  0.1490],\n",
      "         [ 0.4445,  0.2802,  0.1477,  ..., -1.0959,  0.3328,  0.0542],\n",
      "         ...,\n",
      "         [ 0.0518, -0.2514,  0.2030,  ...,  0.3092, -0.3878, -0.1674],\n",
      "         [-0.0025, -0.2837,  0.1863,  ...,  0.4804, -0.5642, -0.2187],\n",
      "         [ 0.0708, -0.3763,  0.1184,  ...,  0.6346, -0.8870, -0.1222]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.3966,  0.0271, -0.7017,  ..., -0.1753, -0.2843, -0.1462],\n",
      "         [ 0.2036,  0.0615, -0.6938,  ..., -0.2501, -0.4423, -0.0554],\n",
      "         [-0.6252,  0.0175,  0.0619,  ...,  0.0719, -0.2999, -0.8405],\n",
      "         ...,\n",
      "         [-0.1056, -0.3915, -0.0570,  ...,  0.2478, -0.3391, -0.3130],\n",
      "         [-0.1131, -0.2933, -0.1045,  ...,  0.2382, -0.4213, -0.3724],\n",
      "         [-0.0176, -0.0785, -0.1801,  ...,  0.2231, -0.3860, -0.0788]],\n",
      "\n",
      "        [[ 0.4646,  0.0548, -0.5473,  ..., -0.2497, -0.5831, -0.0800],\n",
      "         [ 0.4008,  0.0275, -0.5413,  ..., -0.2876, -0.7242,  0.0122],\n",
      "         [-0.8739,  0.2364, -0.3212,  ...,  0.1800, -0.7311, -0.0554],\n",
      "         ...,\n",
      "         [-0.0678,  0.2257,  0.1211,  ...,  0.3844, -0.0818, -0.3308],\n",
      "         [-0.0501,  0.0501,  0.1254,  ...,  0.2523,  0.0697, -0.3080],\n",
      "         [-0.1320, -0.0248,  0.0105,  ...,  0.1754,  0.0517, -0.2547]],\n",
      "\n",
      "        [[ 0.4911,  0.0223, -0.2972,  ..., -0.3466, -0.4593, -0.2285],\n",
      "         [ 0.3556,  0.0973, -0.2462,  ..., -0.3685, -0.5553, -0.1778],\n",
      "         [-0.9746, -0.1338,  0.6475,  ...,  0.1143, -0.9146,  0.3128],\n",
      "         ...,\n",
      "         [-0.1942,  0.0407,  0.1211,  ...,  0.4018, -0.2396, -0.3629],\n",
      "         [-0.1859, -0.0086,  0.0918,  ...,  0.3742, -0.1929, -0.4262],\n",
      "         [-0.1375,  0.0630,  0.1338,  ...,  0.2599, -0.1762, -0.4092]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3097, -0.1188, -0.1637,  ..., -0.1236, -0.1883, -0.0684],\n",
      "         [ 0.2121, -0.0635, -0.0832,  ..., -0.0838, -0.1421, -0.0720],\n",
      "         [-0.8479, -0.2693,  0.6866,  ..., -0.2212, -0.9413,  0.3398],\n",
      "         ...,\n",
      "         [-0.2797,  0.3313,  0.1108,  ...,  0.0091, -0.4760,  0.0657],\n",
      "         [-0.1897,  0.4428,  0.1457,  ...,  0.1173, -0.5233, -0.0497],\n",
      "         [-0.0699,  0.3435,  0.2171,  ...,  0.2012, -0.5797, -0.1550]],\n",
      "\n",
      "        [[ 0.5175,  0.2410, -0.4888,  ..., -0.0305, -0.4321,  0.0989],\n",
      "         [ 0.3591,  0.1966, -0.3807,  ...,  0.0224, -0.5541,  0.1718],\n",
      "         [-0.5532, -0.0587,  0.0545,  ...,  0.2460,  0.2442,  0.0717],\n",
      "         ...,\n",
      "         [-0.2829, -0.1330, -0.1169,  ...,  0.1319, -0.2091,  0.4176],\n",
      "         [-0.3022, -0.0770, -0.1935,  ...,  0.1266, -0.1688,  0.3221],\n",
      "         [-0.2166, -0.1025, -0.0915,  ..., -0.0914, -0.2166,  0.2883]],\n",
      "\n",
      "        [[ 0.1632,  0.2526, -0.6106,  ..., -0.4309, -0.2628,  0.0772],\n",
      "         [ 0.0379,  0.3032, -0.5539,  ..., -0.6333, -0.3846, -0.0055],\n",
      "         [-0.6398,  0.3681, -0.1496,  ..., -0.8129, -0.4689, -0.1338],\n",
      "         ...,\n",
      "         [-0.2297,  0.2872,  0.2100,  ...,  0.0139, -0.3757,  0.0396],\n",
      "         [-0.3651,  0.2163,  0.3158,  ...,  0.0864, -0.4150, -0.1135],\n",
      "         [-0.3763,  0.2101,  0.3179,  ...,  0.1066, -0.4510, -0.1181]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-3.0379e-01,  8.9130e-02, -8.5531e-01,  ...,  1.1714e-01,\n",
      "           3.6482e-01, -2.2698e-01],\n",
      "         [-3.8881e-01,  7.2247e-02, -8.4689e-01,  ...,  9.0841e-02,\n",
      "           4.2716e-01, -6.9541e-02],\n",
      "         [-8.6187e-01,  6.6917e-02, -4.6597e-01,  ..., -1.0008e-01,\n",
      "           3.6403e-02, -8.8480e-01],\n",
      "         ...,\n",
      "         [-4.3152e-01, -1.7836e-01, -4.7432e-02,  ...,  1.3742e-01,\n",
      "          -2.8334e-01, -3.8968e-01],\n",
      "         [-4.3197e-01, -1.3370e-01, -8.0927e-02,  ...,  2.0029e-01,\n",
      "          -2.4788e-01, -4.4310e-01],\n",
      "         [-6.1017e-02,  1.2075e-03, -9.3776e-02,  ...,  1.0258e-01,\n",
      "          -6.0208e-02, -7.4623e-02]],\n",
      "\n",
      "        [[-3.3363e-01,  1.3919e-01, -8.9880e-01,  ..., -6.8382e-02,\n",
      "          -3.2666e-02,  8.7638e-02],\n",
      "         [-3.8749e-01,  1.5107e-01, -8.4487e-01,  ...,  4.6469e-02,\n",
      "          -1.5703e-01,  1.3782e-01],\n",
      "         [-8.0039e-01,  2.1933e-01, -3.9073e-01,  ...,  2.8995e-01,\n",
      "           2.4576e-01, -3.3755e-01],\n",
      "         ...,\n",
      "         [-1.3663e-01,  1.7097e-01, -4.3521e-01,  ...,  2.2939e-01,\n",
      "          -1.3354e-01,  3.1028e-01],\n",
      "         [-5.9052e-02, -5.1746e-02, -4.0647e-01,  ...,  1.5258e-01,\n",
      "          -1.8640e-02,  2.1470e-01],\n",
      "         [-9.2009e-02, -1.6123e-01, -5.1297e-01,  ...,  8.0546e-02,\n",
      "          -9.7213e-03,  1.8818e-01]],\n",
      "\n",
      "        [[-1.6764e-01,  1.3028e-01, -5.5249e-01,  ..., -2.6593e-01,\n",
      "           2.6085e-01,  3.9806e-01],\n",
      "         [-1.9176e-01,  1.3976e-01, -5.0378e-01,  ..., -1.9678e-01,\n",
      "           1.6960e-01,  3.7597e-01],\n",
      "         [-8.7605e-01, -2.3974e-01, -9.9142e-02,  ..., -2.2890e-01,\n",
      "          -5.4775e-01,  1.0016e-02],\n",
      "         ...,\n",
      "         [-6.6178e-02,  2.5493e-01, -3.8842e-01,  ...,  9.9297e-02,\n",
      "          -3.2154e-01,  2.7477e-01],\n",
      "         [-8.6071e-02,  2.5536e-01, -4.4663e-01,  ...,  2.1015e-01,\n",
      "          -2.2131e-01,  2.8518e-01],\n",
      "         [-2.6208e-02,  3.0018e-01, -4.7040e-01,  ...,  1.3138e-01,\n",
      "          -1.7678e-01,  2.8497e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.8846e-01, -4.7073e-02, -3.0240e-01,  ..., -1.7808e-02,\n",
      "           2.2956e-01,  2.4981e-02],\n",
      "         [-4.8390e-01,  3.3816e-02, -1.9710e-01,  ...,  7.9657e-02,\n",
      "           2.6175e-01,  4.8756e-02],\n",
      "         [-9.5279e-01, -1.7470e-01, -5.9849e-01,  ..., -3.5460e-01,\n",
      "          -5.5417e-01,  2.4002e-02],\n",
      "         ...,\n",
      "         [-2.6355e-01,  4.7814e-01, -7.1012e-01,  ...,  1.9665e-01,\n",
      "          -2.5270e-01,  9.8110e-02],\n",
      "         [-2.2594e-01,  6.0717e-01, -6.5153e-01,  ...,  3.9104e-01,\n",
      "          -2.7439e-01,  3.1208e-02],\n",
      "         [-1.2988e-01,  5.0515e-01, -5.3816e-01,  ...,  4.8959e-01,\n",
      "          -2.4101e-01,  7.6368e-02]],\n",
      "\n",
      "        [[-4.6051e-01,  4.4903e-01, -7.2497e-01,  ...,  1.3305e-01,\n",
      "           4.1099e-01,  3.5206e-01],\n",
      "         [-6.6848e-01,  4.3555e-01, -7.1390e-01,  ...,  2.6498e-01,\n",
      "           3.3582e-01,  4.6351e-01],\n",
      "         [-5.0867e-01, -3.3289e-04, -2.2127e-01,  ...,  6.2963e-02,\n",
      "           4.2399e-01,  2.0219e-01],\n",
      "         ...,\n",
      "         [-5.1740e-01, -1.9076e-01, -5.6027e-01,  ...,  6.8301e-02,\n",
      "          -5.1624e-01,  7.5801e-01],\n",
      "         [-6.5055e-01, -1.3245e-01, -5.0253e-01,  ...,  1.2704e-01,\n",
      "          -4.7759e-01,  7.6237e-01],\n",
      "         [-4.8402e-01, -1.4631e-02, -3.8170e-01,  ...,  3.2936e-02,\n",
      "          -2.4028e-01,  4.6007e-01]],\n",
      "\n",
      "        [[-4.1815e-01,  7.1986e-02, -7.2632e-01,  ...,  2.3483e-02,\n",
      "           7.7986e-01, -1.4377e-01],\n",
      "         [-4.1616e-01,  8.4383e-02, -6.4405e-01,  ..., -2.6611e-02,\n",
      "           6.2470e-01, -1.1882e-01],\n",
      "         [-1.2801e+00,  2.2832e-01, -6.8636e-01,  ..., -4.1883e-01,\n",
      "           2.2652e-01,  6.2182e-03],\n",
      "         ...,\n",
      "         [-6.3620e-02,  4.1649e-01, -2.7464e-01,  ...,  2.5880e-01,\n",
      "           4.2739e-02, -1.1099e-01],\n",
      "         [-1.8797e-01,  4.3171e-01, -2.1071e-01,  ...,  3.3790e-01,\n",
      "          -1.2576e-02, -1.1793e-01],\n",
      "         [-2.1959e-01,  4.4599e-01, -1.9679e-01,  ...,  3.6852e-01,\n",
      "          -6.2331e-02, -7.1471e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.1243,  0.2169, -0.5540,  ..., -0.2518, -0.2556, -0.3490],\n",
      "         [-0.2785,  0.1409, -0.4693,  ..., -0.2105, -0.2669, -0.1198],\n",
      "         [-0.9040,  0.1905, -0.1371,  ...,  0.0681, -0.4507, -0.4254],\n",
      "         ...,\n",
      "         [-0.5623, -0.2627, -0.2352,  ..., -0.2901, -0.4598, -0.2723],\n",
      "         [-0.4890, -0.2405, -0.2398,  ..., -0.2236, -0.4639, -0.2967],\n",
      "         [-0.0092,  0.0025, -0.0164,  ..., -0.0080, -0.4155,  0.0093]],\n",
      "\n",
      "        [[ 0.1156,  0.4454, -0.8030,  ...,  0.0375, -0.3702, -0.1503],\n",
      "         [ 0.1379,  0.4516, -0.8282,  ...,  0.0514, -0.4285, -0.1210],\n",
      "         [-0.2152,  0.1889, -0.2833,  ..., -0.3622, -0.2226, -0.3531],\n",
      "         ...,\n",
      "         [ 0.1419, -0.3218, -0.3762,  ..., -0.3294, -0.3470,  0.0514],\n",
      "         [ 0.1087, -0.4573, -0.2660,  ..., -0.3796, -0.3469,  0.0963],\n",
      "         [ 0.0664, -0.5496, -0.2800,  ..., -0.3977, -0.3524,  0.0925]],\n",
      "\n",
      "        [[-0.0209,  0.1789, -0.4416,  ..., -0.0141, -0.3771,  0.0434],\n",
      "         [-0.0095,  0.1828, -0.3846,  ..., -0.0517, -0.4152, -0.1082],\n",
      "         [-0.6176,  0.3169, -0.4213,  ..., -0.5060, -0.4177,  0.2228],\n",
      "         ...,\n",
      "         [ 0.1193,  0.2650, -0.2865,  ..., -0.3211, -0.4658, -0.2860],\n",
      "         [ 0.0940,  0.2234, -0.3405,  ..., -0.1510, -0.4668, -0.3124],\n",
      "         [ 0.1621,  0.2475, -0.3734,  ..., -0.1147, -0.4803, -0.3498]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3822,  0.0790, -0.4336,  ...,  0.0501, -0.3905, -0.0881],\n",
      "         [-0.3645,  0.1694, -0.3281,  ...,  0.0893, -0.4130, -0.1058],\n",
      "         [-0.5459, -0.0797, -0.3628,  ..., -0.5022, -0.5306, -0.0863],\n",
      "         ...,\n",
      "         [ 0.2729,  0.4515, -0.5343,  ..., -0.1792, -0.4707,  0.0445],\n",
      "         [ 0.2817,  0.5175, -0.4963,  ..., -0.0718, -0.4640,  0.0423],\n",
      "         [ 0.2131,  0.3646, -0.4938,  ..., -0.0280, -0.4237,  0.0359]],\n",
      "\n",
      "        [[-0.1331,  0.8524, -0.8748,  ...,  0.1817, -0.2530, -0.3025],\n",
      "         [-0.3013,  0.7847, -0.8793,  ...,  0.1622, -0.2744, -0.2956],\n",
      "         [ 0.0865,  0.1044, -0.6266,  ..., -0.1558, -0.3835, -0.0661],\n",
      "         ...,\n",
      "         [-0.0424, -0.1983, -0.4262,  ...,  0.0818, -0.5177,  0.2064],\n",
      "         [-0.1115, -0.1502, -0.3612,  ...,  0.0387, -0.5038,  0.1486],\n",
      "         [-0.1796, -0.0368, -0.2717,  ..., -0.0228, -0.4332, -0.2973]],\n",
      "\n",
      "        [[ 0.0459,  0.1498, -0.4835,  ..., -0.3987, -0.2654, -0.2132],\n",
      "         [-0.1640,  0.2563, -0.4330,  ..., -0.4431, -0.3475, -0.2130],\n",
      "         [-0.7311,  0.0667, -0.3530,  ..., -0.4015, -0.4752,  0.0715],\n",
      "         ...,\n",
      "         [ 0.3909,  0.3207, -0.1829,  ..., -0.2690, -0.3719, -0.0331],\n",
      "         [ 0.3287,  0.3664, -0.0942,  ..., -0.2101, -0.3698, -0.0625],\n",
      "         [ 0.3030,  0.3787, -0.0831,  ..., -0.2546, -0.3685, -0.0930]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-2.5653e-01,  3.8020e-01, -8.3538e-01,  ...,  2.9195e-01,\n",
      "          -1.1379e-01,  4.1938e-01],\n",
      "         [-4.2144e-01,  3.4464e-01, -5.8304e-01,  ...,  3.7372e-01,\n",
      "          -2.0668e-02,  4.3731e-01],\n",
      "         [-6.8210e-01, -3.8106e-02, -2.5667e-01,  ...,  5.8514e-01,\n",
      "           1.0053e-01, -2.4864e-01],\n",
      "         ...,\n",
      "         [-6.8005e-01, -1.1232e-01, -2.1604e-01,  ..., -5.2296e-01,\n",
      "          -1.5643e-01,  3.8846e-01],\n",
      "         [-6.4847e-01, -5.7061e-02, -2.1057e-01,  ..., -3.6123e-01,\n",
      "          -1.5693e-01,  3.4769e-01],\n",
      "         [-8.1662e-03, -8.5763e-03, -2.6149e-02,  ..., -2.6977e-02,\n",
      "          -6.8160e-02, -3.3905e-02]],\n",
      "\n",
      "        [[ 3.7857e-02,  2.2687e-01, -8.2353e-01,  ...,  1.0811e-01,\n",
      "          -1.3059e-02,  2.2865e-01],\n",
      "         [-5.3588e-02,  9.4748e-02, -8.8446e-01,  ...,  9.0609e-02,\n",
      "          -1.1790e-01,  2.8126e-01],\n",
      "         [ 6.4557e-02, -4.4709e-01, -4.1544e-01,  ..., -1.0026e-01,\n",
      "          -1.5895e-01,  1.9020e-01],\n",
      "         ...,\n",
      "         [-8.5341e-02, -8.2886e-02, -3.7993e-01,  ..., -6.1048e-01,\n",
      "          -1.5266e-01,  7.0546e-01],\n",
      "         [-7.9216e-02, -2.8006e-01, -1.7778e-01,  ..., -6.2327e-01,\n",
      "          -2.2092e-01,  6.5851e-01],\n",
      "         [-7.8149e-02, -3.9351e-01, -1.2165e-01,  ..., -6.2124e-01,\n",
      "          -2.2503e-01,  6.0550e-01]],\n",
      "\n",
      "        [[ 3.4973e-02,  3.8947e-01, -6.6502e-01,  ...,  1.2878e-01,\n",
      "           1.5279e-02,  1.4109e-01],\n",
      "         [-2.1594e-02,  4.1044e-01, -6.0492e-01,  ...,  9.7123e-02,\n",
      "          -1.2698e-03,  1.3057e-01],\n",
      "         [-3.6282e-01, -8.1634e-02, -3.0843e-01,  ..., -4.1026e-01,\n",
      "           5.6906e-02,  5.5903e-01],\n",
      "         ...,\n",
      "         [-3.4561e-01,  3.7090e-01, -2.0477e-01,  ..., -4.8129e-01,\n",
      "          -2.2236e-01,  3.7488e-01],\n",
      "         [-3.4363e-01,  2.4571e-01, -2.1519e-01,  ..., -3.2855e-01,\n",
      "          -2.6460e-01,  4.0524e-01],\n",
      "         [-2.6041e-01,  2.4763e-01, -2.2422e-01,  ..., -3.2881e-01,\n",
      "          -2.7728e-01,  4.0187e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.8288e-01,  1.7695e-01, -4.4777e-01,  ..., -9.4529e-02,\n",
      "           8.1622e-02,  3.8674e-01],\n",
      "         [-1.1992e-01,  3.5066e-01, -3.3133e-01,  ...,  1.3914e-01,\n",
      "           1.2971e-01,  5.0148e-01],\n",
      "         [-2.1772e-01, -2.1633e-01, -6.6762e-01,  ..., -1.2494e-01,\n",
      "          -1.1440e-01,  3.6183e-01],\n",
      "         ...,\n",
      "         [ 1.9369e-01,  8.6628e-01, -5.4071e-01,  ...,  2.8535e-05,\n",
      "          -3.2905e-02,  7.0759e-01],\n",
      "         [ 2.5456e-01,  8.9284e-01, -5.4100e-01,  ...,  4.1912e-02,\n",
      "          -4.9601e-02,  7.4919e-01],\n",
      "         [ 2.0702e-01,  8.0029e-01, -4.5605e-01,  ...,  3.2619e-02,\n",
      "          -3.5419e-02,  7.5633e-01]],\n",
      "\n",
      "        [[ 9.4052e-02,  4.1965e-01, -1.1999e+00,  ...,  3.0200e-01,\n",
      "           1.1944e-01, -3.3908e-01],\n",
      "         [ 2.5494e-02,  3.6858e-01, -1.1571e+00,  ...,  4.4345e-01,\n",
      "           1.0403e-01, -3.2006e-01],\n",
      "         [-1.1257e-01, -6.7929e-02, -6.8048e-01,  ...,  3.0472e-01,\n",
      "          -8.0611e-02,  8.3335e-01],\n",
      "         ...,\n",
      "         [-2.8746e-01,  7.0625e-02, -6.3112e-01,  ...,  2.9858e-01,\n",
      "          -1.0406e-01,  4.2126e-01],\n",
      "         [-3.8383e-01,  1.2729e-01, -5.9420e-01,  ...,  2.8321e-01,\n",
      "          -7.9799e-02,  3.2483e-01],\n",
      "         [-3.8030e-01,  2.0044e-01, -5.1588e-01,  ...,  2.2077e-01,\n",
      "          -7.5533e-02,  1.0766e-01]],\n",
      "\n",
      "        [[ 1.3840e-01,  1.4764e-01, -5.9037e-01,  ..., -2.2789e-01,\n",
      "           1.7365e-01,  5.3790e-01],\n",
      "         [-1.7878e-02,  1.1165e-01, -4.8811e-01,  ..., -3.6846e-01,\n",
      "           3.3822e-02,  5.1021e-01],\n",
      "         [-5.9714e-01, -4.4713e-01, -8.1742e-01,  ..., -3.3103e-01,\n",
      "          -2.4120e-01,  3.4121e-01],\n",
      "         ...,\n",
      "         [-1.9487e-01,  4.3961e-01, -2.8080e-01,  ..., -4.6299e-01,\n",
      "          -7.5667e-02,  3.7428e-01],\n",
      "         [-2.1264e-01,  4.6722e-01, -2.0831e-01,  ..., -3.8009e-01,\n",
      "          -8.9398e-02,  4.0221e-01],\n",
      "         [-2.1837e-01,  4.2966e-01, -1.5825e-01,  ..., -3.9634e-01,\n",
      "          -8.1195e-02,  3.9352e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 7.1490e-01,  1.0426e+00, -1.4352e+00,  ...,  2.2641e+00,\n",
      "           4.9185e+00, -1.1977e+00],\n",
      "         [ 3.2868e-01,  1.0303e+00, -1.3608e+00,  ...,  2.1884e+00,\n",
      "           4.7756e+00, -5.5558e-01],\n",
      "         [-6.4203e-01, -1.0101e-03,  8.1174e-01,  ...,  2.4218e+00,\n",
      "           3.8359e+00, -1.4938e+00],\n",
      "         ...,\n",
      "         [-9.5346e-01, -1.4132e+00, -6.9167e-01,  ..., -2.2049e+00,\n",
      "          -6.9825e-01,  2.0159e+00],\n",
      "         [-1.0212e+00, -9.5790e-01, -1.0289e+00,  ..., -1.5320e+00,\n",
      "          -9.8192e-02,  1.8672e+00],\n",
      "         [ 2.9031e+00,  2.5718e+00,  8.1638e-01,  ...,  1.7284e+00,\n",
      "           2.2995e-01, -1.0356e+00]],\n",
      "\n",
      "        [[ 2.6863e+00,  7.0051e-01,  2.0810e+00,  ...,  6.8357e-01,\n",
      "           4.6522e+00, -1.2265e+00],\n",
      "         [ 2.3632e+00,  3.8084e-01,  1.7229e+00,  ...,  6.6038e-01,\n",
      "           4.4631e+00, -9.4258e-01],\n",
      "         [ 1.5795e+00,  6.0749e-01,  2.2596e+00,  ...,  1.3175e+00,\n",
      "           1.8959e+00, -2.0618e+00],\n",
      "         ...,\n",
      "         [ 1.8601e+00,  4.9377e-01,  1.6086e+00,  ..., -1.3221e+00,\n",
      "           3.9687e-01,  5.0650e-01],\n",
      "         [ 2.0369e+00, -8.4817e-03,  2.5287e+00,  ..., -1.4179e+00,\n",
      "          -3.4990e-01,  9.0006e-01],\n",
      "         [ 2.1486e+00, -2.6384e-01,  2.9168e+00,  ..., -1.3274e+00,\n",
      "          -9.4527e-01,  1.1113e+00]],\n",
      "\n",
      "        [[ 2.4609e+00,  1.1483e+00, -1.6246e-01,  ...,  2.3944e+00,\n",
      "           5.9812e+00, -2.3380e+00],\n",
      "         [ 2.4954e+00,  1.1690e+00,  2.9409e-02,  ...,  2.6083e+00,\n",
      "           6.0319e+00, -2.5606e+00],\n",
      "         [ 1.6375e+00,  6.8721e-01,  2.3200e+00,  ...,  7.4504e-02,\n",
      "           4.1853e+00, -7.8742e-01],\n",
      "         ...,\n",
      "         [-2.6858e-01,  1.6670e+00, -6.5072e-01,  ..., -1.9422e+00,\n",
      "          -1.9250e-01,  1.7568e+00],\n",
      "         [ 2.4018e-02,  8.4662e-01, -3.8947e-01,  ..., -1.3396e+00,\n",
      "          -2.9595e-01,  2.1844e+00],\n",
      "         [ 5.0629e-01,  7.3788e-01, -3.6356e-01,  ..., -1.1607e+00,\n",
      "          -2.7390e-01,  2.2668e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5644e+00,  1.1423e+00, -2.7254e+00,  ...,  7.4949e-01,\n",
      "           5.6660e+00, -1.0481e+00],\n",
      "         [ 1.6472e+00,  1.7447e+00, -2.2076e+00,  ...,  1.5185e+00,\n",
      "           5.4691e+00, -4.8169e-01],\n",
      "         [ 2.2079e+00,  4.3793e-01, -7.8510e-01,  ...,  1.7147e+00,\n",
      "           1.6178e+00, -7.4383e-01],\n",
      "         ...,\n",
      "         [ 3.4404e+00,  2.9517e+00, -7.0463e-01,  ...,  8.3023e-01,\n",
      "           9.6943e-01,  5.0491e-02],\n",
      "         [ 3.6957e+00,  3.1930e+00, -7.6013e-01,  ...,  1.0879e+00,\n",
      "           7.9117e-01,  2.8209e-01],\n",
      "         [ 3.2228e+00,  3.1674e+00, -5.3642e-01,  ...,  1.0182e+00,\n",
      "           4.7496e-01,  5.7614e-01]],\n",
      "\n",
      "        [[ 2.4579e+00,  1.2773e+00, -1.1520e+00,  ...,  1.3935e+00,\n",
      "           1.8652e+00, -3.0418e+00],\n",
      "         [ 2.4557e+00,  1.0474e+00, -1.3525e+00,  ...,  2.2873e+00,\n",
      "           2.3713e+00, -3.7122e+00],\n",
      "         [ 5.1436e-01, -1.8422e-01,  2.3641e-01,  ...,  4.0808e-01,\n",
      "           8.6083e-01, -1.6467e-01],\n",
      "         ...,\n",
      "         [ 7.2440e-02,  1.9108e-02, -2.3824e+00,  ...,  1.5321e+00,\n",
      "           1.2994e+00,  1.8378e+00],\n",
      "         [-6.0087e-02,  2.8597e-01, -2.1541e+00,  ...,  1.6872e+00,\n",
      "           1.6367e+00,  1.3335e+00],\n",
      "         [ 2.2830e-01,  5.9209e-01, -2.0218e+00,  ...,  1.6904e+00,\n",
      "           1.7925e+00,  4.8019e-01]],\n",
      "\n",
      "        [[ 1.5424e+00,  3.4170e+00, -1.0500e+00,  ...,  1.1170e-01,\n",
      "           5.4868e+00, -1.5311e+00],\n",
      "         [ 7.7116e-01,  3.6759e+00, -9.2202e-01,  ..., -2.0687e-01,\n",
      "           4.2758e+00, -1.8180e+00],\n",
      "         [ 1.5082e+00,  2.6064e-01, -9.3865e-01,  ...,  1.2903e-02,\n",
      "           3.4433e+00, -3.3452e+00],\n",
      "         ...,\n",
      "         [-9.9443e-01,  2.6801e+00,  3.0429e-01,  ..., -1.8798e+00,\n",
      "          -2.7742e-01,  7.2905e-01],\n",
      "         [-9.4402e-01,  2.5558e+00,  4.4089e-01,  ..., -1.5974e+00,\n",
      "          -3.4991e-01,  7.6650e-01],\n",
      "         [-8.8761e-01,  2.2482e+00,  4.3790e-01,  ..., -1.6694e+00,\n",
      "          -2.4854e-01,  8.2001e-01]]], grad_fn=<NativeLayerNormBackward0>)), decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-3.5745e-02,  8.8268e-03, -1.2027e-03,  ...,  1.1396e-02,\n",
      "          -1.4661e-03, -1.1811e-02],\n",
      "         [ 1.4367e-01,  3.8184e-01,  3.8923e-01,  ..., -4.7614e-01,\n",
      "          -1.0176e-01,  1.9167e-02],\n",
      "         [-3.0674e-01, -4.9893e-03,  8.6143e-02,  ..., -2.4232e-01,\n",
      "          -1.8271e-01, -5.9778e-02],\n",
      "         ...,\n",
      "         [ 9.5454e-02,  1.7104e-01,  1.2741e-02,  ...,  3.9884e-02,\n",
      "           9.2760e-02, -3.5920e-02],\n",
      "         [ 1.0944e-01,  1.9966e-01,  5.6768e-03,  ...,  3.2334e-02,\n",
      "           1.5919e-01, -5.0886e-02],\n",
      "         [ 3.6118e-01, -3.5335e-02, -1.4816e-02,  ...,  2.3522e-01,\n",
      "           5.6379e-01, -1.4918e-02]],\n",
      "\n",
      "        [[-3.5863e-02,  9.0216e-03, -2.1364e-03,  ...,  1.1928e-02,\n",
      "           3.4421e-04, -1.5176e-02],\n",
      "         [-6.2374e-03,  3.2295e-01,  3.0040e-01,  ..., -1.9724e-01,\n",
      "          -9.2731e-02,  4.2038e-01],\n",
      "         [ 7.8879e-02,  1.2099e-01,  1.2001e-01,  ..., -1.4488e-01,\n",
      "           5.6239e-03,  2.2286e-01],\n",
      "         ...,\n",
      "         [ 9.0471e-02,  1.4833e-01, -4.4878e-02,  ...,  2.3048e-02,\n",
      "           1.7881e-01, -2.6949e-02],\n",
      "         [ 6.8973e-02,  1.3377e-01, -6.2255e-02,  ..., -3.7848e-03,\n",
      "           1.8692e-01, -6.3762e-02],\n",
      "         [ 1.4406e-01,  1.6237e-01, -9.7032e-02,  ..., -1.0900e-02,\n",
      "           1.7336e-01, -7.3576e-02]],\n",
      "\n",
      "        [[-3.8195e-02,  7.3286e-03, -2.0211e-03,  ...,  1.0376e-02,\n",
      "          -1.3337e-03, -1.4168e-02],\n",
      "         [-1.3370e-01,  2.8188e-01,  3.4861e-01,  ..., -2.6183e-01,\n",
      "          -2.1265e-02,  3.8104e-01],\n",
      "         [ 4.8100e-02,  3.7753e-02,  9.5221e-02,  ..., -2.4733e-01,\n",
      "           1.3990e-02,  1.9642e-01],\n",
      "         ...,\n",
      "         [ 1.6987e-01,  2.5670e-01, -6.7638e-02,  ...,  8.1464e-02,\n",
      "           2.4591e-01,  2.9468e-02],\n",
      "         [ 6.1052e-02,  1.6752e-01, -1.4917e-02,  ...,  2.0721e-02,\n",
      "           8.1627e-02, -4.8428e-02],\n",
      "         [ 1.0534e-01,  2.8852e-01, -9.3444e-02,  ..., -2.8984e-03,\n",
      "           2.1471e-01, -2.0690e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.6398e-02,  9.0313e-03, -1.9369e-03,  ...,  1.1063e-02,\n",
      "          -1.6230e-03, -1.3801e-02],\n",
      "         [ 7.2394e-02,  1.3025e-01,  1.2008e-02,  ..., -6.7950e-01,\n",
      "          -2.5421e-01,  3.4263e-01],\n",
      "         [ 3.6840e-02,  3.0900e-01,  1.6183e-01,  ..., -1.6243e-01,\n",
      "           3.3092e-02,  4.8373e-01],\n",
      "         ...,\n",
      "         [ 3.1848e-01,  6.6436e-02, -9.5219e-03,  ...,  1.3734e-01,\n",
      "           3.6635e-01,  1.9097e-01],\n",
      "         [ 1.5882e-01,  2.1736e-01, -2.2585e-02,  ...,  2.7520e-02,\n",
      "           2.6909e-01,  1.8777e-02],\n",
      "         [ 2.4030e-01,  1.4493e-01, -7.6411e-02,  ...,  1.3902e-01,\n",
      "           4.3259e-01,  4.6514e-02]],\n",
      "\n",
      "        [[-3.6898e-02,  8.0207e-03, -2.7144e-03,  ...,  1.1667e-02,\n",
      "          -1.2370e-03, -1.3637e-02],\n",
      "         [ 3.5688e-01, -1.4431e-01,  3.9117e-01,  ..., -4.5789e-01,\n",
      "          -5.4167e-01,  6.6350e-02],\n",
      "         [ 2.8837e-01,  1.3654e-01,  4.1197e-01,  ..., -6.8346e-01,\n",
      "          -4.0116e-01, -1.7989e-01],\n",
      "         ...,\n",
      "         [ 8.0119e-02,  9.0630e-02, -4.9434e-02,  ...,  4.7402e-02,\n",
      "           7.0586e-02, -8.8313e-02],\n",
      "         [ 7.9258e-02,  1.0533e-01, -4.2686e-02,  ...,  4.6321e-02,\n",
      "           8.8614e-02, -8.3294e-02],\n",
      "         [ 8.3239e-02,  1.1032e-01, -4.2938e-02,  ...,  1.9482e-02,\n",
      "           4.2302e-02, -5.6846e-02]],\n",
      "\n",
      "        [[-3.7537e-02,  8.0758e-03, -2.0962e-03,  ...,  1.0937e-02,\n",
      "          -2.3940e-03, -1.3104e-02],\n",
      "         [-1.8002e-01,  2.6632e-01,  3.0659e-01,  ..., -2.5578e-01,\n",
      "          -4.7298e-02,  4.0828e-01],\n",
      "         [ 1.2617e-01,  2.7602e-02,  9.4449e-02,  ..., -2.5698e-01,\n",
      "          -5.1935e-02,  2.2923e-01],\n",
      "         ...,\n",
      "         [ 4.5839e-02,  1.9339e-01, -3.0199e-02,  ...,  1.8919e-02,\n",
      "           1.6875e-01,  4.7387e-02],\n",
      "         [ 7.1682e-02,  2.1171e-01, -8.5704e-03,  ...,  1.2957e-02,\n",
      "           1.9582e-01,  5.3831e-02],\n",
      "         [ 1.6799e-01,  1.8937e-01, -8.2689e-02,  ...,  1.0582e-01,\n",
      "           3.3687e-01, -2.0829e-03]]]), encoder_hidden_states=(tensor([[[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.6842,  0.0244,  0.5646,  ..., -0.2659, -0.1468, -0.3223],\n",
      "         [-0.3948, -0.1109,  0.3872,  ..., -0.2016, -0.0933,  0.0181],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.0258, -0.1399,  0.0230,  ..., -0.1057, -0.2303,  0.3949],\n",
      "         [ 0.1203, -0.2499, -0.3727,  ..., -0.4963, -0.1258,  0.3642],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.0258, -0.1399,  0.0230,  ..., -0.1057, -0.2303,  0.3949],\n",
      "         [ 0.1203, -0.2499, -0.3727,  ..., -0.4963, -0.1258,  0.3642],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.0281, -0.1556, -0.0626,  ..., -0.0102, -0.6082,  0.3842],\n",
      "         [ 0.2644, -0.0536,  0.3005,  ..., -0.1117, -0.2438,  0.0645],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.5605, -0.2375,  0.4582,  ..., -0.2304, -1.3615,  0.0061],\n",
      "         [-0.0774, -0.0784,  0.2087,  ...,  0.2008, -0.2986, -0.1076],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.0258, -0.1399,  0.0230,  ..., -0.1057, -0.2303,  0.3949],\n",
      "         [ 0.1203, -0.2499, -0.3727,  ..., -0.4963, -0.1258,  0.3642],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]]]), tensor([[[-0.0353, -0.0277,  0.0630,  ...,  0.0256, -0.0278,  0.0242],\n",
      "         [ 0.5894,  0.1181,  0.7072,  ...,  0.2288,  0.1117, -0.0521],\n",
      "         [-0.2510,  0.3698,  0.0659,  ...,  0.1475, -0.2854,  0.2002],\n",
      "         ...,\n",
      "         [ 0.2979,  0.6588,  0.2385,  ...,  0.5052,  0.4085, -0.0217],\n",
      "         [ 0.6166,  0.5528,  0.1341,  ...,  0.5420,  0.3530, -0.0903],\n",
      "         [ 0.6815,  0.3507, -0.2360,  ...,  0.4582,  0.3945,  0.0500]],\n",
      "\n",
      "        [[-0.0460, -0.0222,  0.0589,  ...,  0.0170, -0.0177,  0.0205],\n",
      "         [-0.2708, -0.0412,  0.4505,  ..., -0.1459, -0.2562,  0.2778],\n",
      "         [ 0.1112, -0.2639, -0.1804,  ..., -0.3723, -0.1957,  0.5110],\n",
      "         ...,\n",
      "         [ 0.1757,  0.6946,  0.1266,  ...,  0.5960,  0.4747, -0.2967],\n",
      "         [ 0.2520,  0.6783,  0.0547,  ...,  0.6924,  0.3806, -0.1824],\n",
      "         [ 0.4538,  0.3945, -0.1242,  ...,  0.8356,  0.3076,  0.1990]],\n",
      "\n",
      "        [[-0.0394, -0.0220,  0.0589,  ...,  0.0306, -0.0197,  0.0234],\n",
      "         [-0.2116, -0.0190,  0.4442,  ..., -0.0218, -0.2274,  0.2800],\n",
      "         [ 0.0943, -0.2582, -0.1539,  ..., -0.3160, -0.1039,  0.4378],\n",
      "         ...,\n",
      "         [ 0.4217,  0.6069,  0.1285,  ...,  0.5450,  0.6920, -0.1225],\n",
      "         [ 0.2313,  0.4861,  0.1797,  ...,  0.6905,  0.6349, -0.2641],\n",
      "         [ 0.3973,  0.3121, -0.0305,  ...,  0.8892,  0.4543,  0.0608]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0448, -0.0244,  0.0591,  ...,  0.0171, -0.0234,  0.0230],\n",
      "         [-0.1404, -0.2013, -0.2048,  ..., -0.0608, -0.6990,  0.4221],\n",
      "         [-0.0722,  0.2626,  0.3828,  ...,  0.1968, -0.4737, -0.0699],\n",
      "         ...,\n",
      "         [ 0.5609,  0.6707,  0.0432,  ...,  0.2348,  0.4989, -0.1419],\n",
      "         [ 0.6827,  0.6212, -0.0129,  ...,  0.5024,  0.4943, -0.0023],\n",
      "         [ 0.6077,  0.4040, -0.1268,  ...,  0.9569,  0.4869,  0.1080]],\n",
      "\n",
      "        [[-0.0508, -0.0319,  0.0616,  ...,  0.0147, -0.0195,  0.0258],\n",
      "         [ 0.3798, -0.0942,  0.4610,  ..., -0.2426, -1.4140,  0.0253],\n",
      "         [ 0.0781,  0.0304,  0.8763,  ..., -0.2942, -0.5417, -0.0204],\n",
      "         ...,\n",
      "         [ 0.0235,  0.6199,  0.0613,  ...,  0.4996,  0.4252, -0.2095],\n",
      "         [ 0.3225,  0.7316,  0.1050,  ...,  0.5294,  0.4618, -0.1321],\n",
      "         [ 0.4533,  0.5078, -0.0660,  ...,  0.7246,  0.4470,  0.1773]],\n",
      "\n",
      "        [[-0.0380, -0.0277,  0.0477,  ...,  0.0307, -0.0311,  0.0252],\n",
      "         [-0.2626, -0.0072,  0.3920,  ...,  0.0146, -0.2919,  0.2513],\n",
      "         [ 0.0121, -0.2076, -0.1700,  ..., -0.2785, -0.2068,  0.4073],\n",
      "         ...,\n",
      "         [ 0.2672,  0.6178,  0.0194,  ...,  0.4930,  0.4406, -0.3270],\n",
      "         [ 0.4081,  0.5103,  0.0115,  ...,  0.5920,  0.4611, -0.0944],\n",
      "         [ 0.4807,  0.3562, -0.2364,  ...,  0.8899,  0.5226,  0.0183]]]), tensor([[[-6.4757e-02,  1.6932e-02,  4.2125e-02,  ..., -3.5204e-02,\n",
      "          -5.7501e-02,  1.6184e-03],\n",
      "         [ 6.4994e-01,  3.2646e-01,  6.9558e-01,  ..., -2.5238e-01,\n",
      "           1.0629e-01, -7.2508e-02],\n",
      "         [-5.3574e-01,  1.7599e-01,  3.1645e-01,  ...,  2.0455e-01,\n",
      "          -3.9969e-01,  1.9260e-01],\n",
      "         ...,\n",
      "         [ 2.5912e-01,  6.2764e-01,  3.5912e-01,  ...,  4.3083e-01,\n",
      "           5.2110e-01,  3.3572e-02],\n",
      "         [ 5.1051e-01,  5.8637e-01,  2.1003e-01,  ...,  3.9606e-01,\n",
      "           5.3523e-01, -2.2860e-01],\n",
      "         [ 7.1605e-01,  5.2565e-01,  4.4949e-02,  ...,  3.6420e-01,\n",
      "           5.8301e-01, -9.7918e-02]],\n",
      "\n",
      "        [[-6.8867e-02,  5.8268e-03,  3.5196e-02,  ..., -3.5035e-02,\n",
      "          -4.6463e-02,  4.3332e-03],\n",
      "         [-1.8387e-01,  3.5433e-01,  5.3034e-01,  ..., -2.2535e-01,\n",
      "           1.0463e-01,  7.6001e-01],\n",
      "         [ 1.9209e-01, -1.6167e-02,  3.4456e-02,  ..., -4.8460e-01,\n",
      "           3.0465e-03,  1.4616e-01],\n",
      "         ...,\n",
      "         [ 1.1178e-01,  6.1175e-01,  1.2524e-01,  ...,  3.1198e-01,\n",
      "           7.0479e-01, -1.7726e-01],\n",
      "         [ 1.4991e-01,  5.5946e-01, -1.2702e-03,  ...,  3.4357e-01,\n",
      "           6.3374e-01, -1.2544e-01],\n",
      "         [ 3.8728e-01,  4.4566e-01, -1.2188e-01,  ...,  4.8019e-01,\n",
      "           5.4192e-01,  2.1348e-02]],\n",
      "\n",
      "        [[-6.6660e-02,  6.0126e-03,  3.0769e-02,  ..., -3.6451e-02,\n",
      "          -5.7120e-02, -1.1675e-02],\n",
      "         [-1.8961e-01,  5.0680e-01,  5.2225e-01,  ..., -1.9731e-01,\n",
      "           1.7554e-01,  4.9792e-01],\n",
      "         [ 1.5670e-01,  1.8640e-01, -9.0787e-02,  ..., -3.4332e-01,\n",
      "           1.0926e-01, -1.9343e-02],\n",
      "         ...,\n",
      "         [ 4.7828e-01,  3.7853e-01,  2.2328e-01,  ...,  3.8925e-01,\n",
      "           8.9984e-01, -7.4487e-02],\n",
      "         [ 2.5713e-01,  4.7109e-01,  1.2015e-01,  ...,  3.9711e-01,\n",
      "           8.2711e-01, -3.3618e-01],\n",
      "         [ 3.9528e-01,  4.6550e-01,  2.3234e-02,  ...,  5.2649e-01,\n",
      "           6.4562e-01, -1.8480e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.7754e-02,  3.7337e-03,  3.7695e-02,  ..., -3.9883e-02,\n",
      "          -5.6197e-02, -3.9193e-04],\n",
      "         [-4.9584e-02, -2.5599e-02, -1.8905e-01,  ..., -6.6787e-01,\n",
      "          -4.1521e-01,  3.8788e-01],\n",
      "         [-4.1659e-02,  4.3633e-01,  2.2320e-01,  ..., -1.4086e-01,\n",
      "          -5.5516e-02,  4.2993e-01],\n",
      "         ...,\n",
      "         [ 6.3346e-01,  5.2026e-01,  1.5158e-01,  ...,  1.0569e-01,\n",
      "           6.9745e-01, -1.7528e-02],\n",
      "         [ 6.5230e-01,  4.8653e-01,  4.5214e-02,  ...,  2.3521e-01,\n",
      "           7.1452e-01, -6.2120e-02],\n",
      "         [ 6.2302e-01,  4.3356e-01, -4.6675e-02,  ...,  4.9783e-01,\n",
      "           7.2809e-01, -1.0573e-01]],\n",
      "\n",
      "        [[-7.0983e-02, -1.5755e-03,  3.7367e-02,  ..., -3.9611e-02,\n",
      "          -5.0261e-02,  7.3727e-04],\n",
      "         [ 7.1336e-01, -4.1292e-01,  5.8211e-01,  ..., -3.7375e-01,\n",
      "          -1.3173e+00,  1.4375e-01],\n",
      "         [ 2.2795e-01, -1.6817e-01,  7.6466e-01,  ..., -4.6995e-01,\n",
      "          -6.3236e-01, -3.9364e-02],\n",
      "         ...,\n",
      "         [ 5.7409e-02,  6.9146e-01,  9.3915e-02,  ...,  3.0279e-01,\n",
      "           5.5793e-01, -2.2363e-01],\n",
      "         [ 2.9488e-01,  6.0909e-01,  8.3792e-02,  ...,  2.2600e-01,\n",
      "           5.7996e-01, -1.9363e-01],\n",
      "         [ 3.9043e-01,  5.8577e-01, -4.2802e-02,  ...,  4.0086e-01,\n",
      "           6.2407e-01,  1.7413e-01]],\n",
      "\n",
      "        [[-7.1897e-02,  7.3490e-03,  3.4894e-02,  ..., -3.3239e-02,\n",
      "          -5.9445e-02, -1.1313e-03],\n",
      "         [-1.8851e-01,  5.2309e-01,  5.3136e-01,  ..., -1.3735e-01,\n",
      "           7.9628e-02,  5.0421e-01],\n",
      "         [ 1.6447e-01,  2.1480e-01, -1.4729e-01,  ..., -2.4888e-01,\n",
      "          -9.4062e-03,  1.0283e-01],\n",
      "         ...,\n",
      "         [ 3.1177e-01,  6.0733e-01,  9.9036e-02,  ...,  3.1378e-01,\n",
      "           6.2337e-01, -2.9583e-01],\n",
      "         [ 4.4518e-01,  5.4830e-01,  2.1917e-02,  ...,  3.2644e-01,\n",
      "           6.6399e-01, -2.0802e-01],\n",
      "         [ 5.3976e-01,  5.5759e-01, -1.1443e-01,  ...,  5.8942e-01,\n",
      "           7.6282e-01, -8.8040e-02]]]), tensor([[[-6.7762e-02,  2.1535e-02,  1.1509e-02,  ..., -1.3316e-02,\n",
      "          -3.4752e-03,  2.6314e-03],\n",
      "         [ 3.4890e-01,  3.4580e-01,  7.1168e-01,  ..., -1.8084e-01,\n",
      "           8.9363e-02,  3.7140e-02],\n",
      "         [-7.0258e-01,  2.1492e-01,  1.3655e-01,  ...,  8.5677e-02,\n",
      "          -2.4750e-01,  3.0022e-01],\n",
      "         ...,\n",
      "         [ 4.6127e-02,  1.0414e-01,  4.0652e-01,  ...,  5.5384e-01,\n",
      "           3.8481e-01,  4.1166e-01],\n",
      "         [ 3.2136e-01,  5.7137e-02,  2.3912e-01,  ...,  5.9456e-01,\n",
      "           4.4054e-01,  2.7914e-01],\n",
      "         [ 4.4855e-01, -7.8525e-02,  8.2705e-02,  ...,  4.8906e-01,\n",
      "           6.7876e-01,  3.6877e-01]],\n",
      "\n",
      "        [[-6.4347e-02,  2.2295e-02,  7.4145e-03,  ..., -1.7145e-02,\n",
      "          -7.0984e-03, -2.9341e-03],\n",
      "         [-4.3782e-01,  5.8388e-01,  4.3689e-01,  ..., -5.3354e-01,\n",
      "           6.9087e-02,  7.6799e-01],\n",
      "         [ 4.9958e-02,  7.9982e-02,  3.9284e-02,  ..., -3.2611e-01,\n",
      "          -2.8940e-02,  2.5691e-01],\n",
      "         ...,\n",
      "         [-1.3109e-01, -1.1415e-01,  1.0308e-01,  ...,  3.0486e-01,\n",
      "           5.5128e-01, -3.3058e-02],\n",
      "         [-1.3811e-01, -1.2319e-01,  2.3539e-02,  ...,  3.5818e-01,\n",
      "           5.6850e-01,  1.3417e-02],\n",
      "         [ 1.0664e-01, -1.4062e-01, -8.7150e-02,  ...,  3.8026e-01,\n",
      "           4.6162e-01,  2.2840e-01]],\n",
      "\n",
      "        [[-6.3751e-02,  1.9900e-02,  8.6203e-03,  ..., -1.7902e-02,\n",
      "          -9.5616e-03, -5.4160e-03],\n",
      "         [-5.4999e-01,  5.5480e-01,  4.7921e-01,  ..., -4.2798e-01,\n",
      "           1.1817e-01,  6.2708e-01],\n",
      "         [-5.0308e-02,  1.2114e-01, -1.3238e-01,  ..., -2.4838e-01,\n",
      "           6.4916e-02,  5.3500e-02],\n",
      "         ...,\n",
      "         [-2.1929e-02, -8.9271e-02,  1.4513e-01,  ...,  3.2750e-01,\n",
      "           8.4491e-01,  1.4429e-01],\n",
      "         [-7.7281e-02, -4.3167e-02,  1.0100e-01,  ...,  4.1917e-01,\n",
      "           7.1176e-01, -2.7125e-02],\n",
      "         [ 6.0865e-02, -1.3133e-01, -2.4171e-02,  ...,  4.3011e-01,\n",
      "           5.5829e-01,  9.4404e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.4398e-02,  2.1962e-02,  1.2121e-02,  ..., -2.4285e-02,\n",
      "          -1.1820e-02, -3.1300e-04],\n",
      "         [ 2.2389e-01,  3.1726e-01, -1.9090e-01,  ..., -6.2305e-01,\n",
      "          -2.3787e-01,  4.8003e-01],\n",
      "         [-2.6968e-01,  4.5795e-01,  7.2720e-02,  ..., -5.8481e-01,\n",
      "          -1.1069e-03,  7.9025e-01],\n",
      "         ...,\n",
      "         [ 2.7468e-01, -1.3541e-01,  3.1550e-02,  ...,  1.8055e-01,\n",
      "           5.6775e-01,  2.5553e-01],\n",
      "         [ 3.6126e-01, -1.7081e-01,  3.7765e-02,  ...,  4.4565e-01,\n",
      "           5.6438e-01,  2.4253e-01],\n",
      "         [ 2.5629e-01, -1.4452e-01, -6.0752e-02,  ...,  5.5359e-01,\n",
      "           6.5005e-01,  2.7691e-01]],\n",
      "\n",
      "        [[-6.4901e-02,  1.7708e-02,  1.2676e-02,  ..., -1.6744e-02,\n",
      "          -8.4684e-03,  9.2728e-04],\n",
      "         [ 6.5458e-01, -1.1447e-01,  6.0665e-01,  ..., -4.2406e-01,\n",
      "          -1.2018e+00,  1.6541e-02],\n",
      "         [ 2.4413e-01,  1.1291e-01,  7.0890e-01,  ..., -5.6545e-01,\n",
      "          -6.4273e-01,  3.2325e-01],\n",
      "         ...,\n",
      "         [ 1.9552e-02,  4.5756e-02,  1.0315e-01,  ...,  2.9089e-01,\n",
      "           4.8987e-01,  7.5350e-02],\n",
      "         [ 2.4254e-01,  3.1297e-02,  1.3095e-01,  ...,  2.8166e-01,\n",
      "           5.1328e-01,  2.3650e-01],\n",
      "         [ 2.8429e-01, -3.4589e-02, -7.2526e-03,  ...,  3.3812e-01,\n",
      "           5.4291e-01,  3.6858e-01]],\n",
      "\n",
      "        [[-6.7494e-02,  2.1233e-02,  8.0257e-03,  ..., -1.4578e-02,\n",
      "          -8.4492e-03, -1.3635e-03],\n",
      "         [-5.2328e-01,  5.2934e-01,  4.6697e-01,  ..., -5.0560e-01,\n",
      "           4.3305e-02,  6.6827e-01],\n",
      "         [-7.8007e-03,  8.2623e-02, -1.2084e-01,  ..., -2.5176e-01,\n",
      "          -5.2172e-02,  2.2386e-01],\n",
      "         ...,\n",
      "         [-1.1116e-03, -9.7011e-03,  1.0309e-01,  ...,  3.5477e-01,\n",
      "           4.7219e-01,  1.7808e-01],\n",
      "         [ 1.0669e-01, -2.5090e-02,  8.4646e-02,  ...,  4.1455e-01,\n",
      "           5.2232e-01,  2.9832e-01],\n",
      "         [ 1.8233e-01, -4.2049e-02, -1.0772e-01,  ...,  4.8591e-01,\n",
      "           7.1178e-01,  4.2340e-01]]]), tensor([[[-8.9894e-02,  2.4130e-02, -9.7733e-03,  ...,  4.3442e-02,\n",
      "           5.4153e-03, -2.4452e-03],\n",
      "         [ 3.2932e-01,  6.5269e-01,  7.2098e-01,  ..., -6.7198e-01,\n",
      "           6.8206e-02,  3.3626e-01],\n",
      "         [-6.3092e-01,  8.5176e-02, -1.0686e-01,  ...,  1.6405e-02,\n",
      "          -3.6218e-01,  5.2530e-01],\n",
      "         ...,\n",
      "         [ 3.0327e-01,  1.9791e-01,  3.5728e-01,  ...,  6.3689e-01,\n",
      "           3.8196e-01,  1.0833e-01],\n",
      "         [ 4.8354e-01,  1.0243e-01,  2.3483e-01,  ...,  6.8327e-01,\n",
      "           4.5076e-01,  8.5449e-03],\n",
      "         [ 7.0096e-01, -2.7358e-02,  8.3463e-02,  ...,  6.5101e-01,\n",
      "           9.0437e-01,  3.3499e-02]],\n",
      "\n",
      "        [[-8.6145e-02,  2.6585e-02, -1.1025e-02,  ...,  4.7920e-02,\n",
      "           5.6691e-03, -9.2601e-03],\n",
      "         [-5.2989e-01,  2.9724e-01,  5.6765e-01,  ..., -4.5215e-01,\n",
      "          -1.2630e-01,  9.3778e-01],\n",
      "         [ 2.1153e-01, -1.1656e-01,  1.5617e-01,  ..., -1.1178e-01,\n",
      "           7.4464e-02,  3.3600e-01],\n",
      "         ...,\n",
      "         [ 1.4001e-01, -8.6279e-02,  7.2488e-02,  ...,  4.0392e-01,\n",
      "           6.9834e-01,  7.5097e-02],\n",
      "         [ 9.0416e-02, -1.2434e-01, -3.0168e-02,  ...,  4.2771e-01,\n",
      "           7.2287e-01,  3.1211e-02],\n",
      "         [ 3.5084e-01, -1.3124e-01, -7.6121e-02,  ...,  4.8472e-01,\n",
      "           6.5891e-01,  1.0078e-01]],\n",
      "\n",
      "        [[-8.5287e-02,  2.5960e-02, -1.1796e-02,  ...,  4.8586e-02,\n",
      "           4.2052e-03, -6.7226e-03],\n",
      "         [-5.7192e-01,  1.8734e-01,  5.7212e-01,  ..., -3.5485e-01,\n",
      "          -9.0544e-02,  9.9003e-01],\n",
      "         [ 6.5284e-03, -1.9455e-01, -5.5951e-05,  ..., -3.1301e-02,\n",
      "           7.1126e-02,  2.1035e-01],\n",
      "         ...,\n",
      "         [ 2.6687e-01,  1.9971e-01,  1.5032e-01,  ...,  3.4052e-01,\n",
      "           9.7918e-01,  1.8283e-01],\n",
      "         [ 9.0380e-02,  2.7523e-01,  8.3936e-02,  ...,  3.6612e-01,\n",
      "           7.4678e-01,  1.2804e-01],\n",
      "         [ 2.6625e-01,  5.2983e-02, -5.9489e-02,  ...,  5.1103e-01,\n",
      "           7.1712e-01,  1.8050e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.7260e-02,  2.6155e-02, -8.9711e-03,  ...,  4.8623e-02,\n",
      "           3.3155e-03, -5.9527e-03],\n",
      "         [ 2.2478e-01,  2.3157e-01,  2.3098e-02,  ..., -6.0219e-01,\n",
      "          -4.4919e-01,  5.8279e-01],\n",
      "         [-2.1550e-01,  1.1795e-01,  2.6593e-01,  ..., -3.3203e-01,\n",
      "           8.5901e-03,  9.9440e-01],\n",
      "         ...,\n",
      "         [ 5.5272e-01, -3.9098e-02,  4.5393e-02,  ...,  3.8152e-01,\n",
      "           7.6107e-01,  2.2320e-01],\n",
      "         [ 4.0313e-01,  5.2747e-02,  3.3073e-02,  ...,  4.8121e-01,\n",
      "           7.2223e-01,  3.6942e-01],\n",
      "         [ 4.2764e-01, -7.5547e-02, -5.5121e-02,  ...,  5.6922e-01,\n",
      "           9.0302e-01,  2.8740e-01]],\n",
      "\n",
      "        [[-8.6879e-02,  2.4273e-02, -1.2161e-02,  ...,  4.7948e-02,\n",
      "           5.6326e-03, -5.3834e-03],\n",
      "         [ 7.1913e-01, -6.3200e-02,  6.2273e-01,  ..., -1.3200e-01,\n",
      "          -1.2725e+00, -2.1170e-01],\n",
      "         [ 4.9371e-01,  1.2863e-01,  7.7800e-01,  ..., -6.0585e-01,\n",
      "          -7.2602e-01,  6.8535e-03],\n",
      "         ...,\n",
      "         [ 2.1445e-01,  9.6704e-02,  1.0750e-01,  ...,  3.7131e-01,\n",
      "           4.3422e-01,  6.7841e-02],\n",
      "         [ 3.5855e-01,  1.5887e-02,  1.0478e-01,  ...,  4.6464e-01,\n",
      "           4.9815e-01,  2.0652e-01],\n",
      "         [ 4.2863e-01,  1.1571e-01, -5.8147e-02,  ...,  3.9486e-01,\n",
      "           5.1864e-01,  1.9344e-01]],\n",
      "\n",
      "        [[-8.9270e-02,  2.4731e-02, -9.1787e-03,  ...,  4.7619e-02,\n",
      "           4.2347e-03, -4.6446e-03],\n",
      "         [-6.7482e-01,  1.0355e-01,  5.6104e-01,  ..., -3.4112e-01,\n",
      "          -1.2588e-01,  9.9922e-01],\n",
      "         [ 4.3454e-02, -1.9272e-01, -1.5001e-02,  ..., -2.0162e-02,\n",
      "          -4.6242e-03,  3.0944e-01],\n",
      "         ...,\n",
      "         [ 1.7515e-01,  1.6798e-01,  1.2419e-01,  ...,  3.9348e-01,\n",
      "           5.1333e-01,  2.5816e-01],\n",
      "         [ 2.3091e-01,  8.8281e-02,  1.2792e-01,  ...,  4.6649e-01,\n",
      "           5.9567e-01,  3.4025e-01],\n",
      "         [ 3.5094e-01,  1.8444e-02, -6.3916e-02,  ...,  6.2467e-01,\n",
      "           8.7366e-01,  2.5691e-01]]]), tensor([[[-7.1027e-02,  2.2329e-02, -4.8118e-03,  ...,  2.6506e-02,\n",
      "          -6.7290e-04, -1.6733e-02],\n",
      "         [ 2.8609e-01,  7.4744e-01,  8.1237e-01,  ..., -8.7273e-01,\n",
      "          -2.7908e-03,  2.1180e-01],\n",
      "         [-6.2245e-01, -1.6036e-02, -1.0031e-01,  ..., -2.5933e-01,\n",
      "          -4.0697e-01,  3.0922e-01],\n",
      "         ...,\n",
      "         [ 3.3464e-01,  5.5758e-01,  1.0029e-01,  ...,  3.0391e-01,\n",
      "           3.0736e-01,  7.4740e-02],\n",
      "         [ 3.9938e-01,  4.9534e-01,  4.1412e-02,  ...,  2.8510e-01,\n",
      "           4.6714e-01,  6.9816e-02],\n",
      "         [ 6.5163e-01, -1.3462e-01,  5.7760e-04,  ...,  4.9242e-01,\n",
      "           1.1389e+00,  3.0972e-02]],\n",
      "\n",
      "        [[-6.5100e-02,  1.9263e-02, -1.1490e-02,  ...,  1.8981e-02,\n",
      "           7.1163e-03, -1.5635e-02],\n",
      "         [-2.9832e-01,  6.9495e-01,  6.1013e-01,  ..., -5.2831e-01,\n",
      "           7.3802e-02,  9.2303e-01],\n",
      "         [ 8.9107e-02, -1.5784e-02,  2.5613e-01,  ..., -6.4959e-02,\n",
      "           7.7967e-02,  3.3720e-01],\n",
      "         ...,\n",
      "         [ 2.3715e-01,  2.1568e-01, -9.0460e-02,  ...,  1.8571e-01,\n",
      "           6.5554e-01, -1.0907e-02],\n",
      "         [ 1.6791e-01,  1.3413e-01, -1.4834e-01,  ...,  1.2181e-01,\n",
      "           7.2151e-01, -2.6158e-02],\n",
      "         [ 3.9431e-01,  1.3768e-01, -2.2390e-01,  ...,  1.5375e-01,\n",
      "           6.3683e-01, -2.6594e-02]],\n",
      "\n",
      "        [[-6.5630e-02,  1.5990e-02, -9.1496e-03,  ...,  1.8288e-02,\n",
      "          -1.4216e-03, -1.3160e-02],\n",
      "         [-3.9336e-01,  7.2555e-01,  6.6344e-01,  ..., -5.7686e-01,\n",
      "           7.8141e-02,  7.9758e-01],\n",
      "         [-7.7100e-02, -7.3992e-02,  1.2633e-01,  ..., -1.5935e-01,\n",
      "           3.2864e-03,  2.2532e-01],\n",
      "         ...,\n",
      "         [ 3.5320e-01,  4.3482e-01, -8.6068e-02,  ...,  2.5015e-01,\n",
      "           7.7734e-01,  1.5512e-01],\n",
      "         [ 1.9338e-01,  3.9210e-01, -4.7218e-02,  ...,  4.3707e-02,\n",
      "           3.5181e-01,  1.1879e-01],\n",
      "         [ 3.4120e-01,  3.9793e-01, -2.9565e-01,  ...,  1.6152e-01,\n",
      "           6.2582e-01,  1.1388e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.3848e-02,  1.8759e-02, -9.4355e-03,  ...,  1.9143e-02,\n",
      "           2.3963e-03, -1.6081e-02],\n",
      "         [ 2.4196e-01,  4.1297e-01, -8.5780e-03,  ..., -9.7489e-01,\n",
      "          -4.8179e-01,  5.4680e-01],\n",
      "         [ 8.2891e-02,  6.0439e-01,  3.5918e-01,  ..., -3.1507e-01,\n",
      "          -9.0018e-02,  7.8324e-01],\n",
      "         ...,\n",
      "         [ 5.8716e-01,  4.2189e-03, -1.0110e-01,  ...,  3.0235e-01,\n",
      "           8.9419e-01,  1.7640e-01],\n",
      "         [ 4.8843e-01,  3.6458e-01, -1.7250e-01,  ...,  1.6292e-01,\n",
      "           7.8992e-01,  2.0711e-01],\n",
      "         [ 4.7381e-01,  7.4246e-02, -2.3059e-01,  ...,  3.5398e-01,\n",
      "           1.0887e+00,  1.6744e-01]],\n",
      "\n",
      "        [[-6.6861e-02,  1.3373e-02, -9.6694e-03,  ...,  2.1488e-02,\n",
      "           3.2609e-03, -1.7738e-02],\n",
      "         [ 6.9972e-01, -2.3056e-01,  6.7687e-01,  ..., -6.4706e-01,\n",
      "          -1.0163e+00, -3.0358e-02],\n",
      "         [ 4.8609e-01,  3.5072e-02,  8.0805e-01,  ..., -7.2462e-01,\n",
      "          -6.1617e-01, -6.4266e-02],\n",
      "         ...,\n",
      "         [ 3.3296e-01,  3.6070e-01, -4.1608e-02,  ...,  7.5015e-02,\n",
      "           2.6676e-01,  1.2214e-01],\n",
      "         [ 4.0030e-01,  3.4926e-01,  1.4531e-03,  ...,  9.9832e-02,\n",
      "           3.3326e-01,  1.3704e-01],\n",
      "         [ 4.6751e-01,  3.1251e-01, -9.2945e-02,  ...,  3.6732e-02,\n",
      "           2.7017e-01,  1.6928e-01]],\n",
      "\n",
      "        [[-6.9303e-02,  2.0258e-02, -1.0413e-02,  ...,  1.9553e-02,\n",
      "          -5.2946e-03, -1.3738e-02],\n",
      "         [-4.7011e-01,  7.5468e-01,  6.1061e-01,  ..., -5.7204e-01,\n",
      "           1.0439e-02,  8.8292e-01],\n",
      "         [ 2.3758e-02, -6.8100e-02,  8.5078e-02,  ..., -2.3977e-01,\n",
      "          -1.0535e-01,  3.4165e-01],\n",
      "         ...,\n",
      "         [ 2.1123e-01,  4.8706e-01, -7.7832e-02,  ...,  1.2230e-01,\n",
      "           4.2913e-01,  2.7743e-01],\n",
      "         [ 2.5369e-01,  4.3226e-01, -4.4474e-02,  ...,  1.6319e-01,\n",
      "           5.0654e-01,  2.5739e-01],\n",
      "         [ 2.9424e-01,  3.1162e-01, -2.3282e-01,  ...,  3.8706e-01,\n",
      "           8.6862e-01,  7.6707e-02]]]), tensor([[[-3.5745e-02,  8.8268e-03, -1.2027e-03,  ...,  1.1396e-02,\n",
      "          -1.4661e-03, -1.1811e-02],\n",
      "         [ 1.4367e-01,  3.8184e-01,  3.8923e-01,  ..., -4.7614e-01,\n",
      "          -1.0176e-01,  1.9167e-02],\n",
      "         [-3.0674e-01, -4.9893e-03,  8.6143e-02,  ..., -2.4232e-01,\n",
      "          -1.8271e-01, -5.9778e-02],\n",
      "         ...,\n",
      "         [ 9.5454e-02,  1.7104e-01,  1.2741e-02,  ...,  3.9884e-02,\n",
      "           9.2760e-02, -3.5920e-02],\n",
      "         [ 1.0944e-01,  1.9966e-01,  5.6768e-03,  ...,  3.2334e-02,\n",
      "           1.5919e-01, -5.0886e-02],\n",
      "         [ 3.6118e-01, -3.5335e-02, -1.4816e-02,  ...,  2.3522e-01,\n",
      "           5.6379e-01, -1.4918e-02]],\n",
      "\n",
      "        [[-3.5863e-02,  9.0216e-03, -2.1364e-03,  ...,  1.1928e-02,\n",
      "           3.4421e-04, -1.5176e-02],\n",
      "         [-6.2374e-03,  3.2295e-01,  3.0040e-01,  ..., -1.9724e-01,\n",
      "          -9.2731e-02,  4.2038e-01],\n",
      "         [ 7.8879e-02,  1.2099e-01,  1.2001e-01,  ..., -1.4488e-01,\n",
      "           5.6239e-03,  2.2286e-01],\n",
      "         ...,\n",
      "         [ 9.0471e-02,  1.4833e-01, -4.4878e-02,  ...,  2.3048e-02,\n",
      "           1.7881e-01, -2.6949e-02],\n",
      "         [ 6.8973e-02,  1.3377e-01, -6.2255e-02,  ..., -3.7848e-03,\n",
      "           1.8692e-01, -6.3762e-02],\n",
      "         [ 1.4406e-01,  1.6237e-01, -9.7032e-02,  ..., -1.0900e-02,\n",
      "           1.7336e-01, -7.3576e-02]],\n",
      "\n",
      "        [[-3.8195e-02,  7.3286e-03, -2.0211e-03,  ...,  1.0376e-02,\n",
      "          -1.3337e-03, -1.4168e-02],\n",
      "         [-1.3370e-01,  2.8188e-01,  3.4861e-01,  ..., -2.6183e-01,\n",
      "          -2.1265e-02,  3.8104e-01],\n",
      "         [ 4.8100e-02,  3.7753e-02,  9.5221e-02,  ..., -2.4733e-01,\n",
      "           1.3990e-02,  1.9642e-01],\n",
      "         ...,\n",
      "         [ 1.6987e-01,  2.5670e-01, -6.7638e-02,  ...,  8.1464e-02,\n",
      "           2.4591e-01,  2.9468e-02],\n",
      "         [ 6.1052e-02,  1.6752e-01, -1.4917e-02,  ...,  2.0721e-02,\n",
      "           8.1627e-02, -4.8428e-02],\n",
      "         [ 1.0534e-01,  2.8852e-01, -9.3444e-02,  ..., -2.8984e-03,\n",
      "           2.1471e-01, -2.0690e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.6398e-02,  9.0313e-03, -1.9369e-03,  ...,  1.1063e-02,\n",
      "          -1.6230e-03, -1.3801e-02],\n",
      "         [ 7.2394e-02,  1.3025e-01,  1.2008e-02,  ..., -6.7950e-01,\n",
      "          -2.5421e-01,  3.4263e-01],\n",
      "         [ 3.6840e-02,  3.0900e-01,  1.6183e-01,  ..., -1.6243e-01,\n",
      "           3.3092e-02,  4.8373e-01],\n",
      "         ...,\n",
      "         [ 3.1848e-01,  6.6436e-02, -9.5219e-03,  ...,  1.3734e-01,\n",
      "           3.6635e-01,  1.9097e-01],\n",
      "         [ 1.5882e-01,  2.1736e-01, -2.2585e-02,  ...,  2.7520e-02,\n",
      "           2.6909e-01,  1.8777e-02],\n",
      "         [ 2.4030e-01,  1.4493e-01, -7.6411e-02,  ...,  1.3902e-01,\n",
      "           4.3259e-01,  4.6514e-02]],\n",
      "\n",
      "        [[-3.6898e-02,  8.0207e-03, -2.7144e-03,  ...,  1.1667e-02,\n",
      "          -1.2370e-03, -1.3637e-02],\n",
      "         [ 3.5688e-01, -1.4431e-01,  3.9117e-01,  ..., -4.5789e-01,\n",
      "          -5.4167e-01,  6.6350e-02],\n",
      "         [ 2.8837e-01,  1.3654e-01,  4.1197e-01,  ..., -6.8346e-01,\n",
      "          -4.0116e-01, -1.7989e-01],\n",
      "         ...,\n",
      "         [ 8.0119e-02,  9.0630e-02, -4.9434e-02,  ...,  4.7402e-02,\n",
      "           7.0586e-02, -8.8313e-02],\n",
      "         [ 7.9258e-02,  1.0533e-01, -4.2686e-02,  ...,  4.6321e-02,\n",
      "           8.8614e-02, -8.3294e-02],\n",
      "         [ 8.3239e-02,  1.1032e-01, -4.2938e-02,  ...,  1.9482e-02,\n",
      "           4.2302e-02, -5.6846e-02]],\n",
      "\n",
      "        [[-3.7537e-02,  8.0758e-03, -2.0962e-03,  ...,  1.0937e-02,\n",
      "          -2.3940e-03, -1.3104e-02],\n",
      "         [-1.8002e-01,  2.6632e-01,  3.0659e-01,  ..., -2.5578e-01,\n",
      "          -4.7298e-02,  4.0828e-01],\n",
      "         [ 1.2617e-01,  2.7602e-02,  9.4449e-02,  ..., -2.5698e-01,\n",
      "          -5.1935e-02,  2.2923e-01],\n",
      "         ...,\n",
      "         [ 4.5839e-02,  1.9339e-01, -3.0199e-02,  ...,  1.8919e-02,\n",
      "           1.6875e-01,  4.7387e-02],\n",
      "         [ 7.1682e-02,  2.1171e-01, -8.5704e-03,  ...,  1.2957e-02,\n",
      "           1.9582e-01,  5.3831e-02],\n",
      "         [ 1.6799e-01,  1.8937e-01, -8.2689e-02,  ...,  1.0582e-01,\n",
      "           3.3687e-01, -2.0829e-03]]])), encoder_attentions=None)\n",
      "seg_num: 1\n",
      "batch_size: 32\n",
      "non_empty_mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "batch_size: 32\n",
      "decoder_input_ids: None\n",
      "prefix_tokens: torch.Size([20])\n",
      "out: Seq2SeqLMOutput(loss=tensor(18.4472, grad_fn=<NllLossBackward0>), logits=tensor([[[ -9.1170,  -4.2681,   1.3676,  ...,  -3.9043,  -3.6876,   0.3226],\n",
      "         [-10.6418,  -4.5800,  -0.0532,  ...,  -4.0220,  -3.8128,   0.3482],\n",
      "         [-10.4752,  -4.5470,   0.0955,  ...,  -3.9396,  -3.7680,   0.4284],\n",
      "         ...,\n",
      "         [ -6.2270,  -3.9042,   6.5972,  ...,  -3.2747,  -3.1340,   1.0631],\n",
      "         [ -6.6896,  -4.0092,   6.3095,  ...,  -3.3929,  -3.2577,   1.1830],\n",
      "         [ -6.8789,  -4.0675,   6.3091,  ...,  -3.4745,  -3.3173,   1.1092]],\n",
      "\n",
      "        [[ -9.0630,  -4.9542,  -2.6572,  ...,  -4.4340,  -4.4218,  -1.0364],\n",
      "         [ -7.1059,  -4.7968,  -1.2762,  ...,  -4.5179,  -4.5580,  -0.5227],\n",
      "         [ -8.2153,  -4.7409,  -1.6354,  ...,  -4.4534,  -4.5319,  -0.7533],\n",
      "         ...,\n",
      "         [ -6.8318,  -4.0008,   6.8228,  ...,  -2.7463,  -2.9440,   0.0226],\n",
      "         [ -8.7293,  -4.1779,   5.7335,  ...,  -2.9300,  -2.8895,  -0.9244],\n",
      "         [ -9.5695,  -4.3186,   4.9979,  ...,  -3.1022,  -2.9631,  -1.9642]],\n",
      "\n",
      "        [[  0.2292,  -3.8215,   6.3042,  ...,  -3.8695,  -4.1174,   1.7115],\n",
      "         [ -0.2667,  -3.8106,   6.7689,  ...,  -3.7763,  -4.0611,   1.9062],\n",
      "         [ -0.5675,  -4.0141,   6.3435,  ...,  -3.6551,  -4.1492,   2.1025],\n",
      "         ...,\n",
      "         [ -4.5415,  -3.4700,  14.0642,  ...,  -2.1119,  -2.2649,  -2.2345],\n",
      "         [ -5.0720,  -3.4046,  13.8224,  ...,  -2.0021,  -2.2389,  -1.8125],\n",
      "         [ -5.6201,  -3.1017,  14.2408,  ...,  -1.4073,  -1.6987,  -1.2351]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -4.3916,  -5.0231,   0.3399,  ...,  -4.2077,  -4.3911,  -1.5282],\n",
      "         [ -1.9826,  -4.6400,   1.0801,  ...,  -4.0435,  -4.2184,  -1.1946],\n",
      "         [ -0.3084,  -4.4019,   1.0760,  ...,  -3.9874,  -4.2082,  -1.1277],\n",
      "         ...,\n",
      "         [ -8.7539,  -4.0207,   5.9456,  ...,  -2.7572,  -3.4091,  -0.9800],\n",
      "         [ -8.8507,  -4.0468,   5.8419,  ...,  -2.7755,  -3.3923,  -0.9892],\n",
      "         [ -8.4354,  -3.9884,   5.6110,  ...,  -2.7292,  -3.3314,  -1.2720]],\n",
      "\n",
      "        [[ -4.6709,  -3.8766,   1.0605,  ...,  -2.9136,  -3.0761,   1.7702],\n",
      "         [ -3.8774,  -3.5176,   1.6180,  ...,  -2.5598,  -2.6667,   1.9161],\n",
      "         [ -4.8566,  -3.4912,   1.1958,  ...,  -2.5725,  -2.7553,   1.9204],\n",
      "         ...,\n",
      "         [ -5.5097,  -3.8614,   5.9696,  ...,  -3.1377,  -2.7806,   1.6252],\n",
      "         [ -5.9075,  -3.9523,   5.8152,  ...,  -3.2449,  -2.8997,   1.6729],\n",
      "         [ -5.9754,  -3.9768,   5.8181,  ...,  -3.2732,  -2.9150,   1.5790]],\n",
      "\n",
      "        [[-10.5596,  -5.1994,  -0.8251,  ...,  -4.0301,  -4.0988,   1.5189],\n",
      "         [ -7.1363,  -4.1747,   0.4637,  ...,  -3.0603,  -2.7852,   1.7111],\n",
      "         [ -6.9847,  -4.0957,   0.6794,  ...,  -2.9736,  -2.7294,   2.0629],\n",
      "         ...,\n",
      "         [ -6.7602,  -4.2725,   6.1967,  ...,  -3.3410,  -3.1090,   1.9727],\n",
      "         [ -7.3588,  -4.3727,   5.9412,  ...,  -3.4389,  -3.2300,   2.0744],\n",
      "         [ -7.5448,  -4.3847,   5.9882,  ...,  -3.4694,  -3.2440,   2.0369]]],\n",
      "       grad_fn=<AddBackward0>), past_key_values=None, decoder_hidden_states=(tensor([[[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.0294,  0.2074,  0.0431,  ..., -0.2617,  0.1940,  0.1261],\n",
      "         [-0.0132,  0.2832, -0.0114,  ..., -0.3147,  0.3118,  0.0943],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [ 0.5675, -0.1371,  0.0697,  ...,  0.1330,  0.0706,  0.1900],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [ 0.5675, -0.1371,  0.0697,  ...,  0.1330,  0.0706,  0.1900],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [ 0.5675, -0.1371,  0.0697,  ...,  0.1330,  0.0706,  0.1900],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.0294,  0.2074,  0.0431,  ..., -0.2617,  0.1940,  0.1261],\n",
      "         [-0.0132,  0.2832, -0.0114,  ..., -0.3147,  0.3118,  0.0943],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.0294,  0.2074,  0.0431,  ..., -0.2617,  0.1940,  0.1261],\n",
      "         [-0.0132,  0.2832, -0.0114,  ..., -0.3147,  0.3118,  0.0943],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]]]), tensor([[[-5.9341e-02,  1.7933e-01, -3.1436e-01,  ..., -5.7335e-01,\n",
      "          -1.7437e-01,  1.6050e-02],\n",
      "         [ 1.7099e-02,  4.0469e-02, -6.6397e-02,  ..., -4.5473e-01,\n",
      "          -7.0535e-02, -2.3153e-01],\n",
      "         [ 3.0559e-02,  3.1687e-01, -1.2447e-01,  ..., -2.5800e-01,\n",
      "           2.8565e-01,  1.6071e-03],\n",
      "         ...,\n",
      "         [ 6.6739e-02,  1.2138e-01,  3.0506e-02,  ...,  2.9597e-01,\n",
      "          -5.1102e-02,  1.0040e-01],\n",
      "         [ 8.3934e-02,  1.5455e-01,  5.8902e-02,  ...,  4.3597e-01,\n",
      "          -3.0399e-01,  1.0591e-01],\n",
      "         [ 1.1892e-01, -4.1926e-02,  2.9683e-02,  ...,  5.6529e-01,\n",
      "          -6.4430e-01,  1.3956e-01]],\n",
      "\n",
      "        [[ 7.3411e-01,  4.4747e-02, -4.0624e-01,  ..., -4.7167e-01,\n",
      "           4.2800e-02, -7.2622e-03],\n",
      "         [ 7.5459e-01, -5.4443e-02, -3.8697e-01,  ..., -6.4346e-01,\n",
      "          -7.8098e-02,  9.5149e-02],\n",
      "         [ 7.5801e-01, -1.1636e-01, -3.9499e-01,  ..., -6.5637e-01,\n",
      "          -2.8212e-02,  9.6915e-02],\n",
      "         ...,\n",
      "         [ 1.1603e-02, -1.7864e-01,  2.0003e-01,  ...,  3.3509e-01,\n",
      "          -3.2454e-01, -2.6745e-01],\n",
      "         [-2.9917e-02, -1.5355e-01,  2.0618e-01,  ...,  5.5704e-01,\n",
      "          -4.9131e-01, -3.7470e-01],\n",
      "         [ 5.9014e-02, -2.8137e-01,  1.2526e-01,  ...,  6.6633e-01,\n",
      "          -7.8631e-01, -2.6558e-01]],\n",
      "\n",
      "        [[ 9.1737e-01,  2.7259e-01, -4.0140e-01,  ..., -9.9282e-02,\n",
      "           1.2885e-01,  5.6903e-02],\n",
      "         [ 8.6339e-01,  1.3140e-01, -3.0614e-01,  ..., -3.5112e-01,\n",
      "          -6.9984e-02, -9.6703e-04],\n",
      "         [ 9.0276e-01,  9.9913e-02, -2.8072e-01,  ..., -5.5362e-01,\n",
      "          -4.0285e-02, -1.0987e-01],\n",
      "         ...,\n",
      "         [ 1.6010e-01, -2.0024e-01,  2.1158e-01,  ...,  3.0820e-01,\n",
      "          -2.6775e-01, -1.7260e-01],\n",
      "         [ 1.0350e-01, -2.5766e-01,  2.2029e-01,  ...,  4.6706e-01,\n",
      "          -4.1622e-01, -2.3098e-01],\n",
      "         [ 1.8405e-01, -3.3165e-01,  1.4524e-01,  ...,  6.0634e-01,\n",
      "          -7.7274e-01, -1.5471e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.9280e-01,  4.0372e-01, -2.7556e-01,  ..., -6.6077e-02,\n",
      "           7.8886e-02,  8.2480e-02],\n",
      "         [ 9.4820e-01,  2.6128e-01, -2.6982e-01,  ..., -1.5508e-01,\n",
      "          -6.0954e-03,  1.1437e-01],\n",
      "         [ 1.0037e+00,  1.5248e-01, -3.1245e-01,  ..., -2.1587e-01,\n",
      "           3.1871e-02,  1.3194e-01],\n",
      "         ...,\n",
      "         [ 8.9316e-02, -4.2313e-02,  2.5620e-01,  ...,  3.2895e-01,\n",
      "          -3.4714e-01, -1.6002e-01],\n",
      "         [ 1.4369e-02, -8.9333e-02,  2.3561e-01,  ...,  5.0496e-01,\n",
      "          -4.9730e-01, -2.3634e-01],\n",
      "         [ 9.7529e-02, -1.7866e-01,  1.7273e-01,  ...,  6.0424e-01,\n",
      "          -8.1188e-01, -1.5232e-01]],\n",
      "\n",
      "        [[ 2.1752e-02,  1.4150e-01, -3.5797e-01,  ..., -4.0877e-01,\n",
      "          -1.3301e-01,  2.0804e-01],\n",
      "         [-4.7480e-02,  7.7150e-02, -1.3131e-01,  ..., -3.6127e-01,\n",
      "          -1.1061e-02, -2.0395e-01],\n",
      "         [-2.8388e-03,  2.9160e-01, -9.4810e-02,  ..., -2.4940e-01,\n",
      "           3.0945e-01,  8.6623e-03],\n",
      "         ...,\n",
      "         [ 7.8076e-02,  1.3137e-01,  3.0284e-02,  ...,  2.8927e-01,\n",
      "          -4.7583e-02,  1.0653e-01],\n",
      "         [ 9.4399e-02,  1.6164e-01,  5.9736e-02,  ...,  4.2887e-01,\n",
      "          -3.0214e-01,  1.1016e-01],\n",
      "         [ 1.3177e-01, -3.2491e-02,  3.0852e-02,  ...,  5.5725e-01,\n",
      "          -6.4140e-01,  1.4370e-01]],\n",
      "\n",
      "        [[ 1.5447e-01,  4.4114e-01, -3.2362e-01,  ..., -5.7134e-01,\n",
      "           1.7492e-01,  9.9719e-03],\n",
      "         [ 2.8938e-02,  5.2378e-02, -2.8653e-02,  ..., -3.4767e-01,\n",
      "           5.7727e-03, -2.7527e-01],\n",
      "         [ 7.2466e-02,  2.6433e-01, -3.7194e-02,  ..., -1.5871e-01,\n",
      "           3.3824e-01, -3.1203e-02],\n",
      "         ...,\n",
      "         [ 7.4132e-02,  1.3137e-01,  3.0729e-02,  ...,  2.8758e-01,\n",
      "          -5.3755e-02,  1.0284e-01],\n",
      "         [ 9.0948e-02,  1.6287e-01,  5.9277e-02,  ...,  4.2729e-01,\n",
      "          -3.0444e-01,  1.0713e-01],\n",
      "         [ 1.2722e-01, -3.0775e-02,  3.0611e-02,  ...,  5.5360e-01,\n",
      "          -6.4406e-01,  1.3920e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0098,  0.5018, -0.1864,  ..., -0.3346, -0.2722,  0.2620],\n",
      "         [-0.1386,  0.1641,  0.0842,  ..., -0.4479, -0.0730,  0.3717],\n",
      "         [ 0.1153,  0.1704, -0.0230,  ..., -0.3121,  0.0115,  0.4577],\n",
      "         ...,\n",
      "         [ 0.3320,  0.1167, -0.0340,  ...,  0.1881, -0.2106,  0.4172],\n",
      "         [ 0.3136,  0.2119, -0.0080,  ...,  0.1484, -0.2288,  0.3968],\n",
      "         [ 0.2513,  0.1157, -0.1541,  ...,  0.0944, -0.3244,  0.3193]],\n",
      "\n",
      "        [[ 0.3921, -0.1033, -0.1886,  ..., -0.2207, -0.2583,  0.1127],\n",
      "         [ 0.3751, -0.0027, -0.1691,  ..., -0.4241, -0.4615,  0.2948],\n",
      "         [ 0.3739,  0.0178, -0.2603,  ..., -0.4109, -0.4503,  0.3435],\n",
      "         ...,\n",
      "         [-0.1954,  0.0165,  0.0717,  ...,  0.5393, -0.0168, -0.1438],\n",
      "         [-0.0201,  0.1404,  0.0632,  ...,  0.4909, -0.1077, -0.2238],\n",
      "         [ 0.0165,  0.1231,  0.0931,  ...,  0.3449, -0.1527, -0.2744]],\n",
      "\n",
      "        [[ 0.5250,  0.2412, -0.4186,  ...,  0.0558, -0.1360, -0.3949],\n",
      "         [ 0.3371,  0.2971, -0.3882,  ..., -0.0799, -0.3081, -0.3079],\n",
      "         [ 0.2755,  0.4058, -0.5229,  ..., -0.3471, -0.3001, -0.3382],\n",
      "         ...,\n",
      "         [-0.2574, -0.0340, -0.0930,  ...,  0.3624, -0.3420, -0.1684],\n",
      "         [-0.2478,  0.0373, -0.0834,  ...,  0.3214, -0.2958, -0.2499],\n",
      "         [-0.2004, -0.0404, -0.0112,  ...,  0.2326, -0.3154, -0.3330]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2810,  0.2207, -0.2633,  ...,  0.0512, -0.0944, -0.1130],\n",
      "         [ 0.3080,  0.2782, -0.2863,  ...,  0.0579, -0.1846, -0.0200],\n",
      "         [ 0.4057,  0.2856, -0.3636,  ..., -0.0065, -0.2278, -0.0093],\n",
      "         ...,\n",
      "         [-0.2333,  0.4254,  0.1016,  ...,  0.3075, -0.5031, -0.0788],\n",
      "         [-0.2151,  0.4167,  0.1408,  ...,  0.2471, -0.3687, -0.1166],\n",
      "         [-0.0538,  0.4627,  0.0869,  ...,  0.1815, -0.3415, -0.0232]],\n",
      "\n",
      "        [[ 0.0312,  0.3874, -0.2095,  ..., -0.0789, -0.3473,  0.2074],\n",
      "         [-0.1010,  0.2202, -0.0214,  ..., -0.2115, -0.2016,  0.3887],\n",
      "         [ 0.1343,  0.1501,  0.0396,  ..., -0.2864,  0.0110,  0.5576],\n",
      "         ...,\n",
      "         [ 0.2821,  0.0584, -0.0962,  ...,  0.1148, -0.3033,  0.4275],\n",
      "         [ 0.2951,  0.1280, -0.0385,  ...,  0.0709, -0.3027,  0.3595],\n",
      "         [ 0.2456,  0.0402, -0.1731,  ...,  0.0651, -0.3630,  0.3004]],\n",
      "\n",
      "        [[ 0.0345,  0.5037, -0.3184,  ..., -0.1272, -0.2605,  0.2398],\n",
      "         [-0.0793,  0.2402, -0.1157,  ..., -0.2361, -0.2432,  0.4985],\n",
      "         [ 0.1977,  0.2158, -0.1599,  ..., -0.1050, -0.1757,  0.5626],\n",
      "         ...,\n",
      "         [ 0.1902,  0.0240, -0.0587,  ...,  0.1872, -0.2169,  0.2513],\n",
      "         [ 0.1686,  0.0919, -0.0219,  ...,  0.2452, -0.2368,  0.2635],\n",
      "         [ 0.1245,  0.0250, -0.0712,  ...,  0.2062, -0.2166,  0.3106]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.4517,  0.6619,  0.1105,  ...,  0.2588,  0.1725, -0.3568],\n",
      "         [-0.2121,  0.3338,  0.0151,  ...,  0.3060,  0.3216, -0.3349],\n",
      "         [ 0.0192,  0.3376, -0.0253,  ...,  0.2144,  0.2038, -0.2662],\n",
      "         ...,\n",
      "         [ 0.0909,  0.4465,  0.1840,  ...,  0.5389,  0.4165, -0.0677],\n",
      "         [ 0.0889,  0.4492,  0.1978,  ...,  0.4936,  0.3875, -0.0593],\n",
      "         [ 0.0610,  0.3557,  0.1131,  ...,  0.4611,  0.3481, -0.0921]],\n",
      "\n",
      "        [[-0.3276, -0.0073, -0.0994,  ..., -0.2053,  0.0891,  0.3492],\n",
      "         [-0.3165,  0.1312, -0.1746,  ..., -0.2750, -0.0973,  0.4547],\n",
      "         [-0.4186,  0.1517, -0.3133,  ..., -0.2071, -0.1553,  0.4135],\n",
      "         ...,\n",
      "         [-0.6614,  0.1230, -0.6005,  ...,  0.1739,  0.0277,  0.3265],\n",
      "         [-0.4778,  0.1739, -0.4553,  ...,  0.2036,  0.1712,  0.2956],\n",
      "         [-0.2713,  0.0879, -0.4624,  ...,  0.0970,  0.1907,  0.2567]],\n",
      "\n",
      "        [[ 0.1746,  0.4868, -0.5707,  ...,  0.2705,  0.3987, -0.5049],\n",
      "         [-0.1590,  0.4844, -0.5698,  ...,  0.1460,  0.1866, -0.2252],\n",
      "         [-0.4067,  0.4814, -0.7697,  ...,  0.0580,  0.1259, -0.2465],\n",
      "         ...,\n",
      "         [-0.3753, -0.0526, -0.5254,  ...,  0.3611, -0.5328,  0.1675],\n",
      "         [-0.3832,  0.0310, -0.5197,  ...,  0.4139, -0.5036,  0.1783],\n",
      "         [-0.1074,  0.0711, -0.4048,  ...,  0.2631, -0.4710,  0.0748]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1300,  0.0333, -0.3870,  ...,  0.0180,  0.2415, -0.1911],\n",
      "         [-0.0404,  0.0568, -0.4065,  ..., -0.0187,  0.2326, -0.1566],\n",
      "         [ 0.0286,  0.0442, -0.4930,  ..., -0.0416,  0.2171, -0.2653],\n",
      "         ...,\n",
      "         [-0.1895,  0.4654, -0.6484,  ...,  0.4205, -0.4297, -0.1269],\n",
      "         [-0.1414,  0.4640, -0.6220,  ...,  0.4724, -0.3147, -0.1023],\n",
      "         [-0.0587,  0.4920, -0.6421,  ...,  0.4074, -0.3594,  0.0230]],\n",
      "\n",
      "        [[-0.3469,  0.5101,  0.3463,  ...,  0.0372,  0.5422, -0.0187],\n",
      "         [-0.1884,  0.3020,  0.2329,  ...,  0.1250,  0.3951, -0.1271],\n",
      "         [-0.0353,  0.2618,  0.1457,  ..., -0.0667,  0.3259, -0.1929],\n",
      "         ...,\n",
      "         [ 0.0632,  0.1788,  0.1026,  ...,  0.3759,  0.4054,  0.0835],\n",
      "         [ 0.1330,  0.1381,  0.1022,  ...,  0.3436,  0.4122,  0.1191],\n",
      "         [ 0.1288,  0.0739,  0.0050,  ...,  0.3040,  0.4157,  0.1496]],\n",
      "\n",
      "        [[-0.5364,  0.5801,  0.2336,  ...,  0.2135,  0.3701, -0.1807],\n",
      "         [-0.3825,  0.3904,  0.2410,  ...,  0.2075,  0.3101, -0.0187],\n",
      "         [-0.3124,  0.3933,  0.1577,  ...,  0.2081,  0.3092, -0.0056],\n",
      "         ...,\n",
      "         [-0.1851,  0.4202,  0.1663,  ...,  0.4323,  0.2728,  0.0501],\n",
      "         [-0.1705,  0.3737,  0.1968,  ...,  0.4430,  0.1950,  0.0172],\n",
      "         [-0.1814,  0.3013,  0.2096,  ...,  0.4239,  0.1441,  0.0012]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0389,  0.9814,  0.3398,  ...,  0.1405, -0.2862, -0.5077],\n",
      "         [ 0.1340,  0.8996,  0.1565,  ...,  0.0709, -0.2798, -0.6152],\n",
      "         [ 0.2250,  0.8958,  0.0908,  ..., -0.0189, -0.2566, -0.5793],\n",
      "         ...,\n",
      "         [ 0.2237,  0.9061,  0.0715,  ..., -0.2966, -0.1592, -0.4978],\n",
      "         [ 0.2327,  0.9218,  0.0953,  ..., -0.3025, -0.1476, -0.5170],\n",
      "         [ 0.1803,  0.8901,  0.0461,  ..., -0.3129, -0.1451, -0.5408]],\n",
      "\n",
      "        [[-0.0194, -0.2040, -0.3289,  ..., -0.2753, -0.3762, -0.1358],\n",
      "         [ 0.1210, -0.1802, -0.2643,  ..., -0.2650, -0.4355, -0.2882],\n",
      "         [ 0.1548, -0.1901, -0.3407,  ..., -0.2304, -0.4849, -0.3035],\n",
      "         ...,\n",
      "         [ 0.0789,  0.2106, -0.7488,  ...,  0.2014, -0.3306, -0.1109],\n",
      "         [ 0.2449,  0.2341, -0.6254,  ..., -0.1427, -0.3043, -0.1121],\n",
      "         [ 0.3076,  0.0835, -0.5828,  ..., -0.3190, -0.2642, -0.2164]],\n",
      "\n",
      "        [[ 0.3780,  0.8628, -0.8244,  ...,  0.3045, -0.2682, -0.6735],\n",
      "         [ 0.1867,  0.8595, -0.7091,  ...,  0.1436, -0.3010, -0.5057],\n",
      "         [-0.0489,  0.8228, -0.7475,  ..., -0.1402, -0.3118, -0.5151],\n",
      "         ...,\n",
      "         [ 0.0369, -0.1530, -0.3949,  ...,  0.1420, -0.5069, -0.0802],\n",
      "         [ 0.0529, -0.1180, -0.3903,  ...,  0.1157, -0.5003, -0.0565],\n",
      "         [ 0.0776, -0.1342, -0.3586,  ..., -0.0597, -0.5032, -0.2053]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0121,  0.3709, -0.5265,  ...,  0.0101, -0.4100, -0.2208],\n",
      "         [ 0.1687,  0.3819, -0.5285,  ..., -0.0333, -0.4032, -0.2492],\n",
      "         [ 0.1861,  0.4127, -0.5814,  ..., -0.0410, -0.3874, -0.4099],\n",
      "         ...,\n",
      "         [ 0.2938,  0.4955, -0.8365,  ..., -0.3452, -0.2671, -0.0772],\n",
      "         [ 0.2794,  0.4808, -0.8284,  ..., -0.2954, -0.2561, -0.1097],\n",
      "         [ 0.2832,  0.4752, -0.7802,  ..., -0.2860, -0.2589, -0.0979]],\n",
      "\n",
      "        [[ 0.2253,  1.0692,  0.2822,  ..., -0.3142, -0.0964, -0.3779],\n",
      "         [ 0.0168,  0.7918,  0.0748,  ..., -0.2073, -0.1397, -0.5910],\n",
      "         [ 0.0511,  0.8293,  0.0466,  ..., -0.3582, -0.1535, -0.6164],\n",
      "         ...,\n",
      "         [ 0.2693,  0.6807, -0.0721,  ..., -0.2483, -0.1477, -0.2844],\n",
      "         [ 0.3648,  0.7064, -0.0491,  ..., -0.2427, -0.1366, -0.2847],\n",
      "         [ 0.3659,  0.6902, -0.1031,  ..., -0.2615, -0.1315, -0.2796]],\n",
      "\n",
      "        [[ 0.0666,  1.1638,  0.2878,  ...,  0.0760, -0.1606, -0.4380],\n",
      "         [ 0.0319,  0.8481,  0.4421,  ...,  0.0948, -0.2007, -0.8801],\n",
      "         [ 0.1350,  0.8302,  0.4646,  ..., -0.0244, -0.1902, -0.9075],\n",
      "         ...,\n",
      "         [ 0.2419,  0.8581, -0.0282,  ..., -0.2562, -0.1679, -0.5515],\n",
      "         [ 0.3133,  0.8388,  0.0203,  ..., -0.2391, -0.1740, -0.5218],\n",
      "         [ 0.3400,  0.7957,  0.0389,  ..., -0.2881, -0.1711, -0.5087]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 3.8313e-02,  1.1975e+00, -4.7332e-02,  ...,  7.8098e-01,\n",
      "           8.0729e-02, -7.4418e-01],\n",
      "         [ 2.7029e-02,  1.0583e+00, -1.1347e-01,  ...,  6.2727e-01,\n",
      "           5.0415e-02, -7.2362e-01],\n",
      "         [ 4.5914e-02,  1.1005e+00, -1.5736e-01,  ...,  5.6766e-01,\n",
      "           1.4928e-02, -6.5882e-01],\n",
      "         ...,\n",
      "         [ 1.7061e-01,  1.2334e+00,  1.3163e-01,  ...,  2.4032e-01,\n",
      "           1.4934e-01, -4.6876e-01],\n",
      "         [ 1.6943e-01,  1.2024e+00,  1.3086e-01,  ...,  2.3691e-01,\n",
      "           1.4975e-01, -5.2598e-01],\n",
      "         [ 1.5177e-01,  1.1620e+00,  1.0542e-01,  ...,  2.3347e-01,\n",
      "           1.5258e-01, -5.1618e-01]],\n",
      "\n",
      "        [[-2.3602e-01, -1.6786e-01, -4.8118e-01,  ..., -9.0461e-03,\n",
      "           8.7042e-03,  2.1023e-01],\n",
      "         [-2.4787e-01, -1.7846e-01, -3.6099e-01,  ..., -1.4060e-01,\n",
      "          -3.7204e-02,  2.3282e-01],\n",
      "         [-1.4101e-01, -1.9994e-01, -4.0975e-01,  ..., -1.7158e-01,\n",
      "          -1.0343e-01,  2.0670e-01],\n",
      "         ...,\n",
      "         [-5.0999e-01,  4.8620e-01, -8.0026e-01,  ..., -2.0126e-01,\n",
      "           5.8908e-02,  3.1582e-01],\n",
      "         [-4.5279e-01,  4.7063e-01, -6.2192e-01,  ..., -3.6808e-01,\n",
      "           7.8036e-03,  2.3707e-01],\n",
      "         [-3.7553e-01,  3.6715e-01, -5.3608e-01,  ..., -3.6550e-01,\n",
      "           1.1108e-02,  2.5533e-01]],\n",
      "\n",
      "        [[ 1.6472e-01,  5.1392e-01, -5.6920e-01,  ...,  2.1189e-01,\n",
      "           9.4469e-04, -3.2718e-01],\n",
      "         [ 1.0532e-01,  5.0106e-01, -4.9749e-01,  ..., -6.6265e-02,\n",
      "          -7.5110e-02, -2.9233e-01],\n",
      "         [ 1.0267e-02,  4.4522e-01, -4.9810e-01,  ..., -3.1452e-01,\n",
      "          -1.5754e-01, -2.1674e-01],\n",
      "         ...,\n",
      "         [-2.2585e-01, -1.0204e-01, -3.6604e-01,  ...,  1.2981e-01,\n",
      "          -3.6916e-01,  4.2081e-01],\n",
      "         [-2.2076e-01, -1.5635e-02, -3.5702e-01,  ...,  1.0553e-01,\n",
      "          -3.6171e-01,  4.5737e-01],\n",
      "         [-9.7391e-02, -8.9981e-02, -2.4168e-01,  ..., -1.2339e-01,\n",
      "          -3.5796e-01,  4.5880e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.4760e-01,  3.6964e-01, -6.6410e-01,  ..., -1.8646e-01,\n",
      "           4.6816e-02,  6.3395e-01],\n",
      "         [ 3.3284e-01,  3.0674e-01, -6.1977e-01,  ..., -2.5743e-01,\n",
      "           2.5976e-02,  5.6883e-01],\n",
      "         [ 2.4002e-01,  2.8097e-01, -6.2380e-01,  ..., -2.5572e-01,\n",
      "           2.9583e-02,  5.1005e-01],\n",
      "         ...,\n",
      "         [-3.4011e-02,  6.8913e-01, -8.3254e-01,  ..., -2.5040e-01,\n",
      "          -1.5777e-01,  6.4049e-01],\n",
      "         [-3.6924e-02,  6.6813e-01, -8.3560e-01,  ..., -2.4627e-01,\n",
      "          -1.7828e-01,  6.4107e-01],\n",
      "         [-3.5850e-02,  6.5836e-01, -7.9955e-01,  ..., -2.6392e-01,\n",
      "          -1.8849e-01,  6.3035e-01]],\n",
      "\n",
      "        [[ 3.6173e-01,  1.1431e+00, -1.3614e-02,  ...,  2.8679e-01,\n",
      "           3.0706e-01, -6.2423e-01],\n",
      "         [ 2.6795e-01,  7.9143e-01, -1.1206e-01,  ...,  3.6854e-01,\n",
      "           2.7311e-01, -5.8771e-01],\n",
      "         [ 2.9643e-01,  8.5669e-01, -1.4416e-01,  ...,  2.8742e-01,\n",
      "           2.1240e-01, -5.1988e-01],\n",
      "         ...,\n",
      "         [-1.0784e-01,  9.8813e-01,  2.7576e-02,  ...,  2.0410e-01,\n",
      "           2.0800e-01, -3.4098e-01],\n",
      "         [-8.0624e-02,  9.8444e-01,  1.6405e-02,  ...,  2.0936e-01,\n",
      "           2.1014e-01, -3.7943e-01],\n",
      "         [-6.5707e-02,  9.6498e-01, -6.1256e-03,  ...,  1.8976e-01,\n",
      "           2.0964e-01, -3.7217e-01]],\n",
      "\n",
      "        [[ 2.8965e-01,  9.0090e-01, -3.8728e-02,  ...,  4.8142e-01,\n",
      "           2.5859e-01, -5.6289e-01],\n",
      "         [ 2.2676e-01,  8.7680e-01,  1.2501e-01,  ...,  3.9419e-01,\n",
      "           1.1586e-01, -6.5203e-01],\n",
      "         [ 2.3161e-01,  9.3418e-01,  1.5523e-01,  ...,  3.4054e-01,\n",
      "           1.0133e-01, -6.4963e-01],\n",
      "         ...,\n",
      "         [ 4.4949e-01,  1.0203e+00,  1.3646e-01,  ...,  2.7416e-01,\n",
      "           2.6633e-01, -2.3344e-01],\n",
      "         [ 4.6450e-01,  9.8679e-01,  1.2489e-01,  ...,  2.8178e-01,\n",
      "           2.6038e-01, -2.5735e-01],\n",
      "         [ 4.7416e-01,  9.5948e-01,  1.2544e-01,  ...,  2.5799e-01,\n",
      "           2.6261e-01, -2.3555e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.5574,  2.7299,  1.7644,  ...,  3.8878,  3.6748, -2.9682],\n",
      "         [-1.2385,  2.4217,  1.4513,  ...,  3.1684,  3.2283, -2.6191],\n",
      "         [-1.2577,  2.6678,  1.2978,  ...,  3.1420,  3.0328, -2.4704],\n",
      "         ...,\n",
      "         [-0.5392,  1.6495,  2.0474,  ...,  1.4983,  3.5895, -2.6731],\n",
      "         [-0.5430,  1.6313,  2.1181,  ...,  1.4924,  3.5740, -2.7337],\n",
      "         [-0.5747,  1.5431,  2.0305,  ...,  1.5043,  3.6112, -2.7024]],\n",
      "\n",
      "        [[ 1.6650, -0.1536, -1.5905,  ...,  1.5675,  3.3128, -1.8146],\n",
      "         [ 1.7882, -0.4315, -0.8853,  ...,  1.0509,  2.9287, -1.6345],\n",
      "         [ 1.7248, -0.6132, -0.7529,  ...,  0.8679,  3.0820, -1.8128],\n",
      "         ...,\n",
      "         [ 1.6363,  2.3808, -1.3496,  ..., -0.2500,  1.5274, -1.5889],\n",
      "         [ 1.1859,  2.4725, -0.6861,  ..., -0.8270,  1.2119, -1.3822],\n",
      "         [ 1.0351,  2.1470, -0.3311,  ..., -0.7226,  0.7787, -0.9414]],\n",
      "\n",
      "        [[ 1.8395,  2.2896, -0.6211,  ...,  1.0288,  3.6456, -1.8448],\n",
      "         [ 1.4253,  2.5984, -1.2991,  ...,  0.6419,  3.8052, -1.5869],\n",
      "         [ 0.9557,  3.0045, -1.5680,  ..., -0.1572,  3.2591, -1.5158],\n",
      "         ...,\n",
      "         [ 0.4121, -0.9219,  0.7315,  ...,  0.2822, -1.2178,  2.2190],\n",
      "         [ 0.3974, -0.5745,  0.5809,  ...,  0.2572, -1.1938,  2.2286],\n",
      "         [ 0.6903, -1.0640,  0.9429,  ..., -0.4767, -1.0488,  2.1341]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0813,  1.1755, -2.6329,  ...,  1.6933,  4.7373, -1.5665],\n",
      "         [ 1.6438,  1.1614, -2.4792,  ...,  1.6404,  4.2066, -1.2908],\n",
      "         [ 1.4427,  1.2869, -2.4946,  ...,  1.5868,  4.0382, -0.7648],\n",
      "         ...,\n",
      "         [ 2.2280,  3.2720,  1.3424,  ..., -0.5590, -1.3058, -0.4848],\n",
      "         [ 2.2823,  3.1805,  1.2489,  ..., -0.4286, -1.6643, -0.4357],\n",
      "         [ 2.5250,  3.0245,  1.4525,  ..., -0.5716, -1.8274, -0.2730]],\n",
      "\n",
      "        [[ 0.1515,  3.2570,  1.6926,  ...,  2.6991,  4.0479, -1.8514],\n",
      "         [-0.2020,  2.4350,  1.1386,  ...,  2.8336,  3.9024, -1.5946],\n",
      "         [-0.1910,  2.6349,  1.1640,  ...,  2.7250,  3.5701, -1.5259],\n",
      "         ...,\n",
      "         [-1.2118,  2.0663,  1.4181,  ...,  1.2168,  3.0632, -2.1710],\n",
      "         [-1.1289,  2.0664,  1.4611,  ...,  1.2492,  3.0882, -2.1852],\n",
      "         [-1.1306,  2.0371,  1.4343,  ...,  1.2136,  3.1006, -2.1619]],\n",
      "\n",
      "        [[ 0.1042,  2.2764,  1.6937,  ...,  3.2073,  3.9115, -2.6609],\n",
      "         [-0.6306,  1.9447,  2.1919,  ...,  3.2447,  3.0554, -2.2734],\n",
      "         [-0.7968,  2.2055,  2.2973,  ...,  3.2411,  2.9335, -2.2000],\n",
      "         ...,\n",
      "         [ 0.0125,  2.2549,  1.7726,  ...,  1.2451,  4.1379, -2.3193],\n",
      "         [ 0.0570,  2.2124,  1.7567,  ...,  1.2933,  4.0943, -2.3311],\n",
      "         [ 0.0394,  2.1453,  1.7176,  ...,  1.2480,  4.1115, -2.2774]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)), decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 8.9600e-03,  4.3611e-03, -9.9629e-03,  ...,  2.8096e-02,\n",
      "          -5.4153e-02,  1.0457e-01],\n",
      "         [ 1.2331e-01, -1.4334e-01,  4.4988e-01,  ...,  2.2261e-01,\n",
      "          -1.0952e-01,  3.6042e-01],\n",
      "         [ 3.6026e-02, -1.2683e-01,  3.6745e-01,  ...,  1.1459e-01,\n",
      "           4.1378e-02,  2.4709e-01],\n",
      "         ...,\n",
      "         [ 6.8112e-02, -7.4947e-02,  4.0643e-01,  ...,  1.8812e-01,\n",
      "           2.5749e-01,  2.8832e-01],\n",
      "         [ 6.6964e-02, -6.5883e-02,  3.1562e-01,  ...,  2.0343e-01,\n",
      "           2.8107e-01,  2.8803e-01],\n",
      "         [ 4.8935e-02, -5.8867e-02,  2.8122e-01,  ...,  2.2763e-01,\n",
      "           2.8398e-01,  2.8321e-01]],\n",
      "\n",
      "        [[-3.6469e-02,  1.0602e-02, -2.0457e-03,  ...,  1.2131e-02,\n",
      "          -7.9561e-04, -1.5222e-02],\n",
      "         [-5.3589e-02,  2.9798e-01,  4.4390e-01,  ...,  9.6474e-02,\n",
      "          -1.7962e-01,  2.7775e-01],\n",
      "         [-2.4748e-01,  8.3584e-02,  1.3068e-01,  ...,  1.6351e-02,\n",
      "           4.6265e-03, -1.6294e-01],\n",
      "         ...,\n",
      "         [ 4.2906e-02,  1.6557e-01, -3.9785e-02,  ..., -4.6588e-03,\n",
      "           1.8436e-01,  3.1765e-02],\n",
      "         [ 2.9919e-02,  1.4585e-01, -5.9581e-03,  ..., -2.5343e-03,\n",
      "           4.3650e-02,  4.7968e-03],\n",
      "         [ 2.2975e-03,  1.3323e-01, -6.6722e-02,  ...,  3.4239e-03,\n",
      "           1.2987e-01, -5.9970e-02]],\n",
      "\n",
      "        [[-3.7903e-02,  6.2472e-03, -2.6940e-03,  ...,  1.0063e-02,\n",
      "          -2.3382e-03, -1.2711e-02],\n",
      "         [ 2.0017e-02,  2.1240e-01,  2.0011e-01,  ..., -7.8214e-02,\n",
      "          -3.4939e-01,  4.3609e-02],\n",
      "         [-4.6498e-02, -1.6959e-01,  1.2598e-01,  ...,  2.6245e-01,\n",
      "          -8.4623e-02, -4.5808e-02],\n",
      "         ...,\n",
      "         [ 5.7552e-02,  2.0570e-01, -3.2642e-02,  ..., -4.3161e-04,\n",
      "           1.5766e-01, -3.1554e-02],\n",
      "         [ 9.5210e-02,  2.7250e-01, -2.7809e-02,  ..., -5.2264e-02,\n",
      "           2.5420e-01,  5.2642e-02],\n",
      "         [ 1.8179e-01,  1.3543e-01, -7.1767e-02,  ..., -1.6728e-02,\n",
      "           3.8241e-01,  6.4053e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.7319e-02,  8.9188e-03, -8.6839e-04,  ...,  1.1274e-02,\n",
      "          -8.8549e-05, -1.5146e-02],\n",
      "         [ 2.9504e-01,  3.8382e-01,  1.4821e-01,  ...,  7.7610e-02,\n",
      "          -1.8683e-01,  2.6949e-01],\n",
      "         [ 2.8087e-01,  3.2174e-01,  6.4600e-02,  ...,  1.5365e-01,\n",
      "           1.6070e-01, -1.1506e-01],\n",
      "         ...,\n",
      "         [ 2.0545e-01,  2.4647e-01,  7.4164e-03,  ...,  1.3523e-02,\n",
      "           1.6829e-01, -9.7626e-02],\n",
      "         [ 1.4060e-01,  2.0739e-01,  5.0529e-02,  ...,  1.2703e-02,\n",
      "           1.6099e-01, -7.1236e-02],\n",
      "         [ 3.0091e-01,  1.0519e-01,  4.4196e-02,  ...,  7.1789e-02,\n",
      "           4.3323e-01, -1.0955e-01]],\n",
      "\n",
      "        [[ 8.9600e-03,  4.3611e-03, -9.9629e-03,  ...,  2.8096e-02,\n",
      "          -5.4153e-02,  1.0457e-01],\n",
      "         [ 1.2331e-01, -1.4334e-01,  4.4988e-01,  ...,  2.2261e-01,\n",
      "          -1.0952e-01,  3.6042e-01],\n",
      "         [ 3.6026e-02, -1.2683e-01,  3.6745e-01,  ...,  1.1459e-01,\n",
      "           4.1378e-02,  2.4709e-01],\n",
      "         ...,\n",
      "         [ 6.8112e-02, -7.4947e-02,  4.0643e-01,  ...,  1.8812e-01,\n",
      "           2.5749e-01,  2.8832e-01],\n",
      "         [ 6.6964e-02, -6.5883e-02,  3.1562e-01,  ...,  2.0343e-01,\n",
      "           2.8107e-01,  2.8803e-01],\n",
      "         [ 4.8935e-02, -5.8867e-02,  2.8122e-01,  ...,  2.2763e-01,\n",
      "           2.8398e-01,  2.8321e-01]],\n",
      "\n",
      "        [[ 8.9600e-03,  4.3611e-03, -9.9629e-03,  ...,  2.8096e-02,\n",
      "          -5.4153e-02,  1.0457e-01],\n",
      "         [ 1.2331e-01, -1.4334e-01,  4.4988e-01,  ...,  2.2261e-01,\n",
      "          -1.0952e-01,  3.6042e-01],\n",
      "         [ 3.6026e-02, -1.2683e-01,  3.6745e-01,  ...,  1.1459e-01,\n",
      "           4.1378e-02,  2.4709e-01],\n",
      "         ...,\n",
      "         [ 6.8112e-02, -7.4947e-02,  4.0643e-01,  ...,  1.8812e-01,\n",
      "           2.5749e-01,  2.8832e-01],\n",
      "         [ 6.6964e-02, -6.5883e-02,  3.1562e-01,  ...,  2.0343e-01,\n",
      "           2.8107e-01,  2.8803e-01],\n",
      "         [ 4.8935e-02, -5.8867e-02,  2.8122e-01,  ...,  2.2763e-01,\n",
      "           2.8398e-01,  2.8321e-01]]]), encoder_hidden_states=(tensor([[[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [-0.0524, -0.4353,  0.2914,  ..., -0.1146, -0.1735,  0.1636],\n",
      "         [-0.0761, -0.5322,  0.2533,  ..., -0.2116, -0.0279, -0.0200],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [-0.0246,  0.0382, -0.1166,  ...,  0.1576, -0.6024,  0.0663],\n",
      "         [ 0.0164, -0.3341, -0.0832,  ...,  0.0371,  0.1220,  0.2191],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.4495, -0.2277, -0.0106,  ..., -0.3477, -0.2672, -0.2672],\n",
      "         [-0.2243, -0.0701,  0.4669,  ..., -0.1731, -0.2081, -0.2968],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]]]), tensor([[[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]],\n",
      "\n",
      "        [[-5.0709e-02, -2.5158e-02,  5.8747e-02,  ...,  1.6715e-02,\n",
      "          -2.4115e-02,  1.9094e-02],\n",
      "         [ 6.3972e-02, -1.6677e-01,  5.0908e-01,  ...,  3.3848e-01,\n",
      "           3.4305e-02,  3.5869e-01],\n",
      "         [ 1.0111e-02, -4.5611e-01,  3.9241e-01,  ..., -2.2872e-01,\n",
      "          -2.1559e-01, -1.8246e-01],\n",
      "         ...,\n",
      "         [ 1.9676e-01,  6.8954e-01, -1.4038e-02,  ...,  6.7478e-01,\n",
      "           5.0750e-01, -2.2744e-01],\n",
      "         [ 4.3532e-01,  6.5669e-01,  6.7238e-02,  ...,  6.1560e-01,\n",
      "           3.2561e-01, -1.0743e-01],\n",
      "         [ 2.1672e-01,  4.0728e-01, -1.4014e-01,  ...,  8.6411e-01,\n",
      "           4.1752e-01, -3.4706e-02]],\n",
      "\n",
      "        [[-4.5657e-02, -2.2770e-02,  6.3670e-02,  ...,  2.4137e-02,\n",
      "          -2.2413e-02,  2.0011e-02],\n",
      "         [-6.2713e-02, -5.8707e-02,  3.3937e-02,  ...,  1.6044e-02,\n",
      "          -5.0097e-01,  2.3099e-01],\n",
      "         [-3.8233e-01, -3.1545e-01,  8.5033e-02,  ...,  5.6782e-01,\n",
      "          -7.7667e-02, -2.2301e-01],\n",
      "         ...,\n",
      "         [ 1.7399e-01,  6.5500e-01,  5.8843e-02,  ...,  4.5903e-01,\n",
      "           6.0781e-01, -2.4064e-01],\n",
      "         [ 3.6708e-01,  8.1396e-01, -2.9674e-03,  ...,  5.6210e-01,\n",
      "           4.7337e-01, -7.2463e-02],\n",
      "         [ 4.3171e-01,  4.9147e-01, -1.6821e-01,  ...,  8.8327e-01,\n",
      "           4.5313e-01, -1.1510e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.9993e-02, -2.7213e-02,  5.4562e-02,  ...,  2.0791e-02,\n",
      "          -2.6884e-02,  1.8412e-02],\n",
      "         [ 3.3906e-01, -1.5661e-01,  2.3621e-01,  ...,  6.1267e-02,\n",
      "          -1.7409e-01,  9.7654e-02],\n",
      "         [ 3.1151e-01, -1.2533e-01,  7.4419e-01,  ...,  1.8429e-01,\n",
      "          -1.9713e-01, -2.3221e-02],\n",
      "         ...,\n",
      "         [ 3.7641e-01,  7.3195e-01,  2.1144e-01,  ...,  4.4969e-01,\n",
      "           5.5429e-01, -2.2877e-01],\n",
      "         [ 4.7480e-01,  4.9709e-01,  1.6932e-01,  ...,  6.6978e-01,\n",
      "           3.7982e-01,  3.3548e-02],\n",
      "         [ 5.4832e-01,  3.5656e-01, -7.5224e-02,  ...,  7.7367e-01,\n",
      "           4.2366e-01,  1.2545e-01]],\n",
      "\n",
      "        [[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]],\n",
      "\n",
      "        [[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]]]), tensor([[[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]],\n",
      "\n",
      "        [[-0.0746,  0.0093,  0.0386,  ..., -0.0421, -0.0550, -0.0054],\n",
      "         [-0.0238,  0.1097,  0.7665,  ...,  0.2679,  0.1806,  0.8259],\n",
      "         [-0.4233, -0.5013,  0.2635,  ..., -0.3098, -0.1072, -0.5540],\n",
      "         ...,\n",
      "         [ 0.1417,  0.4658, -0.0365,  ...,  0.2471,  0.7516, -0.1521],\n",
      "         [ 0.3740,  0.5759, -0.0012,  ...,  0.2769,  0.6312, -0.1877],\n",
      "         [ 0.1662,  0.4377, -0.1821,  ...,  0.5153,  0.7008, -0.1819]],\n",
      "\n",
      "        [[-0.0685,  0.0103,  0.0333,  ..., -0.0386, -0.0583, -0.0096],\n",
      "         [-0.0792,  0.4279,  0.1021,  ..., -0.0384, -0.4870,  0.8170],\n",
      "         [-0.1677, -0.2668,  0.2259,  ...,  0.3475, -0.2048, -0.6603],\n",
      "         ...,\n",
      "         [ 0.1973,  0.5983,  0.0300,  ...,  0.2863,  0.8027, -0.2273],\n",
      "         [ 0.3702,  0.7623, -0.0305,  ...,  0.3219,  0.6478, -0.2090],\n",
      "         [ 0.4648,  0.6368, -0.1224,  ...,  0.5486,  0.6246, -0.2805]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0643,  0.0076,  0.0370,  ..., -0.0390, -0.0565, -0.0053],\n",
      "         [ 0.2015,  0.0440,  0.5102,  ...,  0.3674,  0.0149,  0.9421],\n",
      "         [ 0.1465, -0.1185,  0.5094,  ...,  0.5873, -0.0649, -0.1157],\n",
      "         ...,\n",
      "         [ 0.4327,  0.6752,  0.2799,  ...,  0.2631,  0.7325, -0.3461],\n",
      "         [ 0.4475,  0.5112,  0.2306,  ...,  0.3461,  0.5627, -0.2476],\n",
      "         [ 0.5832,  0.4971,  0.0982,  ...,  0.4413,  0.6579, -0.1723]],\n",
      "\n",
      "        [[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]],\n",
      "\n",
      "        [[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]]]), tensor([[[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]],\n",
      "\n",
      "        [[-6.4140e-02,  2.1056e-02,  1.1048e-02,  ..., -2.4298e-02,\n",
      "          -6.1508e-03, -6.7564e-03],\n",
      "         [ 2.6895e-03,  2.8031e-01,  7.6075e-01,  ...,  2.6563e-01,\n",
      "           7.7858e-02,  9.7345e-01],\n",
      "         [-5.3861e-01, -1.5447e-01,  1.8145e-01,  ..., -2.1954e-01,\n",
      "          -2.5652e-02, -5.2322e-01],\n",
      "         ...,\n",
      "         [-1.4126e-01, -1.6126e-01,  3.4877e-02,  ...,  2.7510e-01,\n",
      "           6.6654e-01,  1.3273e-01],\n",
      "         [ 7.0800e-02, -1.3089e-01,  8.7937e-02,  ...,  4.1522e-01,\n",
      "           5.2652e-01,  6.5328e-02],\n",
      "         [-1.4788e-01, -2.2513e-01, -1.1853e-01,  ...,  4.4167e-01,\n",
      "           5.9328e-01,  1.6735e-01]],\n",
      "\n",
      "        [[-6.5925e-02,  2.3024e-02,  1.1550e-02,  ..., -2.0203e-02,\n",
      "          -8.6657e-03, -3.5980e-03],\n",
      "         [-2.3662e-02,  4.5526e-01,  3.0921e-01,  ..., -1.8752e-01,\n",
      "          -5.1165e-01,  5.5340e-01],\n",
      "         [-3.4269e-01, -2.8855e-02,  4.1069e-01,  ...,  2.3362e-01,\n",
      "          -1.1475e-01, -5.8612e-01],\n",
      "         ...,\n",
      "         [-2.9471e-02,  1.0306e-01,  9.3135e-02,  ...,  2.4166e-01,\n",
      "           6.9904e-01,  3.1077e-02],\n",
      "         [ 2.1417e-01,  1.1188e-01,  6.7656e-02,  ...,  3.6952e-01,\n",
      "           6.0602e-01,  5.5171e-02],\n",
      "         [ 1.6225e-01,  2.5464e-02, -7.9671e-02,  ...,  4.4250e-01,\n",
      "           7.0347e-01,  9.2773e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.4372e-02,  2.4650e-02,  8.4690e-03,  ..., -2.1834e-02,\n",
      "          -9.0616e-03, -2.7107e-03],\n",
      "         [ 2.1487e-01,  3.3384e-01,  6.3361e-01,  ...,  1.7992e-01,\n",
      "          -8.6301e-02,  9.2189e-01],\n",
      "         [ 5.6633e-02,  1.8459e-01,  5.2746e-01,  ...,  4.9777e-01,\n",
      "          -3.4760e-02, -7.0254e-02],\n",
      "         ...,\n",
      "         [ 1.8755e-01,  7.8529e-02,  3.1768e-01,  ...,  2.4565e-01,\n",
      "           5.6809e-01, -1.5200e-01],\n",
      "         [ 1.9458e-01, -1.2844e-01,  3.2571e-01,  ...,  4.2149e-01,\n",
      "           4.6874e-01, -2.9499e-02],\n",
      "         [ 3.1052e-01, -5.9787e-02,  1.0963e-01,  ...,  4.2269e-01,\n",
      "           5.7076e-01,  4.5385e-02]],\n",
      "\n",
      "        [[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]],\n",
      "\n",
      "        [[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]]]), tensor([[[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]],\n",
      "\n",
      "        [[-0.0867,  0.0285, -0.0118,  ...,  0.0482,  0.0045, -0.0087],\n",
      "         [ 0.0076,  0.0364,  0.9071,  ...,  0.3912, -0.1484,  0.7644],\n",
      "         [-0.2568, -0.1539,  0.2405,  ...,  0.2662, -0.0245, -0.4436],\n",
      "         ...,\n",
      "         [ 0.0483, -0.0391,  0.0302,  ...,  0.2689,  0.7774,  0.1994],\n",
      "         [ 0.1869,  0.0277,  0.0942,  ...,  0.2766,  0.5493,  0.2443],\n",
      "         [ 0.0414, -0.1012, -0.1028,  ...,  0.3801,  0.6864,  0.1802]],\n",
      "\n",
      "        [[-0.0843,  0.0259, -0.0112,  ...,  0.0482,  0.0049, -0.0061],\n",
      "         [ 0.1095,  0.3002,  0.4258,  ..., -0.2904, -0.6138,  0.6378],\n",
      "         [ 0.0143, -0.2756,  0.4571,  ...,  0.1347, -0.0453, -0.4301],\n",
      "         ...,\n",
      "         [ 0.2667,  0.2487,  0.0904,  ...,  0.1913,  0.7216,  0.2444],\n",
      "         [ 0.4479,  0.1383,  0.0942,  ...,  0.3855,  0.7037,  0.1935],\n",
      "         [ 0.5055,  0.0313, -0.0264,  ...,  0.5062,  0.8827,  0.1350]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0854,  0.0252, -0.0105,  ...,  0.0474,  0.0059, -0.0062],\n",
      "         [ 0.4011,  0.6448,  0.4719,  ...,  0.6392, -0.2172,  0.6382],\n",
      "         [ 0.5214,  0.3679,  0.3322,  ...,  0.4678,  0.2569, -0.1730],\n",
      "         ...,\n",
      "         [ 0.3722,  0.1379,  0.4018,  ...,  0.3678,  0.6528,  0.1587],\n",
      "         [ 0.3361, -0.1142,  0.3965,  ...,  0.4901,  0.5798,  0.2469],\n",
      "         [ 0.5100, -0.1627,  0.1959,  ...,  0.5570,  0.8277,  0.0639]],\n",
      "\n",
      "        [[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]],\n",
      "\n",
      "        [[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]]]), tensor([[[ 2.2499e-01,  2.2679e-01, -9.7369e-02,  ...,  3.1162e-01,\n",
      "           5.4782e-02,  3.2754e-01],\n",
      "         [ 3.5536e-01,  1.4777e-01,  4.5789e-01,  ...,  3.4361e-01,\n",
      "           3.8069e-02,  9.0847e-01],\n",
      "         [ 2.8214e-01,  1.7340e-01,  3.6478e-01,  ...,  2.5438e-01,\n",
      "           1.8153e-01,  7.4237e-01],\n",
      "         ...,\n",
      "         [ 4.2941e-01,  1.7001e-01,  4.8060e-01,  ...,  2.4500e-01,\n",
      "           5.2668e-01,  8.7164e-01],\n",
      "         [ 4.2571e-01,  1.8047e-01,  3.2447e-01,  ...,  2.7726e-01,\n",
      "           5.7065e-01,  8.9218e-01],\n",
      "         [ 3.8382e-01,  1.5315e-01,  2.4005e-01,  ...,  3.1564e-01,\n",
      "           5.7542e-01,  9.3489e-01]],\n",
      "\n",
      "        [[-6.6267e-02,  2.3116e-02, -9.5219e-03,  ...,  1.8527e-02,\n",
      "           5.3510e-03, -1.9974e-02],\n",
      "         [ 1.2443e-01,  3.6128e-01,  7.7324e-01,  ...,  4.9831e-02,\n",
      "           5.7355e-02,  6.2760e-01],\n",
      "         [-2.9223e-01, -6.4738e-02,  2.5216e-01,  ...,  1.4128e-03,\n",
      "           4.6233e-02, -5.1901e-01],\n",
      "         ...,\n",
      "         [ 2.0919e-01,  2.9592e-01, -1.1088e-01,  ...,  3.3613e-02,\n",
      "           6.5812e-01,  1.6706e-01],\n",
      "         [ 2.3081e-01,  4.0606e-01, -8.7859e-03,  ..., -2.1706e-03,\n",
      "           2.6780e-01,  2.1225e-01],\n",
      "         [ 1.1547e-01,  1.9388e-01, -2.1317e-01,  ...,  2.0047e-02,\n",
      "           5.5272e-01,  5.0239e-02]],\n",
      "\n",
      "        [[-6.2417e-02,  1.4055e-02, -8.3867e-03,  ...,  2.2396e-02,\n",
      "          -5.0079e-03, -1.4484e-02],\n",
      "         [ 1.6962e-01,  3.9532e-01,  3.9960e-01,  ..., -8.1101e-03,\n",
      "          -6.0011e-01,  8.7008e-02],\n",
      "         [ 3.8596e-04, -3.5286e-01,  3.7072e-01,  ...,  5.1895e-01,\n",
      "          -1.1130e-01, -1.4373e-01],\n",
      "         ...,\n",
      "         [ 3.0190e-01,  4.1604e-01, -1.4291e-01,  ..., -5.7875e-02,\n",
      "           5.0931e-01,  2.8492e-01],\n",
      "         [ 3.3535e-01,  4.4937e-01, -9.8643e-02,  ...,  2.6659e-02,\n",
      "           6.3963e-01,  2.5872e-01],\n",
      "         [ 4.3596e-01,  1.3737e-01, -1.6477e-01,  ...,  2.6156e-01,\n",
      "           9.3867e-01,  1.3485e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.6308e-02,  1.6191e-02, -5.1624e-03,  ...,  1.8609e-02,\n",
      "           7.7463e-03, -1.5607e-02],\n",
      "         [ 5.5921e-01,  8.4450e-01,  4.2124e-01,  ...,  2.7015e-01,\n",
      "          -1.9457e-01,  1.9354e-01],\n",
      "         [ 5.4638e-01,  7.6707e-01,  4.6294e-02,  ...,  4.2524e-01,\n",
      "           3.5130e-01, -4.5651e-01],\n",
      "         ...,\n",
      "         [ 4.9669e-01,  6.4202e-01,  1.1301e-01,  ...,  9.0925e-02,\n",
      "           5.8149e-01,  5.6305e-02],\n",
      "         [ 4.3949e-01,  4.0863e-01,  1.9118e-01,  ...,  1.4524e-01,\n",
      "           5.4326e-01,  1.0461e-01],\n",
      "         [ 5.5939e-01,  9.0185e-03,  1.0238e-01,  ...,  2.8003e-01,\n",
      "           1.0296e+00, -9.1871e-02]],\n",
      "\n",
      "        [[ 2.2499e-01,  2.2679e-01, -9.7369e-02,  ...,  3.1162e-01,\n",
      "           5.4782e-02,  3.2754e-01],\n",
      "         [ 3.5536e-01,  1.4777e-01,  4.5789e-01,  ...,  3.4361e-01,\n",
      "           3.8069e-02,  9.0847e-01],\n",
      "         [ 2.8214e-01,  1.7340e-01,  3.6478e-01,  ...,  2.5438e-01,\n",
      "           1.8153e-01,  7.4237e-01],\n",
      "         ...,\n",
      "         [ 4.2941e-01,  1.7001e-01,  4.8060e-01,  ...,  2.4500e-01,\n",
      "           5.2668e-01,  8.7164e-01],\n",
      "         [ 4.2571e-01,  1.8047e-01,  3.2447e-01,  ...,  2.7726e-01,\n",
      "           5.7065e-01,  8.9218e-01],\n",
      "         [ 3.8382e-01,  1.5315e-01,  2.4005e-01,  ...,  3.1564e-01,\n",
      "           5.7542e-01,  9.3489e-01]],\n",
      "\n",
      "        [[ 2.2499e-01,  2.2679e-01, -9.7369e-02,  ...,  3.1162e-01,\n",
      "           5.4782e-02,  3.2754e-01],\n",
      "         [ 3.5536e-01,  1.4777e-01,  4.5789e-01,  ...,  3.4361e-01,\n",
      "           3.8069e-02,  9.0847e-01],\n",
      "         [ 2.8214e-01,  1.7340e-01,  3.6478e-01,  ...,  2.5438e-01,\n",
      "           1.8153e-01,  7.4237e-01],\n",
      "         ...,\n",
      "         [ 4.2941e-01,  1.7001e-01,  4.8060e-01,  ...,  2.4500e-01,\n",
      "           5.2668e-01,  8.7164e-01],\n",
      "         [ 4.2571e-01,  1.8047e-01,  3.2447e-01,  ...,  2.7726e-01,\n",
      "           5.7065e-01,  8.9218e-01],\n",
      "         [ 3.8382e-01,  1.5315e-01,  2.4005e-01,  ...,  3.1564e-01,\n",
      "           5.7542e-01,  9.3489e-01]]]), tensor([[[ 8.9600e-03,  4.3611e-03, -9.9629e-03,  ...,  2.8096e-02,\n",
      "          -5.4153e-02,  1.0457e-01],\n",
      "         [ 1.2331e-01, -1.4334e-01,  4.4988e-01,  ...,  2.2261e-01,\n",
      "          -1.0952e-01,  3.6042e-01],\n",
      "         [ 3.6026e-02, -1.2683e-01,  3.6745e-01,  ...,  1.1459e-01,\n",
      "           4.1378e-02,  2.4709e-01],\n",
      "         ...,\n",
      "         [ 6.8112e-02, -7.4947e-02,  4.0643e-01,  ...,  1.8812e-01,\n",
      "           2.5749e-01,  2.8832e-01],\n",
      "         [ 6.6964e-02, -6.5883e-02,  3.1562e-01,  ...,  2.0343e-01,\n",
      "           2.8107e-01,  2.8803e-01],\n",
      "         [ 4.8935e-02, -5.8867e-02,  2.8122e-01,  ...,  2.2763e-01,\n",
      "           2.8398e-01,  2.8321e-01]],\n",
      "\n",
      "        [[-3.6469e-02,  1.0602e-02, -2.0457e-03,  ...,  1.2131e-02,\n",
      "          -7.9561e-04, -1.5222e-02],\n",
      "         [-5.3589e-02,  2.9798e-01,  4.4390e-01,  ...,  9.6474e-02,\n",
      "          -1.7962e-01,  2.7775e-01],\n",
      "         [-2.4748e-01,  8.3584e-02,  1.3068e-01,  ...,  1.6351e-02,\n",
      "           4.6265e-03, -1.6294e-01],\n",
      "         ...,\n",
      "         [ 4.2906e-02,  1.6557e-01, -3.9785e-02,  ..., -4.6588e-03,\n",
      "           1.8436e-01,  3.1765e-02],\n",
      "         [ 2.9919e-02,  1.4585e-01, -5.9581e-03,  ..., -2.5343e-03,\n",
      "           4.3650e-02,  4.7968e-03],\n",
      "         [ 2.2975e-03,  1.3323e-01, -6.6722e-02,  ...,  3.4239e-03,\n",
      "           1.2987e-01, -5.9970e-02]],\n",
      "\n",
      "        [[-3.7903e-02,  6.2472e-03, -2.6940e-03,  ...,  1.0063e-02,\n",
      "          -2.3382e-03, -1.2711e-02],\n",
      "         [ 2.0017e-02,  2.1240e-01,  2.0011e-01,  ..., -7.8214e-02,\n",
      "          -3.4939e-01,  4.3609e-02],\n",
      "         [-4.6498e-02, -1.6959e-01,  1.2598e-01,  ...,  2.6245e-01,\n",
      "          -8.4623e-02, -4.5808e-02],\n",
      "         ...,\n",
      "         [ 5.7552e-02,  2.0570e-01, -3.2642e-02,  ..., -4.3161e-04,\n",
      "           1.5766e-01, -3.1554e-02],\n",
      "         [ 9.5210e-02,  2.7250e-01, -2.7809e-02,  ..., -5.2264e-02,\n",
      "           2.5420e-01,  5.2642e-02],\n",
      "         [ 1.8179e-01,  1.3543e-01, -7.1767e-02,  ..., -1.6728e-02,\n",
      "           3.8241e-01,  6.4053e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.7319e-02,  8.9188e-03, -8.6839e-04,  ...,  1.1274e-02,\n",
      "          -8.8549e-05, -1.5146e-02],\n",
      "         [ 2.9504e-01,  3.8382e-01,  1.4821e-01,  ...,  7.7610e-02,\n",
      "          -1.8683e-01,  2.6949e-01],\n",
      "         [ 2.8087e-01,  3.2174e-01,  6.4600e-02,  ...,  1.5365e-01,\n",
      "           1.6070e-01, -1.1506e-01],\n",
      "         ...,\n",
      "         [ 2.0545e-01,  2.4647e-01,  7.4164e-03,  ...,  1.3523e-02,\n",
      "           1.6829e-01, -9.7626e-02],\n",
      "         [ 1.4060e-01,  2.0739e-01,  5.0529e-02,  ...,  1.2703e-02,\n",
      "           1.6099e-01, -7.1236e-02],\n",
      "         [ 3.0091e-01,  1.0519e-01,  4.4196e-02,  ...,  7.1789e-02,\n",
      "           4.3323e-01, -1.0955e-01]],\n",
      "\n",
      "        [[ 8.9600e-03,  4.3611e-03, -9.9629e-03,  ...,  2.8096e-02,\n",
      "          -5.4153e-02,  1.0457e-01],\n",
      "         [ 1.2331e-01, -1.4334e-01,  4.4988e-01,  ...,  2.2261e-01,\n",
      "          -1.0952e-01,  3.6042e-01],\n",
      "         [ 3.6026e-02, -1.2683e-01,  3.6745e-01,  ...,  1.1459e-01,\n",
      "           4.1378e-02,  2.4709e-01],\n",
      "         ...,\n",
      "         [ 6.8112e-02, -7.4947e-02,  4.0643e-01,  ...,  1.8812e-01,\n",
      "           2.5749e-01,  2.8832e-01],\n",
      "         [ 6.6964e-02, -6.5883e-02,  3.1562e-01,  ...,  2.0343e-01,\n",
      "           2.8107e-01,  2.8803e-01],\n",
      "         [ 4.8935e-02, -5.8867e-02,  2.8122e-01,  ...,  2.2763e-01,\n",
      "           2.8398e-01,  2.8321e-01]],\n",
      "\n",
      "        [[ 8.9600e-03,  4.3611e-03, -9.9629e-03,  ...,  2.8096e-02,\n",
      "          -5.4153e-02,  1.0457e-01],\n",
      "         [ 1.2331e-01, -1.4334e-01,  4.4988e-01,  ...,  2.2261e-01,\n",
      "          -1.0952e-01,  3.6042e-01],\n",
      "         [ 3.6026e-02, -1.2683e-01,  3.6745e-01,  ...,  1.1459e-01,\n",
      "           4.1378e-02,  2.4709e-01],\n",
      "         ...,\n",
      "         [ 6.8112e-02, -7.4947e-02,  4.0643e-01,  ...,  1.8812e-01,\n",
      "           2.5749e-01,  2.8832e-01],\n",
      "         [ 6.6964e-02, -6.5883e-02,  3.1562e-01,  ...,  2.0343e-01,\n",
      "           2.8107e-01,  2.8803e-01],\n",
      "         [ 4.8935e-02, -5.8867e-02,  2.8122e-01,  ...,  2.2763e-01,\n",
      "           2.8398e-01,  2.8321e-01]]])), encoder_attentions=None)\n",
      "seg_num: 2\n",
      "batch_size: 32\n",
      "non_empty_mask: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "s: torch.Size([512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "input_ids: torch.Size([32, 512])\n",
      "batch_size: 32\n",
      "decoder_input_ids: None\n",
      "prefix_tokens: torch.Size([20])\n",
      "out: Seq2SeqLMOutput(loss=tensor(18.3547, grad_fn=<NllLossBackward0>), logits=tensor([[[-2.7372e-01, -2.6621e+00,  6.8021e+00,  ..., -2.6111e+00,\n",
      "          -2.2680e+00,  4.5636e-01],\n",
      "         [-2.6096e+00, -3.2056e+00,  5.1406e+00,  ..., -3.0199e+00,\n",
      "          -2.5532e+00,  4.8949e-01],\n",
      "         [-3.8655e+00, -3.4071e+00,  4.5445e+00,  ..., -3.2767e+00,\n",
      "          -2.7992e+00,  5.6797e-01],\n",
      "         ...,\n",
      "         [-5.2759e+00, -4.0671e+00,  7.0381e+00,  ..., -3.3484e+00,\n",
      "          -3.1762e+00,  1.1438e+00],\n",
      "         [-5.5619e+00, -4.1406e+00,  6.9741e+00,  ..., -3.4027e+00,\n",
      "          -3.2531e+00,  1.2309e+00],\n",
      "         [-5.5131e+00, -4.1239e+00,  6.9613e+00,  ..., -3.3804e+00,\n",
      "          -3.2204e+00,  1.2053e+00]],\n",
      "\n",
      "        [[ 3.2625e-01, -2.8665e+00,  7.2224e+00,  ..., -2.9418e+00,\n",
      "          -3.0229e+00,  1.1091e+00],\n",
      "         [-2.6015e+00, -2.9506e+00,  6.6317e+00,  ..., -3.3253e+00,\n",
      "          -3.3106e+00,  7.2857e-01],\n",
      "         [-6.1690e+00, -3.4035e+00,  5.0988e+00,  ..., -3.9796e+00,\n",
      "          -3.9706e+00,  6.1340e-03],\n",
      "         ...,\n",
      "         [-2.1828e+00, -1.9874e+00,  2.0787e+01,  ..., -1.5936e+00,\n",
      "          -1.8903e+00, -1.6359e+00],\n",
      "         [-3.5354e+00, -1.9964e+00,  2.0167e+01,  ..., -1.8412e+00,\n",
      "          -2.2321e+00, -1.6050e+00],\n",
      "         [-5.3872e+00, -2.6443e+00,  1.8530e+01,  ..., -2.0277e+00,\n",
      "          -2.5794e+00, -2.4289e+00]],\n",
      "\n",
      "        [[-5.8718e+00, -3.3857e+00,  2.2216e+00,  ..., -2.9506e+00,\n",
      "          -2.2554e+00, -5.1961e-01],\n",
      "         [-5.2225e+00, -3.0998e+00,  2.6547e+00,  ..., -2.6538e+00,\n",
      "          -1.8735e+00,  7.0740e-01],\n",
      "         [-6.1843e+00, -3.4037e+00,  2.2192e+00,  ..., -3.0048e+00,\n",
      "          -2.2764e+00,  1.1422e+00],\n",
      "         ...,\n",
      "         [-7.0964e+00, -4.0486e+00,  4.5168e+00,  ..., -3.5970e+00,\n",
      "          -2.9528e+00,  7.6984e-01],\n",
      "         [-7.6441e+00, -4.1838e+00,  4.2389e+00,  ..., -3.7546e+00,\n",
      "          -3.1222e+00,  7.7980e-01],\n",
      "         [-7.7346e+00, -4.2064e+00,  4.4837e+00,  ..., -3.7724e+00,\n",
      "          -3.1533e+00,  7.4610e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.9041e-01, -4.1543e+00,  5.1121e+00,  ..., -4.3596e+00,\n",
      "          -4.8230e+00, -1.1746e+00],\n",
      "         [-1.3676e+00, -3.9059e+00,  5.6281e+00,  ..., -4.3051e+00,\n",
      "          -4.7825e+00, -3.9357e-01],\n",
      "         [-4.2795e-01, -3.2795e+00,  6.1828e+00,  ..., -3.5411e+00,\n",
      "          -3.9146e+00,  8.2614e-01],\n",
      "         ...,\n",
      "         [-5.0862e+00, -2.7336e+00,  1.4324e+01,  ..., -1.9786e+00,\n",
      "          -2.3493e+00, -1.5529e+00],\n",
      "         [-6.5629e+00, -2.7752e+00,  1.2177e+01,  ..., -1.7191e+00,\n",
      "          -2.4300e+00, -1.5207e+00],\n",
      "         [-1.4998e+01, -3.6163e+00,  5.9863e+00,  ..., -2.2224e+00,\n",
      "          -2.9651e+00, -1.9060e+00]],\n",
      "\n",
      "        [[-6.4367e+00, -4.4011e+00,  2.8527e+00,  ..., -3.7690e+00,\n",
      "          -3.4894e+00, -6.0663e-01],\n",
      "         [-6.8198e+00, -4.0454e+00,  1.7938e+00,  ..., -3.3510e+00,\n",
      "          -2.7199e+00,  1.0118e+00],\n",
      "         [-7.9590e+00, -4.1609e+00,  1.2049e+00,  ..., -3.4815e+00,\n",
      "          -2.8672e+00,  1.2281e+00],\n",
      "         ...,\n",
      "         [-5.4129e+00, -4.2888e+00,  6.6210e+00,  ..., -3.4453e+00,\n",
      "          -3.5837e+00,  9.7255e-01],\n",
      "         [-5.6887e+00, -4.3598e+00,  6.4814e+00,  ..., -3.5196e+00,\n",
      "          -3.6499e+00,  9.8167e-01],\n",
      "         [-6.0175e+00, -4.4328e+00,  6.3166e+00,  ..., -3.6174e+00,\n",
      "          -3.7095e+00,  8.7849e-01]],\n",
      "\n",
      "        [[-4.5328e+00, -3.5488e+00,  2.8639e+00,  ..., -2.8757e+00,\n",
      "          -2.6750e+00, -9.9918e-02],\n",
      "         [-5.7014e+00, -3.6982e+00,  8.6225e-01,  ..., -2.8481e+00,\n",
      "          -2.5809e+00,  3.6030e-01],\n",
      "         [-6.8790e+00, -3.9121e+00,  3.2811e-01,  ..., -3.0765e+00,\n",
      "          -2.8139e+00,  6.4618e-01],\n",
      "         ...,\n",
      "         [-5.6216e+00, -3.7887e+00,  6.5111e+00,  ..., -3.0807e+00,\n",
      "          -2.8322e+00,  1.4078e+00],\n",
      "         [-6.3111e+00, -4.0071e+00,  6.0926e+00,  ..., -3.3171e+00,\n",
      "          -3.1028e+00,  1.3719e+00],\n",
      "         [-6.6559e+00, -4.1011e+00,  6.0062e+00,  ..., -3.4098e+00,\n",
      "          -3.1844e+00,  1.3328e+00]]], grad_fn=<AddBackward0>), past_key_values=None, decoder_hidden_states=(tensor([[[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.0294,  0.2074,  0.0431,  ..., -0.2617,  0.1940,  0.1261],\n",
      "         [-0.0132,  0.2832, -0.0114,  ..., -0.3147,  0.3118,  0.0943],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [ 0.5675, -0.1371,  0.0697,  ...,  0.1330,  0.0706,  0.1900],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.0294,  0.2074,  0.0431,  ..., -0.2617,  0.1940,  0.1261],\n",
      "         [-0.0132,  0.2832, -0.0114,  ..., -0.3147,  0.3118,  0.0943],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.5995, -0.1868,  0.1044,  ...,  0.1692, -0.0029,  0.2117],\n",
      "         [ 0.5675, -0.1371,  0.0697,  ...,  0.1330,  0.0706,  0.1900],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.0294,  0.2074,  0.0431,  ..., -0.2617,  0.1940,  0.1261],\n",
      "         [-0.0132,  0.2832, -0.0114,  ..., -0.3147,  0.3118,  0.0943],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]],\n",
      "\n",
      "        [[ 0.5449, -0.2041,  0.1186,  ...,  0.2692, -0.1195,  0.1970],\n",
      "         [ 0.0294,  0.2074,  0.0431,  ..., -0.2617,  0.1940,  0.1261],\n",
      "         [-0.0132,  0.2832, -0.0114,  ..., -0.3147,  0.3118,  0.0943],\n",
      "         ...,\n",
      "         [ 0.3573,  0.1429,  0.0452,  ..., -0.0938, -0.0274, -0.2304],\n",
      "         [ 0.1478, -0.0411,  0.0663,  ...,  0.1433, -0.3320, -0.3015],\n",
      "         [ 0.2818, -0.2390,  0.0031,  ...,  0.2148, -0.6556, -0.2994]]]), tensor([[[-0.0604,  0.0849, -0.3379,  ..., -0.3935,  0.0631,  0.0079],\n",
      "         [-0.1065,  0.0645, -0.0589,  ..., -0.4074,  0.0305, -0.1824],\n",
      "         [-0.0752,  0.2894, -0.0658,  ..., -0.2668,  0.3313,  0.0221],\n",
      "         ...,\n",
      "         [ 0.0703,  0.1316,  0.0326,  ...,  0.2879, -0.0312,  0.1068],\n",
      "         [ 0.0894,  0.1638,  0.0602,  ...,  0.4263, -0.2880,  0.1096],\n",
      "         [ 0.1223, -0.0328,  0.0307,  ...,  0.5535, -0.6222,  0.1447]],\n",
      "\n",
      "        [[ 0.6178,  0.1105, -0.2975,  ..., -0.0427, -0.1425,  0.1710],\n",
      "         [ 0.5308,  0.0567, -0.1930,  ..., -0.3155, -0.2570,  0.0842],\n",
      "         [ 0.5456,  0.0539, -0.1624,  ..., -0.3887, -0.2111,  0.0260],\n",
      "         ...,\n",
      "         [ 0.3436, -0.1698,  0.3586,  ...,  0.2554, -0.1285, -0.1229],\n",
      "         [ 0.2787, -0.1751,  0.3586,  ...,  0.4329, -0.3015, -0.2008],\n",
      "         [ 0.3173, -0.2757,  0.2647,  ...,  0.5362, -0.5844, -0.1079]],\n",
      "\n",
      "        [[ 0.3097, -0.0707, -0.6629,  ..., -0.1541, -0.1078,  0.0137],\n",
      "         [-0.0716,  0.0307,  0.0261,  ..., -0.3920, -0.1254, -0.1845],\n",
      "         [-0.0431,  0.2581, -0.0105,  ..., -0.2363,  0.2111,  0.0358],\n",
      "         ...,\n",
      "         [ 0.0766,  0.1250,  0.0386,  ...,  0.2939, -0.0491,  0.1009],\n",
      "         [ 0.0907,  0.1578,  0.0652,  ...,  0.4337, -0.3034,  0.1039],\n",
      "         [ 0.1263, -0.0376,  0.0384,  ...,  0.5605, -0.6423,  0.1362]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9692, -0.0207, -0.2501,  ..., -0.0468, -0.1191,  0.3242],\n",
      "         [ 0.8931, -0.0677, -0.1278,  ..., -0.2027, -0.1531,  0.2274],\n",
      "         [ 0.8068, -0.0558, -0.0880,  ..., -0.2566, -0.1064,  0.1763],\n",
      "         ...,\n",
      "         [ 0.3425, -0.1546,  0.3271,  ...,  0.2841, -0.1599, -0.1169],\n",
      "         [ 0.2530, -0.1459,  0.3149,  ...,  0.4405, -0.2971, -0.1923],\n",
      "         [ 0.3064, -0.2541,  0.2363,  ...,  0.5318, -0.5720, -0.1124]],\n",
      "\n",
      "        [[ 0.1412,  0.1662, -0.4040,  ..., -0.4043, -0.0890, -0.0689],\n",
      "         [-0.0801,  0.0314, -0.0414,  ..., -0.3879, -0.0770, -0.2988],\n",
      "         [-0.0614,  0.2408, -0.0675,  ..., -0.2019,  0.2479, -0.0614],\n",
      "         ...,\n",
      "         [ 0.0717,  0.1281,  0.0434,  ...,  0.2890, -0.0378,  0.0988],\n",
      "         [ 0.0909,  0.1627,  0.0705,  ...,  0.4290, -0.2940,  0.1023],\n",
      "         [ 0.1242, -0.0326,  0.0422,  ...,  0.5575, -0.6277,  0.1366]],\n",
      "\n",
      "        [[ 0.0478, -0.1701, -0.4804,  ..., -0.3584, -0.4044,  0.0575],\n",
      "         [-0.0304,  0.0203, -0.0535,  ..., -0.4354, -0.0960, -0.2268],\n",
      "         [ 0.0059,  0.2683, -0.0685,  ..., -0.2831,  0.2147, -0.0157],\n",
      "         ...,\n",
      "         [ 0.0693,  0.1260,  0.0341,  ...,  0.2820, -0.0471,  0.1013],\n",
      "         [ 0.0863,  0.1594,  0.0612,  ...,  0.4201, -0.3016,  0.1069],\n",
      "         [ 0.1225, -0.0381,  0.0336,  ...,  0.5469, -0.6395,  0.1391]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-2.4874e-01,  4.3396e-01, -1.4518e-01,  ..., -1.9358e-01,\n",
      "          -1.7458e-01,  2.0604e-01],\n",
      "         [-2.8799e-01,  3.1770e-01, -3.4289e-02,  ..., -2.2210e-01,\n",
      "          -1.3547e-01,  3.0242e-01],\n",
      "         [ 1.4179e-02,  1.8238e-01, -3.4835e-02,  ..., -1.9088e-01,\n",
      "          -1.2877e-02,  4.1125e-01],\n",
      "         ...,\n",
      "         [ 1.2776e-01,  1.1368e-01,  1.8489e-02,  ...,  1.5146e-01,\n",
      "          -9.8808e-02,  2.6000e-01],\n",
      "         [ 6.7609e-02,  2.0320e-01,  3.4924e-02,  ...,  9.6279e-02,\n",
      "          -8.6006e-02,  2.4745e-01],\n",
      "         [ 1.0328e-01,  6.8600e-02, -2.3654e-02,  ..., -2.7800e-02,\n",
      "          -1.6313e-01,  1.2265e-01]],\n",
      "\n",
      "        [[ 3.5052e-01,  3.7609e-01, -6.4419e-01,  ...,  1.5112e-02,\n",
      "          -2.3132e-01,  2.6464e-01],\n",
      "         [ 1.9650e-01,  5.1625e-01, -4.7835e-01,  ..., -5.8771e-02,\n",
      "          -3.0113e-01,  2.4668e-01],\n",
      "         [ 1.0494e-01,  5.4576e-01, -4.5168e-01,  ..., -9.0613e-02,\n",
      "          -1.9219e-01,  2.7529e-01],\n",
      "         ...,\n",
      "         [-8.5673e-02, -2.4892e-01,  2.8756e-01,  ...,  8.8820e-02,\n",
      "          -2.4603e-02, -5.6349e-02],\n",
      "         [-1.0158e-01, -1.3955e-01,  2.4412e-01,  ...,  1.2227e-01,\n",
      "           4.6474e-03, -1.6800e-02],\n",
      "         [-1.0600e-01,  1.7924e-02,  4.9682e-03,  ...,  2.0551e-01,\n",
      "          -1.5444e-01,  2.2358e-01]],\n",
      "\n",
      "        [[ 2.0098e-01,  4.5200e-01, -3.4683e-01,  ..., -1.8331e-01,\n",
      "          -1.0967e-01,  1.8173e-01],\n",
      "         [-8.3277e-02,  2.7737e-01,  4.2443e-02,  ..., -3.7714e-01,\n",
      "          -1.3967e-01,  4.8171e-01],\n",
      "         [-4.1131e-03,  2.6673e-01,  7.2382e-02,  ..., -2.1714e-01,\n",
      "           1.4189e-02,  7.0680e-01],\n",
      "         ...,\n",
      "         [ 1.7714e-01,  1.5828e-01, -1.9311e-02,  ...,  1.4098e-01,\n",
      "          -1.9288e-01,  4.6590e-01],\n",
      "         [ 1.9605e-01,  2.5766e-01,  1.8321e-02,  ...,  1.3410e-01,\n",
      "          -2.0639e-01,  4.2105e-01],\n",
      "         [ 1.2696e-01,  2.4513e-01, -5.0935e-02,  ...,  7.1717e-02,\n",
      "          -1.7684e-01,  4.3754e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0758e-01,  2.5539e-01, -1.8748e-01,  ..., -4.8362e-01,\n",
      "          -6.1574e-01,  3.1539e-04],\n",
      "         [ 7.0832e-02,  3.2642e-01, -3.0036e-02,  ..., -4.9575e-01,\n",
      "          -6.5082e-01, -1.1471e-03],\n",
      "         [-7.0743e-02,  3.3903e-01, -1.8476e-02,  ..., -5.4804e-01,\n",
      "          -6.0298e-01,  9.1127e-03],\n",
      "         ...,\n",
      "         [-3.3803e-02, -2.2235e-01,  1.9101e-01,  ...,  1.6389e-01,\n",
      "          -2.6288e-01,  1.5299e-02],\n",
      "         [-5.2603e-02, -6.3459e-02,  1.0733e-01,  ...,  2.0530e-01,\n",
      "          -3.6588e-01,  8.5537e-02],\n",
      "         [ 2.0994e-03, -1.0272e-01,  6.8021e-02,  ...,  1.9253e-01,\n",
      "          -4.7898e-01,  1.2473e-01]],\n",
      "\n",
      "        [[ 7.1461e-02,  4.9365e-01, -4.0196e-01,  ..., -1.2717e-01,\n",
      "          -2.1578e-01,  2.1487e-01],\n",
      "         [-6.2799e-02,  3.6500e-01, -1.8982e-01,  ..., -2.8399e-01,\n",
      "          -9.6601e-02,  3.8617e-01],\n",
      "         [-4.1881e-02,  2.6977e-01, -1.2854e-01,  ..., -2.0123e-01,\n",
      "           1.3061e-02,  5.5511e-01],\n",
      "         ...,\n",
      "         [ 2.2150e-01,  1.6831e-01, -4.3017e-02,  ...,  1.8551e-01,\n",
      "          -7.7022e-02,  3.5850e-01],\n",
      "         [ 2.1984e-01,  2.7194e-01, -6.6834e-02,  ...,  2.0196e-01,\n",
      "          -1.3250e-01,  3.5577e-01],\n",
      "         [ 1.8971e-01,  1.9993e-01, -1.4617e-01,  ...,  9.8772e-02,\n",
      "          -1.4687e-01,  4.0638e-01]],\n",
      "\n",
      "        [[-1.5230e-01,  3.4714e-01, -2.6949e-01,  ..., -3.2828e-01,\n",
      "          -2.6462e-01,  3.0640e-01],\n",
      "         [-1.7365e-01,  3.2664e-01, -6.2878e-02,  ..., -2.8816e-01,\n",
      "          -2.6699e-01,  4.5875e-01],\n",
      "         [-6.6180e-02,  2.4659e-01, -4.4579e-02,  ..., -1.5722e-01,\n",
      "          -1.0552e-01,  5.1618e-01],\n",
      "         ...,\n",
      "         [ 1.6075e-01,  1.0455e-01, -4.7717e-02,  ...,  1.5964e-01,\n",
      "          -1.2895e-01,  4.2038e-01],\n",
      "         [ 1.5239e-01,  2.0906e-01, -1.1619e-02,  ...,  1.1365e-01,\n",
      "          -1.8395e-01,  4.3814e-01],\n",
      "         [ 1.5267e-01,  1.1064e-01,  5.1890e-03,  ...,  3.2557e-03,\n",
      "          -1.9170e-01,  4.4283e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0854,  0.8892,  0.2457,  ...,  0.2606,  0.4726, -0.4965],\n",
      "         [-0.1103,  0.4740,  0.0873,  ...,  0.2830,  0.4426, -0.3942],\n",
      "         [-0.0268,  0.3636,  0.1055,  ...,  0.0980,  0.3622, -0.4123],\n",
      "         ...,\n",
      "         [-0.2995,  0.6984,  0.3000,  ...,  0.4055,  0.1095, -0.2250],\n",
      "         [-0.3224,  0.6662,  0.3252,  ...,  0.3922,  0.1190, -0.2147],\n",
      "         [-0.2508,  0.5763,  0.3216,  ...,  0.3720,  0.0970, -0.2588]],\n",
      "\n",
      "        [[-0.1624,  0.6661, -0.2837,  ...,  0.5698,  0.0447,  0.0530],\n",
      "         [-0.3197,  0.8086, -0.2025,  ...,  0.6256,  0.0460,  0.1429],\n",
      "         [-0.4558,  0.7879, -0.2810,  ...,  0.6093,  0.0762,  0.2149],\n",
      "         ...,\n",
      "         [-0.3657, -0.1571, -0.1661,  ..., -0.3696, -0.5525,  0.2446],\n",
      "         [-0.3586, -0.1196, -0.2270,  ..., -0.3046, -0.5242,  0.2208],\n",
      "         [-0.4266,  0.0426, -0.3407,  ..., -0.1426, -0.5277,  0.3106]],\n",
      "\n",
      "        [[-0.2697,  0.7434,  0.0472,  ...,  0.2942,  0.5042,  0.1052],\n",
      "         [-0.2237,  0.4630,  0.0660,  ...,  0.4022,  0.3890,  0.1708],\n",
      "         [-0.2272,  0.4644,  0.0322,  ...,  0.3316,  0.3436,  0.2031],\n",
      "         ...,\n",
      "         [ 0.0757,  0.3753,  0.2854,  ...,  0.3280,  0.3174, -0.0039],\n",
      "         [ 0.0321,  0.4074,  0.2805,  ...,  0.3179,  0.2455,  0.0129],\n",
      "         [ 0.0172,  0.3982,  0.3209,  ...,  0.2771,  0.1972,  0.0677]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5114,  0.4100, -0.2954,  ..., -0.1365,  0.0921,  0.0727],\n",
      "         [-0.5935,  0.4161, -0.1980,  ..., -0.1876,  0.1103,  0.1761],\n",
      "         [-0.6041,  0.4453, -0.3194,  ..., -0.2869,  0.1162,  0.1069],\n",
      "         ...,\n",
      "         [-0.2747, -0.1730, -0.3598,  ..., -0.4072, -0.5370,  0.2411],\n",
      "         [-0.2876, -0.0319, -0.4037,  ..., -0.3113, -0.5567,  0.2204],\n",
      "         [-0.3667, -0.0934, -0.4251,  ..., -0.2822, -0.5756,  0.1975]],\n",
      "\n",
      "        [[-0.2178,  0.6006,  0.2744,  ...,  0.2243,  0.4084, -0.0130],\n",
      "         [-0.0277,  0.4049,  0.0227,  ...,  0.2718,  0.2654, -0.0564],\n",
      "         [-0.0965,  0.3292,  0.0078,  ...,  0.1903,  0.2454, -0.0744],\n",
      "         ...,\n",
      "         [-0.0595,  0.3553,  0.2622,  ...,  0.5433,  0.3515, -0.0329],\n",
      "         [-0.0568,  0.3603,  0.2512,  ...,  0.5633,  0.2412, -0.0098],\n",
      "         [-0.0574,  0.3119,  0.2171,  ...,  0.5043,  0.1751,  0.0009]],\n",
      "\n",
      "        [[-0.1727,  0.4670,  0.1679,  ...,  0.0374,  0.3649, -0.3077],\n",
      "         [-0.0611,  0.2485,  0.0028,  ...,  0.1674,  0.2880, -0.2021],\n",
      "         [ 0.0215,  0.2121, -0.1024,  ...,  0.1614,  0.1842, -0.1420],\n",
      "         ...,\n",
      "         [-0.1015,  0.5181,  0.4773,  ...,  0.5939,  0.3184,  0.0828],\n",
      "         [-0.1161,  0.5080,  0.5273,  ...,  0.5694,  0.2562,  0.1074],\n",
      "         [-0.1139,  0.4316,  0.5010,  ...,  0.4865,  0.2929,  0.0955]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0133,  0.8397,  0.2911,  ..., -0.1556, -0.3060, -0.5211],\n",
      "         [-0.1616,  0.6109,  0.2066,  ..., -0.1155, -0.2944, -0.5696],\n",
      "         [-0.0680,  0.5676,  0.2986,  ..., -0.2069, -0.2732, -0.6110],\n",
      "         ...,\n",
      "         [-0.0775,  0.9774,  0.2687,  ..., -0.5496, -0.2220, -0.4169],\n",
      "         [-0.0511,  0.9747,  0.2956,  ..., -0.5236, -0.2207, -0.4430],\n",
      "         [-0.0373,  0.9314,  0.2804,  ..., -0.5095, -0.2030, -0.4982]],\n",
      "\n",
      "        [[ 0.2463,  0.8166, -0.2601,  ...,  0.3903, -0.4383, -0.3353],\n",
      "         [ 0.3029,  0.9055, -0.1156,  ...,  0.2545, -0.4610, -0.2114],\n",
      "         [ 0.1894,  0.9676, -0.1483,  ...,  0.1419, -0.4508, -0.0611],\n",
      "         ...,\n",
      "         [-0.3916, -0.2679, -0.2677,  ..., -0.3441, -0.5090,  0.3903],\n",
      "         [-0.3486, -0.2749, -0.3251,  ..., -0.3553, -0.5117,  0.2999],\n",
      "         [-0.4154, -0.1852, -0.4655,  ..., -0.3047, -0.4996,  0.3536]],\n",
      "\n",
      "        [[-0.0963,  1.0437,  0.0834,  ...,  0.0717, -0.2242, -0.2927],\n",
      "         [-0.1427,  0.7893,  0.0452,  ...,  0.1796, -0.2578, -0.4228],\n",
      "         [-0.0850,  0.8368,  0.0623,  ...,  0.0471, -0.2447, -0.4212],\n",
      "         ...,\n",
      "         [ 0.1357,  0.9849,  0.0049,  ..., -0.1267, -0.1310, -0.3548],\n",
      "         [ 0.1449,  1.0150,  0.0259,  ..., -0.1417, -0.1342, -0.3820],\n",
      "         [ 0.1516,  1.0055,  0.0511,  ..., -0.1653, -0.1252, -0.4152]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0370,  0.7798, -0.3645,  ...,  0.4092, -0.3330, -0.6383],\n",
      "         [ 0.0410,  0.7457, -0.3545,  ...,  0.3927, -0.3604, -0.5417],\n",
      "         [-0.0181,  0.6613, -0.4824,  ...,  0.2104, -0.3465, -0.5905],\n",
      "         ...,\n",
      "         [-0.2936, -0.5213, -0.4295,  ..., -0.4560, -0.4683,  0.1469],\n",
      "         [-0.2020, -0.4032, -0.4217,  ..., -0.4546, -0.4815,  0.0736],\n",
      "         [-0.2588, -0.5414, -0.5200,  ..., -0.4766, -0.4660,  0.1542]],\n",
      "\n",
      "        [[ 0.0619,  1.1985,  0.3369,  ..., -0.1622, -0.1566, -0.4132],\n",
      "         [ 0.1619,  0.8528,  0.1969,  ..., -0.1345, -0.1718, -0.5449],\n",
      "         [ 0.1341,  0.7867,  0.2008,  ..., -0.1777, -0.1638, -0.5373],\n",
      "         ...,\n",
      "         [ 0.0552,  0.7760,  0.1655,  ..., -0.1177, -0.1910, -0.6613],\n",
      "         [ 0.1095,  0.7933,  0.1655,  ..., -0.1023, -0.2017, -0.6428],\n",
      "         [ 0.1100,  0.7969,  0.1211,  ..., -0.1519, -0.1988, -0.6321]],\n",
      "\n",
      "        [[-0.0060,  0.6977,  0.2623,  ..., -0.1295, -0.2065, -0.6016],\n",
      "         [-0.0892,  0.5866,  0.1257,  ..., -0.0465, -0.2008, -0.6665],\n",
      "         [-0.0226,  0.5404,  0.1913,  ..., -0.0663, -0.2022, -0.6818],\n",
      "         ...,\n",
      "         [ 0.0110,  0.8423,  0.3313,  ..., -0.0253, -0.2170, -0.6015],\n",
      "         [ 0.0295,  0.8789,  0.3549,  ..., -0.0347, -0.2194, -0.5871],\n",
      "         [ 0.0154,  0.8540,  0.3300,  ..., -0.1135, -0.2093, -0.5834]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 1.1083e-01,  1.0004e+00,  1.1067e-01,  ...,  4.0377e-01,\n",
      "           1.5605e-01, -3.8286e-01],\n",
      "         [ 1.7106e-02,  7.9026e-01,  1.4020e-02,  ...,  2.5469e-01,\n",
      "           1.1896e-01, -2.5250e-01],\n",
      "         [ 1.2333e-01,  7.5745e-01,  6.3186e-02,  ...,  1.9449e-01,\n",
      "           1.0501e-01, -2.9657e-01],\n",
      "         ...,\n",
      "         [-2.0626e-01,  1.0211e+00,  3.5124e-01,  ..., -5.0417e-02,\n",
      "           2.2120e-01, -4.7726e-02],\n",
      "         [-2.0712e-01,  1.0241e+00,  3.6311e-01,  ..., -5.1343e-02,\n",
      "           2.1562e-01, -7.4165e-02],\n",
      "         [-1.8908e-01,  1.0077e+00,  3.6548e-01,  ..., -4.5856e-02,\n",
      "           2.2139e-01, -6.6942e-02]],\n",
      "\n",
      "        [[-3.2367e-02,  9.1210e-01, -6.4092e-01,  ..., -1.2274e-01,\n",
      "          -3.4516e-02,  7.7151e-02],\n",
      "         [ 2.9715e-04,  9.4452e-01, -4.3920e-01,  ..., -7.2151e-02,\n",
      "          -4.7827e-02,  8.1101e-02],\n",
      "         [ 1.2379e-02,  1.0030e+00, -4.4613e-01,  ...,  2.9049e-02,\n",
      "          -4.1349e-02,  4.8504e-02],\n",
      "         ...,\n",
      "         [-4.1448e-01, -1.4457e-01, -4.3851e-01,  ..., -3.6972e-01,\n",
      "          -1.7846e-01,  7.2213e-01],\n",
      "         [-4.0452e-01, -1.7816e-01, -5.0889e-01,  ..., -3.5893e-01,\n",
      "          -1.8777e-01,  6.1602e-01],\n",
      "         [-4.7535e-01, -1.1247e-01, -6.9375e-01,  ..., -3.4708e-01,\n",
      "          -1.3029e-01,  5.4719e-01]],\n",
      "\n",
      "        [[ 3.3986e-01,  1.1917e+00,  1.8494e-01,  ...,  7.6803e-01,\n",
      "           1.6015e-01, -2.0523e-01],\n",
      "         [ 1.6227e-01,  9.0234e-01,  1.5076e-01,  ...,  7.4470e-01,\n",
      "           9.0129e-02, -9.9595e-02],\n",
      "         [ 2.1666e-01,  9.5334e-01,  1.8218e-01,  ...,  6.7434e-01,\n",
      "           4.4023e-02, -8.1551e-02],\n",
      "         ...,\n",
      "         [ 2.8384e-01,  1.2429e+00,  2.3348e-01,  ...,  3.5360e-01,\n",
      "           1.8132e-01, -3.1885e-01],\n",
      "         [ 2.9225e-01,  1.2368e+00,  2.0736e-01,  ...,  3.4800e-01,\n",
      "           1.7786e-01, -3.6229e-01],\n",
      "         [ 2.9150e-01,  1.2114e+00,  1.9662e-01,  ...,  3.2033e-01,\n",
      "           1.8725e-01, -3.4991e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.4543e-01,  4.8328e-01, -9.0611e-01,  ...,  4.2592e-01,\n",
      "           1.2018e-01,  3.1690e-01],\n",
      "         [ 2.8381e-01,  3.9725e-01, -6.9081e-01,  ...,  4.4530e-01,\n",
      "           1.0252e-01,  3.9855e-01],\n",
      "         [ 2.2444e-01,  3.1198e-01, -6.4780e-01,  ...,  3.7197e-01,\n",
      "           1.1402e-01,  4.1366e-01],\n",
      "         ...,\n",
      "         [-2.2619e-01, -4.0615e-01, -6.4742e-01,  ..., -3.5977e-01,\n",
      "          -2.5369e-01,  5.6173e-01],\n",
      "         [-2.0797e-01, -2.6084e-01, -6.5201e-01,  ..., -3.6574e-01,\n",
      "          -2.5925e-01,  4.9836e-01],\n",
      "         [-2.8063e-01, -3.8248e-01, -8.5057e-01,  ..., -3.9574e-01,\n",
      "          -1.6652e-01,  3.9222e-01]],\n",
      "\n",
      "        [[ 2.4725e-01,  1.3729e+00,  1.1885e-01,  ...,  2.4692e-01,\n",
      "           2.2584e-01, -5.1304e-01],\n",
      "         [ 2.4786e-01,  1.0845e+00,  9.3212e-02,  ...,  2.2780e-01,\n",
      "           2.0016e-01, -4.2580e-01],\n",
      "         [ 2.2294e-01,  1.0302e+00,  8.4259e-02,  ...,  2.1064e-01,\n",
      "           1.8669e-01, -4.3110e-01],\n",
      "         ...,\n",
      "         [ 1.0585e-01,  1.1711e+00,  3.0911e-01,  ...,  3.7341e-03,\n",
      "           1.6433e-01, -4.0547e-01],\n",
      "         [ 1.4402e-01,  1.1701e+00,  3.0128e-01,  ...,  8.2396e-03,\n",
      "           1.5335e-01, -4.3752e-01],\n",
      "         [ 1.4644e-01,  1.1384e+00,  2.6636e-01,  ..., -1.8770e-02,\n",
      "           1.5228e-01, -4.3289e-01]],\n",
      "\n",
      "        [[ 2.2551e-01,  1.0524e+00,  6.9541e-02,  ...,  4.4893e-01,\n",
      "           1.8575e-01, -4.5121e-01],\n",
      "         [ 7.7416e-02,  9.0602e-01, -6.3553e-02,  ...,  3.8509e-01,\n",
      "           1.1393e-01, -5.2341e-01],\n",
      "         [ 1.2203e-01,  8.6936e-01, -2.1911e-02,  ...,  3.8562e-01,\n",
      "           9.0478e-02, -5.5140e-01],\n",
      "         ...,\n",
      "         [ 1.0747e-01,  1.1613e+00,  2.7412e-01,  ...,  2.3944e-01,\n",
      "           1.6091e-01, -9.7927e-02],\n",
      "         [ 1.1216e-01,  1.1653e+00,  2.8009e-01,  ...,  2.1003e-01,\n",
      "           1.5179e-01, -1.2553e-01],\n",
      "         [ 1.0046e-01,  1.1367e+00,  2.6589e-01,  ...,  1.7557e-01,\n",
      "           1.4866e-01, -1.2594e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.3654,  3.0350,  0.9608,  ...,  3.9031,  3.6207, -2.4139],\n",
      "         [-0.7420,  2.8646,  0.9608,  ...,  3.7912,  2.8729, -1.6424],\n",
      "         [-0.4565,  2.7580,  1.2176,  ...,  3.6964,  2.8640, -1.6574],\n",
      "         ...,\n",
      "         [-1.2694,  2.2337,  2.1802,  ...,  0.7444,  3.6031, -2.4910],\n",
      "         [-1.2456,  2.2377,  2.2483,  ...,  0.7713,  3.5778, -2.4825],\n",
      "         [-1.2232,  2.2390,  2.3072,  ...,  0.8011,  3.6141, -2.4333]],\n",
      "\n",
      "        [[ 3.3524,  2.8704,  0.5294,  ...,  1.5920,  4.1897, -1.5494],\n",
      "         [ 3.2583,  2.3860,  0.3630,  ...,  1.4638,  4.4408, -1.5279],\n",
      "         [ 2.4175,  2.2616, -0.0262,  ...,  1.6177,  4.8530, -1.5023],\n",
      "         ...,\n",
      "         [ 1.3212, -1.2909, -1.4934,  ..., -0.8339, -0.6404,  2.5300],\n",
      "         [ 1.4676, -1.2934, -1.9474,  ..., -0.7274, -0.7555,  2.5331],\n",
      "         [ 1.0889, -0.8891, -2.7627,  ..., -0.4528, -0.2713,  2.1472]],\n",
      "\n",
      "        [[ 0.3314,  2.9968,  2.3529,  ...,  4.6453,  3.1106, -1.7564],\n",
      "         [-0.7875,  2.5716,  2.2425,  ...,  4.7801,  2.4373, -1.3970],\n",
      "         [-0.7400,  2.8329,  2.2592,  ...,  4.5765,  2.2784, -1.2475],\n",
      "         ...,\n",
      "         [ 0.2564,  2.9422,  2.2102,  ...,  2.3111,  3.0041, -2.1521],\n",
      "         [ 0.2729,  2.9419,  2.2175,  ...,  2.2994,  2.9645, -2.2020],\n",
      "         [ 0.2130,  2.8476,  2.1262,  ...,  2.1784,  3.0921, -2.2224]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.8840,  1.3744, -0.2691,  ...,  1.7226,  3.4239, -0.6125],\n",
      "         [ 3.4317,  1.2924, -0.1642,  ...,  1.7843,  3.2859, -0.2496],\n",
      "         [ 3.0804,  1.3847, -0.3362,  ...,  1.8778,  3.6933, -0.3853],\n",
      "         ...,\n",
      "         [ 1.0238, -1.8286, -1.8059,  ..., -1.1359, -0.2862,  1.4164],\n",
      "         [ 1.3281, -1.1202, -2.3194,  ..., -1.0646, -0.5626,  1.6325],\n",
      "         [ 0.8763, -1.5211, -3.9552,  ..., -1.0588,  0.2761,  1.5598]],\n",
      "\n",
      "        [[ 0.5816,  3.3878,  2.8564,  ...,  2.8635,  4.2798, -2.0869],\n",
      "         [-0.5483,  3.2846,  2.5999,  ...,  3.0965,  3.2442, -1.3304],\n",
      "         [-0.6829,  3.1968,  2.6958,  ...,  3.0100,  3.0961, -1.3676],\n",
      "         ...,\n",
      "         [-0.7689,  2.8099,  2.6557,  ...,  0.7661,  3.8437, -2.1558],\n",
      "         [-0.6858,  2.8304,  2.6867,  ...,  0.8285,  3.7879, -2.1503],\n",
      "         [-0.6912,  2.7937,  2.6041,  ...,  0.7859,  3.8099, -2.1272]],\n",
      "\n",
      "        [[-0.7182,  2.7807,  2.0170,  ...,  3.7357,  3.5540, -2.3324],\n",
      "         [-1.4188,  2.7529,  1.8965,  ...,  3.4373,  3.0998, -2.1817],\n",
      "         [-1.3061,  2.7521,  1.9976,  ...,  3.4265,  2.9891, -2.1722],\n",
      "         ...,\n",
      "         [-0.8073,  2.3258,  2.1302,  ...,  1.5212,  3.7139, -2.2880],\n",
      "         [-0.7264,  2.3490,  2.1806,  ...,  1.4500,  3.7037, -2.3014],\n",
      "         [-0.7178,  2.2929,  2.1291,  ...,  1.3743,  3.7356, -2.2863]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)), decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[-0.0339,  0.0117, -0.0037,  ...,  0.0130, -0.0028, -0.0026],\n",
      "         [ 0.3061,  0.4876,  0.3064,  ...,  0.0154, -0.0580,  0.3584],\n",
      "         [ 0.2355,  0.2981,  0.1284,  ...,  0.0763,  0.1097,  0.1388],\n",
      "         ...,\n",
      "         [ 0.0437,  0.0123,  0.0857,  ...,  0.0916,  0.0313,  0.0204],\n",
      "         [ 0.0787,  0.0168,  0.0916,  ...,  0.1152,  0.1979,  0.0399],\n",
      "         [ 0.0402,  0.0498,  0.0319,  ...,  0.0653,  0.0280, -0.0179]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0340,  0.0103, -0.0028,  ...,  0.0122, -0.0018, -0.0047],\n",
      "         [ 0.2004,  0.2386,  0.4975,  ...,  0.2973,  0.1540,  0.4569],\n",
      "         [ 0.0986, -0.0424, -0.2338,  ..., -0.1875,  0.6297,  0.0286],\n",
      "         ...,\n",
      "         [ 0.0823,  0.1003,  0.0305,  ...,  0.0615,  0.0224, -0.0245],\n",
      "         [ 0.2460,  0.0583,  0.1021,  ...,  0.2033,  0.3949,  0.0771],\n",
      "         [ 0.0860,  0.1231,  0.0329,  ...,  0.0553,  0.0460, -0.0400]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]]]), encoder_hidden_states=(tensor([[[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.4281, -0.1174,  0.0323,  ...,  0.6988,  0.1744,  0.5320],\n",
      "         [-0.1183,  0.5425,  0.0263,  ..., -0.3154,  0.0398,  0.6729],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1810, -0.1337,  0.0424,  ...,  0.0790, -0.2555,  0.0459],\n",
      "         [ 0.1846, -0.1617,  0.2782,  ...,  0.0313,  0.0802,  0.1876],\n",
      "         [-0.1224, -0.2709, -0.5299,  ..., -0.0675,  0.3511, -0.0509],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]],\n",
      "\n",
      "        [[-0.0102, -0.0561,  0.0197,  ..., -0.0330, -0.2480,  0.0017],\n",
      "         [ 0.2091, -0.4204,  0.1763,  ...,  0.0304, -0.3715,  0.1434],\n",
      "         [-0.2643, -0.5314,  0.1066,  ...,  0.0879, -0.3064,  0.1012],\n",
      "         ...,\n",
      "         [ 0.4157,  0.6533, -0.0622,  ...,  0.3168,  0.2436, -0.2378],\n",
      "         [ 0.4539,  0.4505, -0.0401,  ...,  0.4219,  0.1895, -0.1260],\n",
      "         [ 0.5269,  0.2336, -0.2028,  ...,  0.7653,  0.1041, -0.1408]]]), tensor([[[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]],\n",
      "\n",
      "        [[-6.1333e-02, -4.1120e-02,  7.2085e-02,  ...,  1.1962e-02,\n",
      "          -6.0724e-02,  3.0347e-02],\n",
      "         [ 3.7574e-01, -5.0313e-02,  7.3627e-02,  ...,  7.8474e-01,\n",
      "           2.3088e-03,  3.1103e-01],\n",
      "         [-1.6134e-01,  6.3517e-01,  9.7537e-02,  ...,  2.3282e-01,\n",
      "          -1.1064e-01,  5.3066e-01],\n",
      "         ...,\n",
      "         [ 2.3667e-01,  5.6759e-01,  2.5403e-01,  ...,  7.1957e-01,\n",
      "           2.3040e-01, -1.0690e-01],\n",
      "         [ 2.8860e-01,  4.8334e-01,  6.2671e-02,  ...,  8.5650e-01,\n",
      "           4.5653e-01,  4.2280e-02],\n",
      "         [ 1.4921e-01,  2.4726e-01, -1.2294e-01,  ...,  1.0254e+00,\n",
      "           3.5230e-01,  6.9091e-02]],\n",
      "\n",
      "        [[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.9438e-02, -5.3628e-02,  6.0097e-02,  ...,  2.2180e-02,\n",
      "          -5.4427e-02,  2.5753e-02],\n",
      "         [ 2.8372e-01, -4.4593e-02,  4.6763e-01,  ...,  4.4281e-01,\n",
      "           3.1664e-01,  4.8281e-01],\n",
      "         [-4.4833e-02, -1.2683e-01, -5.1614e-01,  ..., -1.2234e-01,\n",
      "           8.8544e-01,  2.6819e-02],\n",
      "         ...,\n",
      "         [ 1.4050e-01,  5.9231e-01, -9.4161e-03,  ...,  6.1945e-01,\n",
      "           3.4425e-01, -5.3804e-01],\n",
      "         [ 5.9141e-01,  6.0398e-01, -5.8990e-02,  ...,  8.5137e-01,\n",
      "           3.9245e-01, -3.0304e-01],\n",
      "         [ 4.2102e-01,  4.5231e-01, -1.6616e-01,  ...,  8.3083e-01,\n",
      "           3.5758e-01, -2.4462e-01]],\n",
      "\n",
      "        [[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]],\n",
      "\n",
      "        [[-8.9178e-02, -8.2104e-04,  5.3468e-02,  ..., -2.7802e-02,\n",
      "           2.3031e-02, -1.9729e-02],\n",
      "         [ 3.4639e-01, -6.6405e-02,  4.1876e-01,  ...,  1.5615e-01,\n",
      "           7.4539e-02,  2.6265e-01],\n",
      "         [ 4.2778e-02, -5.8476e-02,  1.9021e-01,  ...,  2.5769e-01,\n",
      "           2.2840e-01,  1.2358e-01],\n",
      "         ...,\n",
      "         [ 4.0582e-01,  5.8914e-01,  1.7366e-01,  ...,  2.6723e-01,\n",
      "           8.1893e-01, -3.8157e-01],\n",
      "         [ 4.5669e-01,  4.2771e-01,  1.1995e-01,  ...,  4.6260e-01,\n",
      "           7.8994e-01, -2.0052e-01],\n",
      "         [ 4.4037e-01,  2.9502e-01, -6.7170e-02,  ...,  8.0768e-01,\n",
      "           7.1845e-01, -6.1761e-02]]]), tensor([[[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]],\n",
      "\n",
      "        [[-0.0775,  0.0033,  0.0536,  ..., -0.0214, -0.0579,  0.0023],\n",
      "         [ 0.5129,  0.3975,  0.3692,  ...,  0.6942,  0.3390,  0.4732],\n",
      "         [ 0.1463,  0.8132, -0.0986,  ...,  0.4884,  0.1536,  0.1926],\n",
      "         ...,\n",
      "         [ 0.2436,  0.6309,  0.4767,  ...,  0.3118,  0.3872, -0.1885],\n",
      "         [ 0.3148,  0.4061,  0.1968,  ...,  0.3533,  0.7676, -0.0904],\n",
      "         [ 0.1552,  0.4409,  0.0054,  ...,  0.6388,  0.6408, -0.1338]],\n",
      "\n",
      "        [[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0682,  0.0021,  0.0461,  ..., -0.0274, -0.0605,  0.0035],\n",
      "         [ 0.2400,  0.0672,  0.8278,  ...,  0.2021,  0.4140,  0.8821],\n",
      "         [-0.0758,  0.0378, -0.4920,  ..., -0.4228,  1.2592,  0.0679],\n",
      "         ...,\n",
      "         [ 0.2166,  0.6236,  0.1733,  ...,  0.2977,  0.5118, -0.4345],\n",
      "         [ 0.6867,  0.4485,  0.0467,  ...,  0.4365,  0.6141, -0.2199],\n",
      "         [ 0.5278,  0.5644,  0.0532,  ...,  0.3827,  0.5892, -0.2866]],\n",
      "\n",
      "        [[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]],\n",
      "\n",
      "        [[-0.0587,  0.0108, -0.0137,  ..., -0.0404, -0.1501, -0.1065],\n",
      "         [ 0.1818, -0.1453,  0.2738,  ...,  0.0600, -0.0516,  0.6832],\n",
      "         [ 0.0290, -0.4635,  0.0849,  ..., -0.0257, -0.0210,  0.0461],\n",
      "         ...,\n",
      "         [ 0.4425,  0.1626,  0.1472,  ...,  0.0230,  0.4951, -0.3883],\n",
      "         [ 0.4885,  0.0330,  0.0152,  ...,  0.1430,  0.4846, -0.2880],\n",
      "         [ 0.4657,  0.0756, -0.1250,  ...,  0.3875,  0.4517, -0.2175]]]), tensor([[[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]],\n",
      "\n",
      "        [[-6.8513e-02,  2.4983e-02,  1.1166e-02,  ..., -6.7922e-03,\n",
      "          -1.5271e-03, -6.4029e-03],\n",
      "         [ 4.8091e-01,  4.9878e-01,  3.6540e-01,  ...,  3.7243e-01,\n",
      "           3.0968e-01,  7.4193e-01],\n",
      "         [ 1.2924e-01,  6.3938e-01, -7.4931e-03,  ..., -1.7599e-01,\n",
      "           3.7465e-02,  2.5090e-01],\n",
      "         ...,\n",
      "         [ 1.9917e-01,  1.5610e-01,  5.7741e-01,  ...,  5.6783e-01,\n",
      "           2.7514e-01, -5.2509e-02],\n",
      "         [ 2.5587e-01, -1.2632e-01,  4.0124e-01,  ...,  6.4576e-01,\n",
      "           7.7980e-01,  6.3142e-02],\n",
      "         [ 5.3271e-02,  1.1368e-01,  1.9469e-01,  ...,  8.4140e-01,\n",
      "           4.9441e-01,  1.2967e-01]],\n",
      "\n",
      "        [[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.1563e-02,  2.5286e-02,  9.8840e-03,  ..., -1.2172e-02,\n",
      "          -4.2569e-03,  3.0190e-03],\n",
      "         [ 3.0041e-01,  2.5799e-01,  8.4035e-01,  ...,  2.0224e-01,\n",
      "           2.3685e-01,  8.0827e-01],\n",
      "         [-8.6120e-02, -5.1009e-02, -4.9557e-01,  ..., -7.7103e-01,\n",
      "           1.3338e+00,  2.4947e-02],\n",
      "         ...,\n",
      "         [-5.0385e-04,  5.7642e-02,  3.0008e-01,  ...,  5.7637e-01,\n",
      "           3.7078e-01, -1.5138e-01],\n",
      "         [ 5.1691e-01, -1.0570e-01,  2.2825e-01,  ...,  6.8290e-01,\n",
      "           6.4391e-01,  5.2203e-02],\n",
      "         [ 3.7033e-01,  1.7501e-01,  2.6223e-01,  ...,  6.6472e-01,\n",
      "           3.9515e-01,  6.1658e-02]],\n",
      "\n",
      "        [[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]],\n",
      "\n",
      "        [[-1.8941e-02,  1.4972e-01,  5.8224e-03,  ...,  1.4980e-02,\n",
      "           1.5121e-02,  3.0977e-02],\n",
      "         [ 9.8816e-02,  3.5667e-01,  2.9004e-01,  ...,  3.0372e-02,\n",
      "           1.7019e-01,  4.8241e-01],\n",
      "         [ 5.5996e-04,  1.8893e-01,  9.9516e-02,  ..., -7.5053e-02,\n",
      "           2.0883e-01,  1.8754e-01],\n",
      "         ...,\n",
      "         [ 2.9197e-01,  2.6632e-01,  2.3701e-01,  ..., -1.1887e-01,\n",
      "           5.5582e-01, -8.9091e-02],\n",
      "         [ 3.1292e-01,  2.1792e-01,  1.2832e-01,  ..., -1.3100e-02,\n",
      "           5.5592e-01, -3.6368e-02],\n",
      "         [ 2.3372e-01,  2.5752e-01,  4.0474e-02,  ...,  9.4879e-02,\n",
      "           5.3229e-01,  4.9802e-02]]]), tensor([[[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]],\n",
      "\n",
      "        [[-0.0933,  0.0280, -0.0025,  ...,  0.0425,  0.0052, -0.0085],\n",
      "         [ 0.5901,  0.7157,  0.4204,  ...,  0.6007,  0.2079,  0.4895],\n",
      "         [ 0.0618,  0.4083,  0.1264,  ...,  0.1388,  0.0134,  0.2189],\n",
      "         ...,\n",
      "         [ 0.3260,  0.2288,  0.5494,  ...,  0.2246,  0.2682,  0.2178],\n",
      "         [ 0.5385,  0.0855,  0.3895,  ...,  0.3943,  0.8235,  0.1636],\n",
      "         [ 0.1983,  0.4012,  0.1723,  ...,  0.4694,  0.4246,  0.1628]],\n",
      "\n",
      "        [[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0899,  0.0276, -0.0040,  ...,  0.0439,  0.0059, -0.0067],\n",
      "         [ 0.3232,  0.6422,  0.8731,  ...,  0.4383,  0.4514,  0.6602],\n",
      "         [ 0.0553,  0.0106, -0.5824,  ..., -0.6696,  1.7346, -0.0268],\n",
      "         ...,\n",
      "         [ 0.2649,  0.3787,  0.2938,  ...,  0.3203,  0.3232,  0.1831],\n",
      "         [ 0.8708,  0.1103,  0.1910,  ...,  0.4619,  0.7290,  0.0070],\n",
      "         [ 0.4533,  0.4295,  0.2216,  ...,  0.4516,  0.3345,  0.3052]],\n",
      "\n",
      "        [[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]],\n",
      "\n",
      "        [[-0.0237,  0.1366,  0.0671,  ...,  0.2832,  0.0199,  0.1640],\n",
      "         [ 0.1102,  0.2478,  0.4866,  ...,  0.7572,  0.1447,  0.7844],\n",
      "         [ 0.0384,  0.2178,  0.3466,  ...,  0.6811,  0.2145,  0.6287],\n",
      "         ...,\n",
      "         [ 0.2148,  0.1970,  0.5349,  ...,  0.6030,  0.4922,  0.5649],\n",
      "         [ 0.2194,  0.1871,  0.4289,  ...,  0.6824,  0.5061,  0.5959],\n",
      "         [ 0.1649,  0.1801,  0.3495,  ...,  0.7623,  0.5061,  0.6557]]]), tensor([[[ 2.2499e-01,  2.2679e-01, -9.7369e-02,  ...,  3.1162e-01,\n",
      "           5.4782e-02,  3.2754e-01],\n",
      "         [ 3.5536e-01,  1.4777e-01,  4.5789e-01,  ...,  3.4361e-01,\n",
      "           3.8069e-02,  9.0847e-01],\n",
      "         [ 2.8214e-01,  1.7340e-01,  3.6478e-01,  ...,  2.5438e-01,\n",
      "           1.8153e-01,  7.4237e-01],\n",
      "         ...,\n",
      "         [ 4.2941e-01,  1.7001e-01,  4.8060e-01,  ...,  2.4500e-01,\n",
      "           5.2668e-01,  8.7164e-01],\n",
      "         [ 4.2571e-01,  1.8047e-01,  3.2447e-01,  ...,  2.7726e-01,\n",
      "           5.7065e-01,  8.9218e-01],\n",
      "         [ 3.8382e-01,  1.5315e-01,  2.4005e-01,  ...,  3.1564e-01,\n",
      "           5.7542e-01,  9.3489e-01]],\n",
      "\n",
      "        [[-7.6416e-02,  3.3272e-02, -9.9048e-03,  ...,  2.7255e-02,\n",
      "          -5.8403e-03, -1.1072e-02],\n",
      "         [ 6.7435e-01,  6.7741e-01,  4.4928e-01,  ...,  2.3562e-03,\n",
      "           2.8457e-01,  7.4173e-01],\n",
      "         [ 2.4611e-01,  4.4750e-01,  1.0877e-03,  ...,  3.5554e-01,\n",
      "           3.8360e-02,  9.7146e-02],\n",
      "         ...,\n",
      "         [ 3.8829e-01,  5.1654e-02,  3.8878e-01,  ...,  2.7435e-01,\n",
      "           1.5280e-01,  2.1632e-01],\n",
      "         [ 4.2361e-01,  3.3990e-02,  2.9684e-01,  ...,  3.2492e-01,\n",
      "           6.7635e-01,  1.5894e-01],\n",
      "         [ 3.4685e-01,  1.6708e-01,  9.7012e-02,  ...,  3.7430e-01,\n",
      "           2.1928e-01,  8.0376e-02]],\n",
      "\n",
      "        [[ 2.2499e-01,  2.2679e-01, -9.7369e-02,  ...,  3.1162e-01,\n",
      "           5.4782e-02,  3.2754e-01],\n",
      "         [ 3.5536e-01,  1.4777e-01,  4.5789e-01,  ...,  3.4361e-01,\n",
      "           3.8069e-02,  9.0847e-01],\n",
      "         [ 2.8214e-01,  1.7340e-01,  3.6478e-01,  ...,  2.5438e-01,\n",
      "           1.8153e-01,  7.4237e-01],\n",
      "         ...,\n",
      "         [ 4.2941e-01,  1.7001e-01,  4.8060e-01,  ...,  2.4500e-01,\n",
      "           5.2668e-01,  8.7164e-01],\n",
      "         [ 4.2571e-01,  1.8047e-01,  3.2447e-01,  ...,  2.7726e-01,\n",
      "           5.7065e-01,  8.9218e-01],\n",
      "         [ 3.8382e-01,  1.5315e-01,  2.4005e-01,  ...,  3.1564e-01,\n",
      "           5.7542e-01,  9.3489e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.4139e-02,  3.5638e-02, -7.3174e-03,  ...,  2.8970e-02,\n",
      "          -5.7101e-03, -1.1463e-02],\n",
      "         [ 5.5140e-01,  6.5762e-01,  1.0227e+00,  ...,  3.0102e-01,\n",
      "           4.5967e-01,  7.0931e-01],\n",
      "         [ 1.5179e-01,  7.5056e-02, -5.7894e-01,  ..., -5.9448e-01,\n",
      "           1.8090e+00,  1.5734e-01],\n",
      "         ...,\n",
      "         [ 4.1500e-01,  3.8824e-01,  1.2249e-01,  ...,  2.4045e-01,\n",
      "           1.3886e-01,  6.1076e-02],\n",
      "         [ 6.1825e-01,  9.5070e-02,  1.6716e-01,  ...,  4.4340e-01,\n",
      "           8.6743e-01,  8.0515e-02],\n",
      "         [ 4.8503e-01,  4.3267e-01,  9.2807e-02,  ...,  3.0176e-01,\n",
      "           2.2726e-01,  6.5479e-02]],\n",
      "\n",
      "        [[ 2.2499e-01,  2.2679e-01, -9.7369e-02,  ...,  3.1162e-01,\n",
      "           5.4782e-02,  3.2754e-01],\n",
      "         [ 3.5536e-01,  1.4777e-01,  4.5789e-01,  ...,  3.4361e-01,\n",
      "           3.8069e-02,  9.0847e-01],\n",
      "         [ 2.8214e-01,  1.7340e-01,  3.6478e-01,  ...,  2.5438e-01,\n",
      "           1.8153e-01,  7.4237e-01],\n",
      "         ...,\n",
      "         [ 4.2941e-01,  1.7001e-01,  4.8060e-01,  ...,  2.4500e-01,\n",
      "           5.2668e-01,  8.7164e-01],\n",
      "         [ 4.2571e-01,  1.8047e-01,  3.2447e-01,  ...,  2.7726e-01,\n",
      "           5.7065e-01,  8.9218e-01],\n",
      "         [ 3.8382e-01,  1.5315e-01,  2.4005e-01,  ...,  3.1564e-01,\n",
      "           5.7542e-01,  9.3489e-01]],\n",
      "\n",
      "        [[ 2.2499e-01,  2.2679e-01, -9.7369e-02,  ...,  3.1162e-01,\n",
      "           5.4782e-02,  3.2754e-01],\n",
      "         [ 3.5536e-01,  1.4777e-01,  4.5789e-01,  ...,  3.4361e-01,\n",
      "           3.8069e-02,  9.0847e-01],\n",
      "         [ 2.8214e-01,  1.7340e-01,  3.6478e-01,  ...,  2.5438e-01,\n",
      "           1.8153e-01,  7.4237e-01],\n",
      "         ...,\n",
      "         [ 4.2941e-01,  1.7001e-01,  4.8060e-01,  ...,  2.4500e-01,\n",
      "           5.2668e-01,  8.7164e-01],\n",
      "         [ 4.2571e-01,  1.8047e-01,  3.2447e-01,  ...,  2.7726e-01,\n",
      "           5.7065e-01,  8.9218e-01],\n",
      "         [ 3.8382e-01,  1.5315e-01,  2.4005e-01,  ...,  3.1564e-01,\n",
      "           5.7542e-01,  9.3489e-01]]]), tensor([[[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[-0.0339,  0.0117, -0.0037,  ...,  0.0130, -0.0028, -0.0026],\n",
      "         [ 0.3061,  0.4876,  0.3064,  ...,  0.0154, -0.0580,  0.3584],\n",
      "         [ 0.2355,  0.2981,  0.1284,  ...,  0.0763,  0.1097,  0.1388],\n",
      "         ...,\n",
      "         [ 0.0437,  0.0123,  0.0857,  ...,  0.0916,  0.0313,  0.0204],\n",
      "         [ 0.0787,  0.0168,  0.0916,  ...,  0.1152,  0.1979,  0.0399],\n",
      "         [ 0.0402,  0.0498,  0.0319,  ...,  0.0653,  0.0280, -0.0179]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0340,  0.0103, -0.0028,  ...,  0.0122, -0.0018, -0.0047],\n",
      "         [ 0.2004,  0.2386,  0.4975,  ...,  0.2973,  0.1540,  0.4569],\n",
      "         [ 0.0986, -0.0424, -0.2338,  ..., -0.1875,  0.6297,  0.0286],\n",
      "         ...,\n",
      "         [ 0.0823,  0.1003,  0.0305,  ...,  0.0615,  0.0224, -0.0245],\n",
      "         [ 0.2460,  0.0583,  0.1021,  ...,  0.2033,  0.3949,  0.0771],\n",
      "         [ 0.0860,  0.1231,  0.0329,  ...,  0.0553,  0.0460, -0.0400]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]],\n",
      "\n",
      "        [[ 0.0090,  0.0044, -0.0100,  ...,  0.0281, -0.0542,  0.1046],\n",
      "         [ 0.1233, -0.1433,  0.4499,  ...,  0.2226, -0.1095,  0.3604],\n",
      "         [ 0.0360, -0.1268,  0.3674,  ...,  0.1146,  0.0414,  0.2471],\n",
      "         ...,\n",
      "         [ 0.0681, -0.0749,  0.4064,  ...,  0.1881,  0.2575,  0.2883],\n",
      "         [ 0.0670, -0.0659,  0.3156,  ...,  0.2034,  0.2811,  0.2880],\n",
      "         [ 0.0489, -0.0589,  0.2812,  ...,  0.2276,  0.2840,  0.2832]]])), encoder_attentions=None)\n",
      "model is finished\n"
     ]
    }
   ],
   "source": [
    "for _, batch in enumerate(train_dataloader):\n",
    "    input_ids = batch[\"input_ids\"].to(model.device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(model.device)\n",
    "    labels = batch[\"labels\"].to(model.device)\n",
    "    \n",
    "    print(\"input_ids.shape:\", input_ids.shape)\n",
    "    print(\"attention_mask.shape:\", attention_mask.shape)\n",
    "    print(\"labels.shape:\", labels.shape)\n",
    "\n",
    "    model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "    # model.generate(\n",
    "    #     input_ids=input_ids,\n",
    "    #     min_length=0,\n",
    "    #     max_length=142,\n",
    "    #     num_beams=4\n",
    "    # )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_tokens = torch.arange(20).long()\n",
    "prefix_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_tokens = prefix_tokens.unsqueeze(0)\n",
    "prefix_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_tokens = prefix_tokens.expand(32, -1)\n",
    "prefix_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token_id: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[12312414],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)\n",
    "segment_size = 20\n",
    "def get_full_padding_segment():\n",
    "    padding_segment = [tokenizer.pad_token_id for _ in range(segment_size)]\n",
    "    return padding_segment\n",
    "\n",
    "test = get_full_padding_segment()\n",
    "test\n",
    "[test]\n",
    "[[12312414]] + [test] * 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
