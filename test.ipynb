{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, MBartForConditionalGeneration\n",
    "tokenizer = AutoTokenizer.from_pretrained('ku-nlp/bart-base-japanese')\n",
    "model = MBartForConditionalGeneration.from_pretrained('ku-nlp/bart-base-japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "本稿では実際に計算機上で試作した論説文要約システムに関して, これで用いられている論説文要約の手法の紹介と, これによって出力された文章の評価を行う."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '本稿 では 実際に 計算機上 で試作した 論説文 要約システム に 関して, これで 用 いられている 論説文 要約の 手法の 紹介と, これ によって 出力された 文章の 評価を 行う.'  # input should be segmented into words by Juman++ in advance\n",
    "encoding = tokenizer(sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 18573, 24285,  1367, 28430,  3126, 28626, 28536,    12, 28884,\n",
       "         28540,   198, 23644, 28673, 21607, 21699,     7,  2210,     3,   180,\n",
       "         28439,   235, 21911,   630, 28441, 28433, 23644, 28673, 21607, 28428,\n",
       "          3713, 28428,  1972, 28436,     3,   180,     7, 28476,    44,  3331,\n",
       "         28459,   483,  7118, 28428,  1418, 28437,   794,     3,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Can't find JUMAN command: jumanpp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyknp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Juman\n\u001b[0;32m----> 3\u001b[0m jumanpp \u001b[38;5;241m=\u001b[39m \u001b[43mJuman\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m吾輩は猫である。\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m mlist \u001b[38;5;241m=\u001b[39m jumanpp\u001b[38;5;241m.\u001b[39manalysis(text)\n",
      "File \u001b[0;32m~/miniconda3/envs/summarization/lib/python3.11/site-packages/pyknp/juman/juman.py:66\u001b[0m, in \u001b[0;36mJuman.__init__\u001b[0;34m(self, command, server, port, timeout, option, rcfile, ignorepattern, pattern, jumanpp, multithreading)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt read rcfile (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)!\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrcfile)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distutils\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mfind_executable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find JUMAN command: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand)\n",
      "\u001b[0;31mException\u001b[0m: Can't find JUMAN command: jumanpp"
     ]
    }
   ],
   "source": [
    "from pyknp import Juman\n",
    "\n",
    "jumanpp = Juman()\n",
    "\n",
    "text = '吾輩は猫である。'\n",
    "mlist = jumanpp.analysis(text)\n",
    "\n",
    "print([mrph.midasi for mrph in mlist.mrph_list()])\n",
    "# ['吾輩', 'は', '猫', 'である', '。']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('ku-nlp/bart-base-japanese')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('ku-nlp/bart-base-japanese')\n",
    "sentence = '京都 大学 で 自然 言語 処理 を 専攻 する 。'  # input should be segmented into words by Juman++ in advance\n",
    "encoding = tokenizer(sentence, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBartForConditionalGeneration(\n",
       "  (model): MBartModel(\n",
       "    (shared): Embedding(32002, 768, padding_idx=1)\n",
       "    (encoder): MBartEncoder(\n",
       "      (embed_tokens): Embedding(32002, 768, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): MBartDecoder(\n",
       "      (embed_tokens): Embedding(32002, 768, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32002, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate \n",
    "\n",
    "metric = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.6, 'rouge2': 0.5, 'rougeL': 0.6, 'rougeLsum': 0.6}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=['京都 大学 で を 専攻する。'], references=['京都 大学 で 自然言語 処理を専攻する。'],tokenizer=lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.5714285714285714, 'p': 0.8, 'f': 0.6666666618055556},\n",
       " 'rouge-2': {'r': 0.3333333333333333, 'p': 0.5, 'f': 0.39999999520000007},\n",
       " 'rouge-l': {'r': 0.5714285714285714, 'p': 0.8, 'f': 0.6666666618055556}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "predictions = ['日本語 は る 言語 である']\n",
    "labels = ['日本語 は 日本 で 使われている 言語 である']\n",
    "\n",
    "scores = rouge.get_scores(predictions, labels, avg=True)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.5714285714285714, 'p': 0.8, 'f': 0.6666666618055556},\n",
       " 'rouge-2': {'r': 0.3333333333333333, 'p': 0.5, 'f': 0.39999999520000007},\n",
       " 'rouge-l': {'r': 0.5714285714285714, 'p': 0.8, 'f': 0.6666666618055556}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rouge-1': {'r': 1.0, 'p': 0.6666666666666666, 'f': 0.7999999952000001}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 1.0, 'p': 0.6666666666666666, 'f': 0.7999999952000001}}]\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# 参考摘要\n",
    "reference_summary = \"日本　摘要文本\"\n",
    "\n",
    "# 生成摘要\n",
    "generated_summary = \"日本　語　摘要文本\"\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(generated_summary, reference_summary)\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoConfig\n",
    "config = AutoConfig.from_pretrained('ku-nlp/bart-base-japanese')\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    generation_config = AutoConfig.from_pretrained('ku-nlp/bart-base-japanese'), \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBartConfig {\n",
      "  \"_name_or_path\": \"ku-nlp/bart-base-japanese\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"MBartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"mbart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_args.generation_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
