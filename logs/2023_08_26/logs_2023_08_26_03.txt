/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:549: FutureWarning: The class `PretrainedBartModel` has been depreciated, please use `BartPreTrainedModel` instead.
  warnings.warn(
[nltk_data] Downloading package punkt to
[nltk_data]     /home/is/kaifan-l/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
trainable params: 184,320 || all params: 139,604,736 || trainable%: 0.13202990477343118
BartPrefixForConditionalGeneration(
  (model): PeftModelForSeq2SeqLM(
    (base_model): BartForConditionalGeneration(
      (model): BartModel(
        (shared): Embedding(50265, 768, padding_idx=1)
        (encoder): BartEncoder(
          (embed_tokens): Embedding(50265, 768, padding_idx=1)
          (embed_positions): BartLearnedPositionalEmbedding(1026, 768)
          (layers): ModuleList(
            (0-5): 6 x BartEncoderLayer(
              (self_attn): BartAttention(
                (k_proj): Linear(in_features=768, out_features=768, bias=True)
                (v_proj): Linear(in_features=768, out_features=768, bias=True)
                (q_proj): Linear(in_features=768, out_features=768, bias=True)
                (out_proj): Linear(in_features=768, out_features=768, bias=True)
              )
              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (activation_fn): GELUActivation()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder): BartDecoder(
          (embed_tokens): Embedding(50265, 768, padding_idx=1)
          (embed_positions): BartLearnedPositionalEmbedding(1026, 768)
          (layers): ModuleList(
            (0-5): 6 x BartDecoderLayer(
              (self_attn): BartAttention(
                (k_proj): Linear(in_features=768, out_features=768, bias=True)
                (v_proj): Linear(in_features=768, out_features=768, bias=True)
                (q_proj): Linear(in_features=768, out_features=768, bias=True)
                (out_proj): Linear(in_features=768, out_features=768, bias=True)
              )
              (activation_fn): GELUActivation()
              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (encoder_attn): BartAttention(
                (k_proj): Linear(in_features=768, out_features=768, bias=True)
                (v_proj): Linear(in_features=768, out_features=768, bias=True)
                (q_proj): Linear(in_features=768, out_features=768, bias=True)
                (out_proj): Linear(in_features=768, out_features=768, bias=True)
              )
              (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (lm_head): Linear(in_features=768, out_features=50265, bias=False)
    )
    (prompt_encoder): ModuleDict(
      (default): PrefixEncoder(
        (embedding): Embedding(20, 9216)
      )
    )
    (word_embeddings): Embedding(50265, 768, padding_idx=1)
  )
)
Start training ...
cuda
================================== epoch 0 ==================================
  0%|          | 0/36 [00:00<?, ?it/s]You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  3%|▎         | 1/36 [00:01<00:54,  1.56s/it]  6%|▌         | 2/36 [00:02<00:49,  1.45s/it]  8%|▊         | 3/36 [00:04<00:48,  1.47s/it] 11%|█         | 4/36 [00:06<00:50,  1.58s/it] 14%|█▍        | 5/36 [00:07<00:50,  1.64s/it] 17%|█▋        | 6/36 [00:09<00:45,  1.51s/it] 19%|█▉        | 7/36 [00:10<00:44,  1.54s/it] 22%|██▏       | 8/36 [00:12<00:44,  1.58s/it] 25%|██▌       | 9/36 [00:13<00:42,  1.57s/it] 28%|██▊       | 10/36 [00:15<00:42,  1.64s/it] 31%|███       | 11/36 [00:17<00:42,  1.70s/it] 33%|███▎      | 12/36 [00:19<00:41,  1.71s/it] 36%|███▌      | 13/36 [00:20<00:36,  1.59s/it] 39%|███▉      | 14/36 [00:22<00:34,  1.56s/it] 42%|████▏     | 15/36 [00:24<00:34,  1.65s/it] 44%|████▍     | 16/36 [00:25<00:31,  1.58s/it] 47%|████▋     | 17/36 [00:27<00:31,  1.67s/it] 50%|█████     | 18/36 [00:28<00:28,  1.60s/it] 53%|█████▎    | 19/36 [00:30<00:28,  1.66s/it] 56%|█████▌    | 20/36 [00:32<00:27,  1.72s/it] 58%|█████▊    | 21/36 [00:34<00:26,  1.77s/it] 61%|██████    | 22/36 [00:35<00:23,  1.71s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.67s/it] 67%|██████▋   | 24/36 [00:39<00:20,  1.69s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.59s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.64s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.60s/it] 78%|███████▊  | 28/36 [00:45<00:13,  1.69s/it] 81%|████████  | 29/36 [00:47<00:11,  1.67s/it] 83%|████████▎ | 30/36 [00:49<00:10,  1.71s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.75s/it] 89%|████████▉ | 32/36 [00:52<00:06,  1.70s/it] 92%|█████████▏| 33/36 [00:54<00:05,  1.73s/it] 94%|█████████▍| 34/36 [00:56<00:03,  1.72s/it] 97%|█████████▋| 35/36 [00:57<00:01,  1.72s/it]100%|██████████| 36/36 [00:59<00:00,  1.62s/it]100%|██████████| 36/36 [00:59<00:00,  1.64s/it]
GPU Memory before entering the train : 533
GPU Memory consumed at the end of the train (end-begin): 4141
GPU Peak Memory consumed during the train (max-begin): 20992
GPU Total Peak Memory consumed during the train (max): 21525
CPU Memory before entering the train : 1881
CPU Memory consumed at the end of the train (end-begin): 436
CPU Peak Memory consumed during the train (max-begin): 436
CPU Total Peak Memory consumed during the train (max): 2317
epoch=0: train_ppl=tensor(7178.3799, device='cuda:0') train_epoch_loss=tensor(8.8788, device='cuda:0')


Start evaluating ...
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:01<00:20,  1.27s/it] 12%|█▏        | 2/17 [00:02<00:21,  1.42s/it] 18%|█▊        | 3/17 [00:04<00:19,  1.40s/it] 24%|██▎       | 4/17 [00:05<00:18,  1.45s/it] 29%|██▉       | 5/17 [00:07<00:16,  1.40s/it] 35%|███▌      | 6/17 [00:08<00:14,  1.31s/it] 41%|████      | 7/17 [00:09<00:13,  1.31s/it] 47%|████▋     | 8/17 [00:10<00:12,  1.37s/it] 53%|█████▎    | 9/17 [00:12<00:11,  1.39s/it] 59%|█████▉    | 10/17 [00:13<00:10,  1.44s/it] 65%|██████▍   | 11/17 [00:15<00:08,  1.47s/it] 71%|███████   | 12/17 [00:16<00:07,  1.47s/it] 76%|███████▋  | 13/17 [00:18<00:05,  1.39s/it] 82%|████████▏ | 14/17 [00:19<00:04,  1.42s/it] 88%|████████▊ | 15/17 [00:20<00:02,  1.39s/it] 94%|█████████▍| 16/17 [00:22<00:01,  1.40s/it]100%|██████████| 17/17 [00:23<00:00,  1.17s/it]100%|██████████| 17/17 [00:23<00:00,  1.36s/it]
epoch=0: eval_ppl=tensor(1097.7078, device='cuda:0') eval_epoch_loss=tensor(7.0010, device='cuda:0')
================================== epoch 1 ==================================
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:45,  1.29s/it]  6%|▌         | 2/36 [00:02<00:47,  1.39s/it]  8%|▊         | 3/36 [00:04<00:49,  1.50s/it] 11%|█         | 4/36 [00:05<00:46,  1.46s/it] 14%|█▍        | 5/36 [00:07<00:49,  1.60s/it] 17%|█▋        | 6/36 [00:09<00:47,  1.58s/it] 19%|█▉        | 7/36 [00:10<00:46,  1.62s/it] 22%|██▏       | 8/36 [00:12<00:43,  1.57s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:15<00:40,  1.55s/it] 31%|███       | 11/36 [00:16<00:38,  1.54s/it] 33%|███▎      | 12/36 [00:18<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:20<00:37,  1.64s/it] 39%|███▉      | 14/36 [00:22<00:37,  1.68s/it] 42%|████▏     | 15/36 [00:24<00:36,  1.72s/it] 44%|████▍     | 16/36 [00:25<00:33,  1.68s/it] 47%|████▋     | 17/36 [00:27<00:32,  1.70s/it] 50%|█████     | 18/36 [00:28<00:29,  1.66s/it] 53%|█████▎    | 19/36 [00:30<00:28,  1.67s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.59s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.66s/it] 61%|██████    | 22/36 [00:35<00:24,  1.72s/it] 64%|██████▍   | 23/36 [00:37<00:22,  1.70s/it] 67%|██████▋   | 24/36 [00:39<00:21,  1.76s/it] 69%|██████▉   | 25/36 [00:41<00:19,  1.77s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.63s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.55s/it] 81%|████████  | 29/36 [00:46<00:10,  1.49s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.69s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.63s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.58s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.54s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.63s/it]100%|██████████| 36/36 [00:58<00:00,  1.59s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
GPU Memory before entering the train : 3496
GPU Memory consumed at the end of the train (end-begin): 1178
GPU Peak Memory consumed during the train (max-begin): 18026
GPU Total Peak Memory consumed during the train (max): 21522
CPU Memory before entering the train : 2340
CPU Memory consumed at the end of the train (end-begin): 0
CPU Peak Memory consumed during the train (max-begin): 0
CPU Total Peak Memory consumed during the train (max): 2340
epoch=1: train_ppl=tensor(1822.4594, device='cuda:0') train_epoch_loss=tensor(7.5079, device='cuda:0')


Start evaluating ...
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:01<00:20,  1.28s/it] 12%|█▏        | 2/17 [00:02<00:21,  1.42s/it] 18%|█▊        | 3/17 [00:04<00:19,  1.39s/it] 24%|██▎       | 4/17 [00:05<00:18,  1.46s/it] 29%|██▉       | 5/17 [00:06<00:16,  1.39s/it] 35%|███▌      | 6/17 [00:08<00:14,  1.30s/it] 41%|████      | 7/17 [00:09<00:13,  1.30s/it] 47%|████▋     | 8/17 [00:10<00:12,  1.37s/it] 53%|█████▎    | 9/17 [00:12<00:11,  1.39s/it] 59%|█████▉    | 10/17 [00:13<00:10,  1.44s/it] 65%|██████▍   | 11/17 [00:15<00:08,  1.47s/it] 71%|███████   | 12/17 [00:16<00:07,  1.47s/it] 76%|███████▋  | 13/17 [00:18<00:05,  1.39s/it] 82%|████████▏ | 14/17 [00:19<00:04,  1.42s/it] 88%|████████▊ | 15/17 [00:20<00:02,  1.39s/it] 94%|█████████▍| 16/17 [00:22<00:01,  1.40s/it]100%|██████████| 17/17 [00:23<00:00,  1.18s/it]100%|██████████| 17/17 [00:23<00:00,  1.36s/it]
epoch=1: eval_ppl=tensor(475.5210, device='cuda:0') eval_epoch_loss=tensor(6.1644, device='cuda:0')
================================== epoch 2 ==================================
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:48,  1.38s/it]  6%|▌         | 2/36 [00:03<00:54,  1.61s/it]  8%|▊         | 3/36 [00:04<00:52,  1.58s/it] 11%|█         | 4/36 [00:06<00:54,  1.70s/it] 14%|█▍        | 5/36 [00:08<00:51,  1.68s/it] 17%|█▋        | 6/36 [00:09<00:49,  1.65s/it] 19%|█▉        | 7/36 [00:11<00:48,  1.66s/it] 22%|██▏       | 8/36 [00:13<00:48,  1.73s/it] 25%|██▌       | 9/36 [00:15<00:46,  1.71s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.65s/it] 31%|███       | 11/36 [00:18<00:40,  1.63s/it] 33%|███▎      | 12/36 [00:20<00:40,  1.71s/it] 36%|███▌      | 13/36 [00:21<00:39,  1.73s/it] 39%|███▉      | 14/36 [00:23<00:39,  1.77s/it] 42%|████▏     | 15/36 [00:25<00:36,  1.72s/it] 44%|████▍     | 16/36 [00:27<00:34,  1.73s/it] 47%|████▋     | 17/36 [00:28<00:32,  1.69s/it] 50%|█████     | 18/36 [00:30<00:29,  1.63s/it] 53%|█████▎    | 19/36 [00:31<00:28,  1.68s/it] 56%|█████▌    | 20/36 [00:33<00:27,  1.72s/it] 58%|█████▊    | 21/36 [00:35<00:25,  1.70s/it] 61%|██████    | 22/36 [00:37<00:24,  1.72s/it] 64%|██████▍   | 23/36 [00:38<00:21,  1.67s/it] 67%|██████▋   | 24/36 [00:40<00:19,  1.62s/it] 69%|██████▉   | 25/36 [00:41<00:17,  1.57s/it] 72%|███████▏  | 26/36 [00:43<00:15,  1.54s/it] 75%|███████▌  | 27/36 [00:44<00:13,  1.55s/it] 78%|███████▊  | 28/36 [00:46<00:12,  1.55s/it] 81%|████████  | 29/36 [00:48<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:49<00:10,  1.70s/it] 86%|████████▌ | 31/36 [00:51<00:08,  1.72s/it] 89%|████████▉ | 32/36 [00:53<00:06,  1.67s/it] 92%|█████████▏| 33/36 [00:54<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:56<00:03,  1.66s/it] 97%|█████████▋| 35/36 [00:57<00:01,  1.59s/it]100%|██████████| 36/36 [00:59<00:00,  1.60s/it]100%|██████████| 36/36 [00:59<00:00,  1.65s/it]
GPU Memory before entering the train : 3496
GPU Memory consumed at the end of the train (end-begin): 1178
GPU Peak Memory consumed during the train (max-begin): 18026
GPU Total Peak Memory consumed during the train (max): 21522
CPU Memory before entering the train : 2340
CPU Memory consumed at the end of the train (end-begin): 0
CPU Peak Memory consumed during the train (max-begin): 0
CPU Total Peak Memory consumed during the train (max): 2340
epoch=2: train_ppl=tensor(981.6609, device='cuda:0') train_epoch_loss=tensor(6.8892, device='cuda:0')


Start evaluating ...
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:01<00:20,  1.28s/it] 12%|█▏        | 2/17 [00:02<00:21,  1.43s/it] 18%|█▊        | 3/17 [00:04<00:19,  1.39s/it] 24%|██▎       | 4/17 [00:05<00:18,  1.45s/it] 29%|██▉       | 5/17 [00:06<00:16,  1.38s/it] 35%|███▌      | 6/17 [00:08<00:14,  1.30s/it] 41%|████      | 7/17 [00:09<00:13,  1.30s/it] 47%|████▋     | 8/17 [00:10<00:12,  1.37s/it] 53%|█████▎    | 9/17 [00:12<00:11,  1.39s/it] 59%|█████▉    | 10/17 [00:13<00:10,  1.44s/it] 65%|██████▍   | 11/17 [00:15<00:08,  1.47s/it] 71%|███████   | 12/17 [00:16<00:07,  1.47s/it] 76%|███████▋  | 13/17 [00:18<00:05,  1.39s/it] 82%|████████▏ | 14/17 [00:19<00:04,  1.42s/it] 88%|████████▊ | 15/17 [00:20<00:02,  1.39s/it] 94%|█████████▍| 16/17 [00:22<00:01,  1.40s/it]100%|██████████| 17/17 [00:23<00:00,  1.18s/it]100%|██████████| 17/17 [00:23<00:00,  1.35s/it]
epoch=2: eval_ppl=tensor(299.4375, device='cuda:0') eval_epoch_loss=tensor(5.7019, device='cuda:0')
================================== epoch 3 ==================================
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:39,  1.13s/it]  6%|▌         | 2/36 [00:02<00:51,  1.51s/it]  8%|▊         | 3/36 [00:04<00:55,  1.68s/it] 11%|█         | 4/36 [00:06<00:55,  1.73s/it] 14%|█▍        | 5/36 [00:08<00:53,  1.73s/it] 17%|█▋        | 6/36 [00:10<00:52,  1.74s/it] 19%|█▉        | 7/36 [00:11<00:51,  1.78s/it] 22%|██▏       | 8/36 [00:13<00:48,  1.72s/it] 25%|██▌       | 9/36 [00:15<00:46,  1.71s/it] 28%|██▊       | 10/36 [00:16<00:40,  1.57s/it] 31%|███       | 11/36 [00:18<00:39,  1.60s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.60s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.65s/it] 39%|███▉      | 14/36 [00:23<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:32,  1.55s/it] 44%|████▍     | 16/36 [00:26<00:32,  1.63s/it] 47%|████▋     | 17/36 [00:28<00:32,  1.72s/it] 50%|█████     | 18/36 [00:29<00:30,  1.69s/it] 53%|█████▎    | 19/36 [00:31<00:28,  1.65s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.58s/it] 58%|█████▊    | 21/36 [00:34<00:23,  1.59s/it] 61%|██████    | 22/36 [00:36<00:22,  1.63s/it] 64%|██████▍   | 23/36 [00:37<00:22,  1.69s/it] 67%|██████▋   | 24/36 [00:39<00:19,  1.66s/it] 69%|██████▉   | 25/36 [00:41<00:18,  1.68s/it] 72%|███████▏  | 26/36 [00:43<00:17,  1.72s/it] 75%|███████▌  | 27/36 [00:44<00:14,  1.66s/it] 78%|███████▊  | 28/36 [00:46<00:12,  1.60s/it] 81%|████████  | 29/36 [00:47<00:11,  1.69s/it] 83%|████████▎ | 30/36 [00:49<00:10,  1.67s/it] 86%|████████▌ | 31/36 [00:51<00:08,  1.71s/it] 89%|████████▉ | 32/36 [00:53<00:06,  1.69s/it] 92%|█████████▏| 33/36 [00:54<00:05,  1.67s/it] 94%|█████████▍| 34/36 [00:56<00:03,  1.60s/it] 97%|█████████▋| 35/36 [00:57<00:01,  1.68s/it]100%|██████████| 36/36 [00:59<00:00,  1.60s/it]100%|██████████| 36/36 [00:59<00:00,  1.65s/it]
GPU Memory before entering the train : 3496
GPU Memory consumed at the end of the train (end-begin): 1178
GPU Peak Memory consumed during the train (max-begin): 18026
GPU Total Peak Memory consumed during the train (max): 21522
CPU Memory before entering the train : 2340
CPU Memory consumed at the end of the train (end-begin): 0
CPU Peak Memory consumed during the train (max-begin): 0
CPU Total Peak Memory consumed during the train (max): 2340
epoch=3: train_ppl=tensor(647.9596, device='cuda:0') train_epoch_loss=tensor(6.4738, device='cuda:0')


Start evaluating ...
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:01<00:20,  1.27s/it] 12%|█▏        | 2/17 [00:02<00:21,  1.43s/it] 18%|█▊        | 3/17 [00:04<00:19,  1.39s/it] 24%|██▎       | 4/17 [00:05<00:18,  1.45s/it] 29%|██▉       | 5/17 [00:06<00:16,  1.39s/it] 35%|███▌      | 6/17 [00:08<00:14,  1.30s/it] 41%|████      | 7/17 [00:09<00:13,  1.31s/it] 47%|████▋     | 8/17 [00:10<00:12,  1.37s/it] 53%|█████▎    | 9/17 [00:12<00:11,  1.39s/it] 59%|█████▉    | 10/17 [00:13<00:10,  1.44s/it] 65%|██████▍   | 11/17 [00:15<00:08,  1.47s/it] 71%|███████   | 12/17 [00:16<00:07,  1.47s/it] 76%|███████▋  | 13/17 [00:18<00:05,  1.39s/it] 82%|████████▏ | 14/17 [00:19<00:04,  1.42s/it] 88%|████████▊ | 15/17 [00:20<00:02,  1.39s/it] 94%|█████████▍| 16/17 [00:22<00:01,  1.40s/it]100%|██████████| 17/17 [00:23<00:00,  1.18s/it]100%|██████████| 17/17 [00:23<00:00,  1.36s/it]
epoch=3: eval_ppl=tensor(232.2206, device='cuda:0') eval_epoch_loss=tensor(5.4477, device='cuda:0')
================================== epoch 4 ==================================
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:44,  1.28s/it]  6%|▌         | 2/36 [00:03<00:52,  1.55s/it]  8%|▊         | 3/36 [00:04<00:55,  1.67s/it] 11%|█         | 4/36 [00:06<00:53,  1.67s/it] 14%|█▍        | 5/36 [00:07<00:49,  1.59s/it] 17%|█▋        | 6/36 [00:09<00:50,  1.70s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.65s/it] 22%|██▏       | 8/36 [00:12<00:44,  1.57s/it] 25%|██▌       | 9/36 [00:14<00:41,  1.55s/it] 28%|██▊       | 10/36 [00:16<00:43,  1.66s/it] 31%|███       | 11/36 [00:17<00:40,  1.60s/it] 33%|███▎      | 12/36 [00:19<00:39,  1.64s/it] 36%|███▌      | 13/36 [00:21<00:38,  1.68s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:32,  1.56s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.63s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.59s/it] 50%|█████     | 18/36 [00:29<00:29,  1.67s/it] 53%|█████▎    | 19/36 [00:30<00:28,  1.65s/it] 56%|█████▌    | 20/36 [00:32<00:27,  1.70s/it] 58%|█████▊    | 21/36 [00:34<00:25,  1.71s/it] 61%|██████    | 22/36 [00:35<00:22,  1.63s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:18,  1.58s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:17,  1.70s/it] 75%|███████▌  | 27/36 [00:44<00:15,  1.76s/it] 78%|███████▊  | 28/36 [00:46<00:13,  1.71s/it] 81%|████████  | 29/36 [00:47<00:12,  1.74s/it] 83%|████████▎ | 30/36 [00:49<00:10,  1.73s/it] 86%|████████▌ | 31/36 [00:51<00:08,  1.73s/it] 89%|████████▉ | 32/36 [00:53<00:07,  1.78s/it] 92%|█████████▏| 33/36 [00:54<00:05,  1.72s/it] 94%|█████████▍| 34/36 [00:56<00:03,  1.62s/it] 97%|█████████▋| 35/36 [00:57<00:01,  1.61s/it]100%|██████████| 36/36 [00:59<00:00,  1.59s/it]100%|██████████| 36/36 [00:59<00:00,  1.65s/it]
GPU Memory before entering the train : 3496
GPU Memory consumed at the end of the train (end-begin): 1178
GPU Peak Memory consumed during the train (max-begin): 18026
GPU Total Peak Memory consumed during the train (max): 21522
CPU Memory before entering the train : 2340
CPU Memory consumed at the end of the train (end-begin): 0
CPU Peak Memory consumed during the train (max-begin): 0
CPU Total Peak Memory consumed during the train (max): 2340
epoch=4: train_ppl=tensor(505.7600, device='cuda:0') train_epoch_loss=tensor(6.2261, device='cuda:0')


Start evaluating ...
  0%|          | 0/17 [00:00<?, ?it/s]  6%|▌         | 1/17 [00:01<00:20,  1.26s/it] 12%|█▏        | 2/17 [00:02<00:21,  1.42s/it] 18%|█▊        | 3/17 [00:04<00:19,  1.39s/it] 24%|██▎       | 4/17 [00:05<00:18,  1.45s/it] 29%|██▉       | 5/17 [00:06<00:16,  1.38s/it] 35%|███▌      | 6/17 [00:08<00:14,  1.29s/it] 41%|████      | 7/17 [00:09<00:13,  1.30s/it] 47%|████▋     | 8/17 [00:10<00:12,  1.37s/it] 53%|█████▎    | 9/17 [00:12<00:11,  1.39s/it] 59%|█████▉    | 10/17 [00:13<00:10,  1.44s/it] 65%|██████▍   | 11/17 [00:15<00:08,  1.48s/it] 71%|███████   | 12/17 [00:16<00:07,  1.48s/it] 76%|███████▋  | 13/17 [00:18<00:05,  1.40s/it] 82%|████████▏ | 14/17 [00:19<00:04,  1.42s/it] 88%|████████▊ | 15/17 [00:20<00:02,  1.39s/it] 94%|█████████▍| 16/17 [00:22<00:01,  1.41s/it]100%|██████████| 17/17 [00:23<00:00,  1.18s/it]100%|██████████| 17/17 [00:23<00:00,  1.35s/it]
epoch=4: eval_ppl=tensor(200.5493, device='cuda:0') eval_epoch_loss=tensor(5.3011, device='cuda:0')
Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]Downloading builder script: 100%|██████████| 6.27k/6.27k [00:00<00:00, 21.1MB/s]
Traceback (most recent call last):
  File "/home/is/kaifan-l/private_room/proj-repos/prompt-for-long-text-summarization/run.py", line 251, in <module>
    main()
  File "/home/is/kaifan-l/private_room/proj-repos/prompt-for-long-text-summarization/run.py", line 228, in main
    rouge_metric = evaluate.load("rouge")
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/evaluate/loading.py", line 731, in load
    evaluation_module = evaluation_module_factory(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/evaluate/loading.py", line 680, in evaluation_module_factory
    raise e1 from None
  File "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/evaluate/loading.py", line 639, in evaluation_module_factory
    ).get_module()
      ^^^^^^^^^^^^
  File "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/evaluate/loading.py", line 489, in get_module
    local_imports = _download_additional_modules(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/is/kaifan-l/miniconda3/envs/summarization/lib/python3.11/site-packages/evaluate/loading.py", line 265, in _download_additional_modules
    raise ImportError(
ImportError: To be able to use evaluate-metric/rouge, you need to install the following dependencies['absl', 'rouge_score'] using 'pip install # Here to have a nice missing dependency error message early on rouge_score' for instance'
